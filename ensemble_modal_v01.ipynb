{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abdulkadir TAŞDELEN\n",
    "### Bu dosyada önemli modellerin farklı batch size'lara göre k-fold CV sonucu elde edilen sonuçları içermektedir.\n",
    "\n",
    "### Grid Search ile farklı parametrelerin testi\n",
    "\n",
    "\n",
    "Last Update: 31.08.2024\n",
    "\n",
    "Örnek Makaleler:\n",
    "https://ms.hmb.gov.tr/uploads/2024/07/03-186_13-Turkiyede-Butce-Gelirlerinin-Tahmini.pdf\n",
    "https://www.proquest.com/openview/b7712f88b52716855e3916cd47adeac6/1?cbl=396471&pq-origsite=gscholar&parentSessionId=VpA7%2F6IztQXgaL0%2BZm%2F074%2FnVBSVNxeyvFPQ%2BDFLaiQ%3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOR_1A              0\n",
      "TEMP (ｰC)           0\n",
      "RH (%)              0\n",
      "PAINS (HPA)         0\n",
      "1H RAIN (MM)        0\n",
      "WSINS (KT)      17639\n",
      "RSL                 0\n",
      "Refrence            0\n",
      "dB                  0\n",
      "dB/km               0\n",
      "dtype: int64\n",
      "History file UTC Time\n",
      "1.06.2014 21:00     5.64\n",
      "1.06.2014 21:01     5.25\n",
      "1.06.2014 21:02     4.47\n",
      "1.06.2014 21:03     4.28\n",
      "1.06.2014 21:04     5.25\n",
      "                   ...  \n",
      "2.07.2014 07:25    15.36\n",
      "2.07.2014 07:26    20.22\n",
      "2.07.2014 07:27    12.44\n",
      "2.07.2014 07:28    22.16\n",
      "2.07.2014 07:29    17.88\n",
      "Name: WSINS (KT), Length: 39074, dtype: object\n",
      "MOR_1A          0\n",
      "TEMP (ｰC)       0\n",
      "RH (%)          0\n",
      "PAINS (HPA)     0\n",
      "1H RAIN (MM)    0\n",
      "WSINS (KT)      0\n",
      "RSL             0\n",
      "Refrence        0\n",
      "dB              0\n",
      "dB/km           0\n",
      "dtype: int64\n",
      "Record size: 39045\n",
      "['MOR_1A', 'TEMP (ｰC)', 'RH (%)', 'PAINS (HPA)', '1H RAIN (MM)', 'WSINS (KT)', 'RSL', 'Refrence', 'dB', 'dB/km']\n",
      "                      MOR_1A TEMP (ｰC) RH (%) PAINS (HPA) 1H RAIN (MM)  \\\n",
      "History file UTC Time                                                    \n",
      "2014-06-01 21:00:00     4400      36.2     23       962.7            0   \n",
      "2014-06-01 21:01:00     4500      36.1     23       962.7            0   \n",
      "2014-06-01 21:02:00     4600      36.1     23       962.7            0   \n",
      "2014-06-01 21:03:00     4600      36.1     23       962.8            0   \n",
      "2014-06-01 21:04:00     4700      36.1     23       962.8            0   \n",
      "\n",
      "                       WSINS (KT)   RSL  Refrence   dB     dB/km  \n",
      "History file UTC Time                                             \n",
      "2014-06-01 21:00:00          5.64 -46.1     -43.8  2.3  0.821429  \n",
      "2014-06-01 21:01:00          5.25 -46.1     -43.8  2.3  0.821429  \n",
      "2014-06-01 21:02:00          4.47 -46.1     -43.8  2.3  0.821429  \n",
      "2014-06-01 21:03:00          4.28 -46.1     -43.8  2.3  0.821429  \n",
      "2014-06-01 21:04:00          5.25 -46.1     -43.8  2.3  0.821429  \n",
      "Index(['MOR_1A', 'TEMP (ｰC)', 'RH (%)', 'PAINS (HPA)', '1H RAIN (MM)',\n",
      "       'WSINS (KT)', 'RSL', 'Refrence', 'dB', 'dB/km'],\n",
      "      dtype='object')\n",
      "MOR_1A          0\n",
      "TEMP (ｰC)       0\n",
      "RH (%)          0\n",
      "PAINS (HPA)     0\n",
      "1H RAIN (MM)    0\n",
      "WSINS (KT)      0\n",
      "RSL             0\n",
      "Refrence        0\n",
      "dB              0\n",
      "dB/km           0\n",
      "dtype: int64\n",
      "                    MOR_1A TEMP (ｰC) RH (%) PAINS (HPA)  WSINS (KT)\n",
      "HistoryfileUTCTime                                                 \n",
      "2014-06-01 21:00:00   4400      36.2     23       962.7        5.64\n",
      "2014-06-01 21:01:00   4500      36.1     23       962.7        5.25\n",
      "2014-06-01 21:02:00   4600      36.1     23       962.7        4.47\n",
      "2014-06-01 21:03:00   4600      36.1     23       962.8        4.28\n",
      "2014-06-01 21:04:00   4700      36.1     23       962.8        5.25\n",
      "<bound method DataFrame.count of                     MOR_1A TEMP (ｰC) RH (%) PAINS (HPA)  WSINS (KT)\n",
      "HistoryfileUTCTime                                                 \n",
      "2014-06-01 21:00:00   4400      36.2     23       962.7        5.64\n",
      "2014-06-01 21:01:00   4500      36.1     23       962.7        5.25\n",
      "2014-06-01 21:02:00   4600      36.1     23       962.7        4.47\n",
      "2014-06-01 21:03:00   4600      36.1     23       962.8        4.28\n",
      "2014-06-01 21:04:00   4700      36.1     23       962.8        5.25\n",
      "...                    ...       ...    ...         ...         ...\n",
      "2014-07-02 07:25:00  10000      34.1     39       965.9       15.36\n",
      "2014-07-02 07:26:00  10000      34.2     39         966       20.22\n",
      "2014-07-02 07:27:00  10000      34.3     39       966.1       12.44\n",
      "2014-07-02 07:28:00  10000      34.5     38         966       22.16\n",
      "2014-07-02 07:29:00  10000      34.4     39       965.9       17.88\n",
      "\n",
      "[39045 rows x 5 columns]>\n",
      "MOR_1A         0\n",
      "TEMP (ｰC)      0\n",
      "RH (%)         0\n",
      "PAINS (HPA)    0\n",
      "WSINS (KT)     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, Normalizer\n",
    "\n",
    "read_file=['v002_data_.csv',\n",
    "            'previous_1.csv',\n",
    "            'previous_1_zeros.csv',\n",
    "            'previous_1_filtered.csv',\n",
    "]\n",
    "selected_file = read_file[1]\n",
    "\n",
    "\n",
    "# Örnek veri kümesini oku\n",
    "#data = pd.read_csv('v002_data_.csv', delimiter=\";\", index_col=0, skip_blank_lines=True)\n",
    "#data = pd.read_csv('previous_1.csv', delimiter=\";\", index_col=0, skip_blank_lines=True)\n",
    "#data = pd.read_csv('previous_1_zeros.csv', delimiter=\";\", index_col=0, skip_blank_lines=True)\n",
    "\n",
    "data = pd.read_csv(selected_file, delimiter=\";\", index_col=0, skip_blank_lines=True)\n",
    "\n",
    "print(data.isna().sum())  \n",
    "\n",
    "\n",
    "# Sütun adlarını temizleme\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Virgülleri noktalarla değiştirme\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':  # Eğer veri türü nesne (string) ise\n",
    "        data[col] = data[col].str.replace(',', '.').astype(float, errors='ignore')\n",
    "        \n",
    "data = data.replace(' ', np.nan)\n",
    "\n",
    "print(data['WSINS (KT)'])\n",
    "\n",
    "# WSINS (KT) sütunundaki veriyi sayısal tipe dönüştürme\n",
    "data['WSINS (KT)'] = data['WSINS (KT)'].str.replace(',', '.').astype(float, errors='ignore')\n",
    "\n",
    "# Eksik olan veriyi doğrusal enterpolasyon ile doldurma\n",
    "data['WSINS (KT)'] = data['WSINS (KT)'].interpolate(method='linear', inplace=False)\n",
    "\n",
    "data = data.dropna()     \n",
    "\n",
    "\n",
    "print(data.isna().sum())  \n",
    "   \n",
    "        \n",
    "        \n",
    "# Zaman damgalarını datetime formatına dönüştürme\n",
    "data.index = pd.to_datetime(data.index, format='%d.%m.%Y %H:%M')\n",
    "\n",
    "\n",
    "# İlk birkaç satırı görüntüle\n",
    "print(f'Record size: {data.__len__()}')\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# İlk birkaç satırı görüntüle\n",
    "print(data.head())\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "# Boş değerleri kontrol etme\n",
    "print(data.isnull().sum())  # Hangi sütunlarda eksik veri olduğunu gösterir\n",
    "\n",
    "# Tarih/zaman sütunlarını sayısal verilere dönüştürme\n",
    "data['HistoryfileUTCTime'] = pd.to_datetime(data.index)  # Eğer tarih/zaman verileri indeks olarak varsa\n",
    "# Tarih/saat sütununu indeks olarak ayarla\n",
    "data.set_index('HistoryfileUTCTime', inplace=True)\n",
    "\n",
    " \n",
    "\n",
    "# Tarih/zaman sütununu X'ten çıkarın ve sadece sayısal verileri kullanın\n",
    "#X = data.drop(['dB/km', 'HistoryfileUTCTime','1H RAIN(MM)','Refrence','RSL', 'dB'], axis=1)\n",
    "#X = data.drop(['dB/km', 'Refrence','1H RAIN (MM)','WSINS (KT)','RSL', 'dB'], axis=1)\n",
    "X = data.drop(['dB/km', 'Refrence','1H RAIN (MM)' ,'RSL', 'dB'], axis=1)\n",
    "y = data['dB/km']\n",
    "\n",
    "\n",
    "print(X.head()) \n",
    "print(X.count) \n",
    "print(X.isnull().sum())  # Hangi sütunlarda eksik veri olduğunu gösterir\n",
    "\n",
    "\n",
    "\n",
    "# Veriyi numpy array'e çevirme (eğer DataFrame ise)\n",
    "X = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "y = y.to_numpy() if isinstance(y, pd.DataFrame) else y\n",
    "\n",
    "\n",
    "\n",
    "select_norm=['StandardScaler', 'MinMaxScaler', 'RobustScaler', 'MaxAbsScaler', 'Normalizer']\n",
    "selected_norm = select_norm[0]\n",
    "# Veriyi normalize etme\n",
    "if selected_norm == 'StandardScaler':\n",
    "    # Skaler Normalizasyon\n",
    "    scaler = StandardScaler()\n",
    "elif selected_norm == 'MinMaxScaler':\n",
    "    # MinMaxScaler Normalizasyon\n",
    "    scaler = MinMaxScaler()\n",
    "elif selected_norm == 'MaxAbsScale':\n",
    "    # MaxAbsScaler ile veriyi normalize etme\n",
    "    scaler = MaxAbsScaler()\n",
    "elif selected_norm == 'Normalizerr':\n",
    "    # Normalizer ile veriyi normalize etme\n",
    "    scaler = Normalizer()\n",
    "elif selected_norm == 'RobustScaler':\n",
    "    # RobustScaler ile veriyi normalize etme\n",
    "    scaler = RobustScaler()\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    StandardScaler: Veriyi ortalama 0 ve standart sapma 1 olacak şekilde normalize eder.\n",
    "    MinMaxScaler: Veriyi belirli bir aralığa (genellikle 0 ile 1) dönüştürür.\n",
    "    RobustScaler: Aykırı değerlere karşı dayanıklıdır, medyan ve IQR kullanır.\n",
    "    MaxAbsScaler: Veriyi mutlak maksimum değere böler, genellikle negatif değerler için kullanılır.\n",
    "    Normalizer: Her veri örneğini belirli bir norm ile böler, veri örneklerinin normunu 1 yapar.\n",
    "    \"\"\"\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hibrit Model Kodu (XGBoost + LSTM-GRU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "# Define parameter ranges\n",
    "\"\"\"n_estimators_list = [100, 200, 300]\n",
    "learning_rate_list = [0.01, 0.1, 0.2]\n",
    "max_depth_list = [6, 8, 10, 12]\n",
    "subsample_list = [0.7, 0.8, 0.9]\n",
    "colsample_bytree_list = [0.7, 0.8, 0.9]\"\"\"\n",
    "n_estimators_list = [200]\n",
    "learning_rate_list = [0.1]\n",
    "max_depth_list = [10]\n",
    "subsample_list = [0.8]\n",
    "colsample_bytree_list = [0.8]\n",
    "\n",
    "# Create parameter combinations\n",
    "param_combinations = list(product(n_estimators_list, learning_rate_list, max_depth_list, subsample_list, colsample_bytree_list))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Define the batch size, unit sizes, and dropout sizes\n",
    "batch_sizes = [64]\n",
    "unit_sizes = [64]\n",
    "dropout_sizes = [0.2]\n",
    "\n",
    "model_n = 'Ensemble_XGBoost_LSTM_GRU'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder_main = f'models_exp/{model_n}'\n",
    "os.makedirs(folder_main, exist_ok=True)\n",
    "\n",
    "# Results list to store performance metrics\n",
    "results = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for unit_size in unit_sizes:\n",
    "        for dropout_size in dropout_sizes:\n",
    "            for params in param_combinations:\n",
    "                n_estimators, learning_rate, max_depth, subsample, colsample_bytree = params\n",
    "                \n",
    "                fold_no = 1\n",
    "                all_fold_histories = []\n",
    "                fold_results = []\n",
    "\n",
    "                kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "                for train_index, val_index in kf.split(X_train):\n",
    "                    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                    # XGBoost model\n",
    "                    xgb_model = xgb.XGBRegressor(\n",
    "                        n_estimators=n_estimators,\n",
    "                        learning_rate=learning_rate,\n",
    "                        max_depth=max_depth,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree\n",
    "                    )\n",
    "                    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "                    X_train_fold_transformed = xgb_model.predict(X_train_fold).reshape(-1, 1)\n",
    "                    X_val_fold_transformed = xgb_model.predict(X_val_fold).reshape(-1, 1)\n",
    "                    X_test_transformed = xgb_model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "                    # Reshape the data for LSTM-GRU\n",
    "                    X_train_fold_transformed = np.array(X_train_fold_transformed).reshape((X_train_fold_transformed.shape[0], X_train_fold_transformed.shape[1], 1))\n",
    "                    X_val_fold_transformed = np.array(X_val_fold_transformed).reshape((X_val_fold_transformed.shape[0], X_val_fold_transformed.shape[1], 1))\n",
    "                    X_test_transformed = np.array(X_test_transformed).reshape((X_test_transformed.shape[0], X_test_transformed.shape[1], 1))\n",
    "\n",
    "                    # Define the LSTM-GRU model\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(units=unit_size, activation='tanh', input_shape=(X_train_fold_transformed.shape[1], X_train_fold_transformed.shape[2]), return_sequences=True))\n",
    "                    model.add(Dropout(dropout_size))\n",
    "                    model.add(GRU(units=unit_size, activation='tanh', return_sequences=True))\n",
    "                    model.add(Dropout(dropout_size))\n",
    "                    model.add(Flatten())\n",
    "                    model.add(Dense(100, activation='relu'))\n",
    "                    model.add(Dropout(dropout_size))\n",
    "                    model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "                    # Compile the model\n",
    "                    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "\n",
    "                    # Train the model\n",
    "                    history = model.fit(X_train_fold_transformed, y_train_fold, validation_data=(X_val_fold_transformed, y_val_fold), epochs=100, batch_size=batch_size)\n",
    "\n",
    "                    # Store fold history\n",
    "                    all_fold_histories.append(history.history)\n",
    "\n",
    "                    # Calculate RMSE for training, validation, and test sets\n",
    "                    train_rmse = np.sqrt(history.history['mse'][-1])\n",
    "                    val_rmse = np.sqrt(history.history['val_mse'][-1])\n",
    "\n",
    "                    test_results = model.evaluate(X_test_transformed, y_test, verbose=0)\n",
    "                    test_rmse = np.sqrt(test_results[2])\n",
    "\n",
    "                    # Store fold results\n",
    "                    fold_results.append({\n",
    "                        'Fold': fold_no,\n",
    "                        'Training Size': len(X_train_fold),\n",
    "                        'Validation Size': len(X_val_fold),\n",
    "                        'Test Size': len(X_test_transformed),\n",
    "                        'Training Loss': history.history['loss'][-1],\n",
    "                        'Validation Loss': history.history['val_loss'][-1],\n",
    "                        'Training MAE': history.history['mae'][-1],\n",
    "                        'Validation MAE': history.history['val_mae'][-1],\n",
    "                        'Training MSE': history.history['mse'][-1],\n",
    "                        'Validation MSE': history.history['val_mse'][-1],\n",
    "                        'Test Loss': test_results[0],\n",
    "                        'Test MAE': test_results[1],\n",
    "                        'Test MSE': test_results[2],\n",
    "                        'Training RMSE': train_rmse,\n",
    "                        'Validation RMSE': val_rmse,\n",
    "                        'Test RMSE': test_rmse,\n",
    "                    })\n",
    "\n",
    "                    fold_no += 1\n",
    "\n",
    "                # Average fold histories\n",
    "                average_history = {\n",
    "                    'Epoch': np.arange(1, 101),\n",
    "                    'Loss': np.mean(np.array([h['loss'] for h in all_fold_histories]).T, axis=1),\n",
    "                    'Val_Loss': np.mean(np.array([h['val_loss'] for h in all_fold_histories]).T, axis=1),\n",
    "                    'MAE': np.mean(np.array([h['mae'] for h in all_fold_histories]).T, axis=1),\n",
    "                    'Val_MAE': np.mean(np.array([h['val_mae'] for h in all_fold_histories]).T, axis=1),\n",
    "                    'MSE': np.mean(np.array([h['mse'] for h in all_fold_histories]).T, axis=1),\n",
    "                    'Val_MSE': np.mean(np.array([h['val_mse'] for h in all_fold_histories]).T, axis=1),\n",
    "                }\n",
    "\n",
    "                # Average fold results\n",
    "                average_fold_results = {\n",
    "                    'Training Size': len(X_train_fold),\n",
    "                    'Validation Size': len(X_val_fold),\n",
    "                    'Test Size': len(X_test_transformed),\n",
    "                    'Average Training Loss': np.mean([result['Training Loss'] for result in fold_results if not np.isnan(result['Training Loss'])]),\n",
    "                    'Average Validation Loss': np.mean([result['Validation Loss'] for result in fold_results if not np.isnan(result['Validation Loss'])]),\n",
    "                    'Average Test Loss': np.mean([result['Test Loss'] for result in fold_results if not np.isnan(result['Test Loss'])]),\n",
    "                    'Average Training MAE': np.mean([result['Training MAE'] for result in fold_results if not np.isnan(result['Training MAE'])]),\n",
    "                    'Average Validation MAE': np.mean([result['Validation MAE'] for result in fold_results if not np.isnan(result['Validation MAE'])]),\n",
    "                    'Average Test MAE': np.mean([result['Test MAE'] for result in fold_results if not np.isnan(result['Test MAE'])]),\n",
    "                    'Average Training MSE': np.mean([result['Training MSE'] for result in fold_results if not np.isnan(result['Training MSE'])]),\n",
    "                    'Average Validation MSE': np.mean([result['Validation MSE'] for result in fold_results if not np.isnan(result['Validation MSE'])]),\n",
    "                    'Average Test MSE': np.mean([result['Test MSE'] for result in fold_results if not np.isnan(result['Test MSE'])]),\n",
    "                    'Average Training RMSE': np.mean([result['Training RMSE'] for result in fold_results if not np.isnan(result['Training RMSE'])]),\n",
    "                    'Average Validation RMSE': np.mean([result['Validation RMSE'] for result in fold_results if not np.isnan(result['Validation RMSE'])]),\n",
    "                    'Average Test RMSE': np.mean([result['Test RMSE'] for result in fold_results if not np.isnan(result['Test RMSE'])]),\n",
    "                }\n",
    "\n",
    "                # Store the results\n",
    "                results.append({\n",
    "                    'Params': params,\n",
    "                    'Average Training Loss': average_fold_results['Average Training Loss'],\n",
    "                    'Average Validation Loss': average_fold_results['Average Validation Loss'],\n",
    "                    'Average Test Loss': average_fold_results['Average Test Loss'],\n",
    "                    'Average Training MAE': average_fold_results['Average Training MAE'],\n",
    "                    'Average Validation MAE': average_fold_results['Average Validation MAE'],\n",
    "                    'Average Test MAE': average_fold_results['Average Test MAE'],\n",
    "                    'Average Training MSE': average_fold_results['Average Training MSE'],\n",
    "                    'Average Validation MSE': average_fold_results['Average Validation MSE'],\n",
    "                    'Average Test MSE': average_fold_results['Average Test MSE'],\n",
    "                    'Average Training RMSE': average_fold_results['Average Training RMSE'],\n",
    "                    'Average Validation RMSE': average_fold_results['Average Validation RMSE'],\n",
    "                    'Average Test RMSE': average_fold_results['Average Test RMSE'],\n",
    "                })\n",
    "\n",
    "                # Save results to Excel\n",
    "                results_df = pd.DataFrame(results)\n",
    "                results_df.to_excel(os.path.join(folder_main, f'{model_n}_{timestamp}_results.xlsx'), index=False)\n",
    "\n",
    "print(\"Model eğitimi ve değerlendirmesi tamamlandı.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_33640\\28345785.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "495/495 [==============================] - 4s 3ms/step - loss: 0.0198 - mae: 0.0863 - mse: 0.0198 - val_loss: 0.0042 - val_mae: 0.0305 - val_mse: 0.0042\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0446 - mse: 0.0036 - val_loss: 0.0044 - val_mae: 0.0326 - val_mse: 0.0044\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0392 - mse: 0.0028 - val_loss: 0.0042 - val_mae: 0.0297 - val_mse: 0.0042\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0367 - mse: 0.0024 - val_loss: 0.0044 - val_mae: 0.0335 - val_mse: 0.0044\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0355 - mse: 0.0023 - val_loss: 0.0043 - val_mae: 0.0304 - val_mse: 0.0043\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0334 - mse: 0.0020 - val_loss: 0.0044 - val_mae: 0.0343 - val_mse: 0.0044\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0312 - mse: 0.0018 - val_loss: 0.0043 - val_mae: 0.0299 - val_mse: 0.0043\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0017 - val_loss: 0.0042 - val_mae: 0.0298 - val_mse: 0.0042\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015 - val_loss: 0.0044 - val_mae: 0.0332 - val_mse: 0.0044\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0266 - mse: 0.0015 - val_loss: 0.0044 - val_mae: 0.0339 - val_mse: 0.0044\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 3s 3ms/step - loss: 0.0201 - mae: 0.0866 - mse: 0.0201 - val_loss: 0.0057 - val_mae: 0.0298 - val_mse: 0.0057\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0036 - mae: 0.0450 - mse: 0.0036 - val_loss: 0.0056 - val_mae: 0.0303 - val_mse: 0.0056\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0029 - mae: 0.0407 - mse: 0.0029 - val_loss: 0.0056 - val_mae: 0.0297 - val_mse: 0.0056\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - val_loss: 0.0056 - val_mae: 0.0309 - val_mse: 0.0056\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0380 - val_mse: 0.0062\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0351 - mse: 0.0023 - val_loss: 0.0056 - val_mae: 0.0314 - val_mse: 0.0056\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0315 - mse: 0.0018 - val_loss: 0.0058 - val_mae: 0.0355 - val_mse: 0.0058\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0017 - val_loss: 0.0056 - val_mae: 0.0307 - val_mse: 0.0056\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0283 - mse: 0.0016 - val_loss: 0.0056 - val_mae: 0.0307 - val_mse: 0.0056\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0260 - mse: 0.0014 - val_loss: 0.0056 - val_mae: 0.0299 - val_mse: 0.0056\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 3s 3ms/step - loss: 0.0203 - mae: 0.0863 - mse: 0.0203 - val_loss: 0.0048 - val_mae: 0.0330 - val_mse: 0.0048\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0038 - mae: 0.0466 - mse: 0.0038 - val_loss: 0.0047 - val_mae: 0.0309 - val_mse: 0.0047\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0030 - mae: 0.0415 - mse: 0.0030 - val_loss: 0.0048 - val_mae: 0.0322 - val_mse: 0.0048\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0027 - mae: 0.0387 - mse: 0.0027 - val_loss: 0.0049 - val_mae: 0.0332 - val_mse: 0.0049\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0366 - mse: 0.0025 - val_loss: 0.0047 - val_mae: 0.0316 - val_mse: 0.0047\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0344 - mse: 0.0022 - val_loss: 0.0048 - val_mae: 0.0308 - val_mse: 0.0048\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0315 - mse: 0.0019 - val_loss: 0.0049 - val_mae: 0.0349 - val_mse: 0.0049\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0299 - mse: 0.0017 - val_loss: 0.0048 - val_mae: 0.0326 - val_mse: 0.0048\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015 - val_loss: 0.0052 - val_mae: 0.0350 - val_mse: 0.0052\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0266 - mse: 0.0015 - val_loss: 0.0047 - val_mae: 0.0308 - val_mse: 0.0047\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 4s 3ms/step - loss: 0.0182 - mae: 0.0804 - mse: 0.0182 - val_loss: 0.0063 - val_mae: 0.0325 - val_mse: 0.0063\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0031 - mae: 0.0420 - mse: 0.0031 - val_loss: 0.0064 - val_mae: 0.0339 - val_mse: 0.0064\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0379 - mse: 0.0025 - val_loss: 0.0065 - val_mae: 0.0348 - val_mse: 0.0065\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0364 - mse: 0.0024 - val_loss: 0.0064 - val_mae: 0.0343 - val_mse: 0.0064\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0021 - val_loss: 0.0068 - val_mae: 0.0411 - val_mse: 0.0068\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0329 - mse: 0.0020 - val_loss: 0.0067 - val_mae: 0.0363 - val_mse: 0.0067\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0308 - mse: 0.0018 - val_loss: 0.0066 - val_mae: 0.0355 - val_mse: 0.0066\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0304 - mse: 0.0018 - val_loss: 0.0064 - val_mae: 0.0336 - val_mse: 0.0064\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0015 - val_loss: 0.0063 - val_mae: 0.0317 - val_mse: 0.0063\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0264 - mse: 0.0014 - val_loss: 0.0063 - val_mae: 0.0320 - val_mse: 0.0063\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 3s 3ms/step - loss: 0.0196 - mae: 0.0841 - mse: 0.0196 - val_loss: 0.0064 - val_mae: 0.0343 - val_mse: 0.0064\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0433 - mse: 0.0034 - val_loss: 0.0065 - val_mae: 0.0355 - val_mse: 0.0065\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0027 - mae: 0.0390 - mse: 0.0027 - val_loss: 0.0064 - val_mae: 0.0308 - val_mse: 0.0064\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0361 - mse: 0.0024 - val_loss: 0.0065 - val_mae: 0.0320 - val_mse: 0.0065\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0351 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0312 - val_mse: 0.0063\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0328 - mse: 0.0020 - val_loss: 0.0063 - val_mae: 0.0332 - val_mse: 0.0063\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0310 - mse: 0.0018 - val_loss: 0.0064 - val_mae: 0.0330 - val_mse: 0.0064\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0306 - mse: 0.0018 - val_loss: 0.0063 - val_mae: 0.0310 - val_mse: 0.0063\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0282 - mse: 0.0016 - val_loss: 0.0063 - val_mae: 0.0316 - val_mse: 0.0063\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0266 - mse: 0.0014 - val_loss: 0.0070 - val_mae: 0.0352 - val_mse: 0.0070\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 3s 3ms/step - loss: 0.0194 - mae: 0.0859 - mse: 0.0194 - val_loss: 0.0033 - val_mae: 0.0305 - val_mse: 0.0033\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0037 - mae: 0.0460 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0326 - val_mse: 0.0035\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0030 - mae: 0.0412 - mse: 0.0030 - val_loss: 0.0035 - val_mae: 0.0326 - val_mse: 0.0035\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0387 - mse: 0.0028 - val_loss: 0.0034 - val_mae: 0.0309 - val_mse: 0.0034\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0361 - mse: 0.0023 - val_loss: 0.0034 - val_mae: 0.0307 - val_mse: 0.0034\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0342 - mse: 0.0021 - val_loss: 0.0033 - val_mae: 0.0292 - val_mse: 0.0033\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0322 - mse: 0.0019 - val_loss: 0.0033 - val_mae: 0.0292 - val_mse: 0.0033\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0294 - mse: 0.0017 - val_loss: 0.0033 - val_mae: 0.0296 - val_mse: 0.0033\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0015 - val_loss: 0.0035 - val_mae: 0.0301 - val_mse: 0.0035\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0262 - mse: 0.0015 - val_loss: 0.0035 - val_mae: 0.0317 - val_mse: 0.0035\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 3s 3ms/step - loss: 0.0200 - mae: 0.0835 - mse: 0.0200 - val_loss: 0.0047 - val_mae: 0.0297 - val_mse: 0.0047\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0031 - mae: 0.0420 - mse: 0.0031 - val_loss: 0.0047 - val_mae: 0.0296 - val_mse: 0.0047\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0380 - mse: 0.0026 - val_loss: 0.0048 - val_mae: 0.0316 - val_mse: 0.0048\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0365 - mse: 0.0024 - val_loss: 0.0047 - val_mae: 0.0293 - val_mse: 0.0047\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0348 - mse: 0.0022 - val_loss: 0.0048 - val_mae: 0.0317 - val_mse: 0.0048\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0329 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0293 - val_mse: 0.0047\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0315 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0299 - val_mse: 0.0047\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0017 - val_loss: 0.0048 - val_mae: 0.0316 - val_mse: 0.0048\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0015 - val_loss: 0.0055 - val_mae: 0.0422 - val_mse: 0.0055\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0269 - mse: 0.0015 - val_loss: 0.0050 - val_mae: 0.0351 - val_mse: 0.0050\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 4s 3ms/step - loss: 0.0209 - mae: 0.0869 - mse: 0.0209 - val_loss: 0.0074 - val_mae: 0.0350 - val_mse: 0.0074\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0036 - mae: 0.0455 - mse: 0.0036 - val_loss: 0.0071 - val_mae: 0.0317 - val_mse: 0.0071\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0030 - mae: 0.0407 - mse: 0.0030 - val_loss: 0.0071 - val_mae: 0.0318 - val_mse: 0.0071\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0026 - val_loss: 0.0071 - val_mae: 0.0311 - val_mse: 0.0071\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0024 - mae: 0.0362 - mse: 0.0024 - val_loss: 0.0072 - val_mae: 0.0315 - val_mse: 0.0072\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0339 - mse: 0.0021 - val_loss: 0.0074 - val_mae: 0.0349 - val_mse: 0.0074\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0321 - mse: 0.0020 - val_loss: 0.0073 - val_mae: 0.0347 - val_mse: 0.0073\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0017 - val_loss: 0.0070 - val_mae: 0.0309 - val_mse: 0.0070\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0015 - val_loss: 0.0076 - val_mae: 0.0401 - val_mse: 0.0076\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0265 - mse: 0.0015 - val_loss: 0.0071 - val_mae: 0.0314 - val_mse: 0.0071\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 3s 3ms/step - loss: 0.0212 - mae: 0.0867 - mse: 0.0212 - val_loss: 0.0062 - val_mae: 0.0319 - val_mse: 0.0062\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0035 - mae: 0.0445 - mse: 0.0035 - val_loss: 0.0061 - val_mae: 0.0318 - val_mse: 0.0061\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0402 - mse: 0.0028 - val_loss: 0.0063 - val_mae: 0.0313 - val_mse: 0.0063\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0379 - mse: 0.0025 - val_loss: 0.0067 - val_mae: 0.0359 - val_mse: 0.0067\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0352 - val_mse: 0.0061\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0337 - mse: 0.0021 - val_loss: 0.0060 - val_mae: 0.0334 - val_mse: 0.0060\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0019 - val_loss: 0.0061 - val_mae: 0.0345 - val_mse: 0.0061\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0017 - val_loss: 0.0061 - val_mae: 0.0310 - val_mse: 0.0061\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0015 - val_loss: 0.0061 - val_mae: 0.0308 - val_mse: 0.0061\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0013 - val_loss: 0.0060 - val_mae: 0.0309 - val_mse: 0.0060\n",
      "Epoch 1/10\n",
      "495/495 [==============================] - 3s 3ms/step - loss: 0.0203 - mae: 0.0878 - mse: 0.0203 - val_loss: 0.0063 - val_mae: 0.0306 - val_mse: 0.0063\n",
      "Epoch 2/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0035 - mae: 0.0447 - mse: 0.0035 - val_loss: 0.0062 - val_mae: 0.0305 - val_mse: 0.0062\n",
      "Epoch 3/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0029 - mae: 0.0402 - mse: 0.0029 - val_loss: 0.0059 - val_mae: 0.0304 - val_mse: 0.0059\n",
      "Epoch 4/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0025 - mae: 0.0372 - mse: 0.0025 - val_loss: 0.0059 - val_mae: 0.0304 - val_mse: 0.0059\n",
      "Epoch 5/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0352 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0316 - val_mse: 0.0058\n",
      "Epoch 6/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0339 - mse: 0.0021 - val_loss: 0.0060 - val_mae: 0.0361 - val_mse: 0.0060\n",
      "Epoch 7/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0319 - mse: 0.0019 - val_loss: 0.0060 - val_mae: 0.0310 - val_mse: 0.0060\n",
      "Epoch 8/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0303 - mse: 0.0018 - val_loss: 0.0060 - val_mae: 0.0343 - val_mse: 0.0060\n",
      "Epoch 9/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0280 - mse: 0.0016 - val_loss: 0.0058 - val_mae: 0.0323 - val_mse: 0.0058\n",
      "Epoch 10/10\n",
      "495/495 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0267 - mse: 0.0015 - val_loss: 0.0058 - val_mae: 0.0321 - val_mse: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Length mismatch in RMSE data.\n",
      "Epoch length: 100\n",
      "Train RMSE length: 10\n",
      "Val RMSE length: 10\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'models_exp/Ensemble_XGBoost_LSTM_GRU/xgb_lstm_gru_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 193\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Sonuçları DataFrame'e dönüştür ve kaydet\u001b[39;00m\n\u001b[0;32m    192\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m--> 193\u001b[0m \u001b[43mresults_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder_main\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/xgb_lstm_gru_results.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\kadir\\kadir\\eltahir\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\kadir\\kadir\\eltahir\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\kadir\\kadir\\eltahir\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\kadir\\kadir\\eltahir\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'models_exp/Ensemble_XGBoost_LSTM_GRU/xgb_lstm_gru_results.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\"\"\"n_estimators_list = [100, 200, 300]\n",
    "learning_rate_list = [0.01, 0.1, 0.2]\n",
    "max_depth_list = [6, 8, 10, 12]\n",
    "subsample_list = [0.7, 0.8, 0.9]\n",
    "colsample_bytree_list = [0.7, 0.8, 0.9]\"\"\"\n",
    "n_estimators_list = [200]\n",
    "learning_rate_list = [0.1]\n",
    "max_depth_list = [12]\n",
    "subsample_list = [0.8]\n",
    "colsample_bytree_list = [0.8]\n",
    "\n",
    "# Create parameter combinations\n",
    "param_combinations = list(product(n_estimators_list, learning_rate_list, max_depth_list, subsample_list, colsample_bytree_list))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Define the batch size, unit sizes, and dropout sizes\n",
    "batch_sizes = [64]\n",
    "unit_sizes = [64]\n",
    "dropout_sizes = [0.2]\n",
    "\n",
    "model_n = 'Ensemble_XGBoost_LSTM_GRU'\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder_main = f'models_exp/{model_n}'\n",
    "os.makedirs(folder_main, exist_ok=True)\n",
    "\n",
    "# Results list to store performance metrics\n",
    "results = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for unit_size in unit_sizes:\n",
    "        for dropout_size in dropout_sizes:\n",
    "            for params in param_combinations:\n",
    "                n_estimators, learning_rate, max_depth, subsample, colsample_bytree = params\n",
    "                \n",
    "                fold_no = 1\n",
    "                all_fold_histories = []\n",
    "                fold_results = []\n",
    "\n",
    "                kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "                for train_index, val_index in kf.split(X_train):\n",
    "                    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                    # XGBoost model\n",
    "                    xgb_model = xgb.XGBRegressor(\n",
    "                        n_estimators=n_estimators,\n",
    "                        learning_rate=learning_rate,\n",
    "                        max_depth=max_depth,\n",
    "                        subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree\n",
    "                    )\n",
    "                    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "                    X_train_fold_transformed = xgb_model.predict(X_train_fold).reshape(-1, 1)\n",
    "                    X_val_fold_transformed = xgb_model.predict(X_val_fold).reshape(-1, 1)\n",
    "                    X_test_transformed = xgb_model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "                    # Reshape the data\n",
    "                    X_train_fold_transformed = np.array(X_train_fold_transformed).reshape((X_train_fold_transformed.shape[0], X_train_fold_transformed.shape[1], 1))\n",
    "                    X_val_fold_transformed = np.array(X_val_fold_transformed).reshape((X_val_fold_transformed.shape[0], X_val_fold_transformed.shape[1], 1))\n",
    "                    X_test_transformed = np.array(X_test_transformed).reshape((X_test_transformed.shape[0], X_test_transformed.shape[1], 1))\n",
    "\n",
    "                    # Define the hybrid model\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(units=unit_size, activation='tanh', input_shape=(X_train_fold_transformed.shape[1], X_train_fold_transformed.shape[2]), return_sequences=True))\n",
    "                    model.add(Dropout(dropout_size))\n",
    "                    model.add(GRU(units=unit_size, activation='tanh', return_sequences=True))\n",
    "                    model.add(Dropout(dropout_size))\n",
    "                    model.add(Flatten())\n",
    "                    model.add(Dense(100, activation='relu'))\n",
    "                    model.add(Dropout(dropout_size))\n",
    "                    model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "                    # Compile the model\n",
    "                    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "\n",
    "                    # Train the model\n",
    "                    history = model.fit(X_train_fold_transformed, y_train_fold, validation_data=(X_val_fold_transformed, y_val_fold), epochs=10, batch_size=batch_size)\n",
    "\n",
    "                    # Store fold history\n",
    "                    all_fold_histories.append(history.history)\n",
    "\n",
    "                    # Calculate RMSE for training, validation, and test sets\n",
    "                    train_rmse = np.sqrt(history.history['mse'][-1])\n",
    "                    val_rmse = np.sqrt(history.history['val_mse'][-1])\n",
    "\n",
    "                    test_results = model.evaluate(X_test_transformed, y_test, verbose=0)\n",
    "                    test_rmse = np.sqrt(test_results[2])\n",
    "\n",
    "                    # Store fold results\n",
    "                    fold_results.append({\n",
    "                        'Fold': fold_no,\n",
    "                        'Training Size': len(X_train_fold_transformed),\n",
    "                        'Validation Size': len(X_val_fold_transformed),\n",
    "                        'Test Size': len(X_test_transformed),            \n",
    "                        'Training Loss': history.history['loss'][-1],\n",
    "                        'Validation Loss': history.history['val_loss'][-1],\n",
    "                        'Training MAE': history.history['mae'][-1],\n",
    "                        'Validation MAE': history.history['val_mae'][-1],\n",
    "                        'Training MSE': history.history['mse'][-1],\n",
    "                        'Validation MSE': history.history['val_mse'][-1],\n",
    "                        'Test Loss': test_results[0],\n",
    "                        'Test MAE': test_results[1],\n",
    "                        'Test MSE': test_results[2],\n",
    "                        'Training RMSE': train_rmse,\n",
    "                        'Validation RMSE': val_rmse,\n",
    "                        'Test RMSE': test_rmse,\n",
    "                        'XGBoost Params': params\n",
    "                    })\n",
    "\n",
    "                    fold_no += 1\n",
    "\n",
    "                # Tüm fold'ların sonuçlarını ortalama alma\n",
    "                if all_fold_histories:\n",
    "                    average_history = {\n",
    "                        'Epoch': np.arange(1, 101),\n",
    "                        'Loss': np.mean([h['loss'] for h in all_fold_histories], axis=0),\n",
    "                        'Val_Loss': np.mean([h['val_loss'] for h in all_fold_histories], axis=0),\n",
    "                        'MAE': np.mean([h['mae'] for h in all_fold_histories], axis=0),\n",
    "                        'Val_MAE': np.mean([h['val_mae'] for h in all_fold_histories], axis=0),\n",
    "                        'MSE': np.mean([h['mse'] for h in all_fold_histories], axis=0),\n",
    "                        'Val_MSE': np.mean([h['val_mse'] for h in all_fold_histories], axis=0),\n",
    "                    }\n",
    "\n",
    "                    # Ortalama RMSE hesaplama\n",
    "                    average_rmse = {\n",
    "                        'Epoch': average_history['Epoch'],\n",
    "                        'Train_RMSE': np.sqrt(average_history['MSE']),\n",
    "                        'Val_RMSE': np.sqrt(average_history['Val_MSE'])\n",
    "                    }\n",
    "\n",
    "                    # Ortalama fold sonuçlarını hesapla\n",
    "                    average_fold_results = {\n",
    "                        'Training Size': len(X_train_fold_transformed),\n",
    "                        'Validation Size': len(X_val_fold_transformed),\n",
    "                        'Test Size': len(X_test_transformed),  \n",
    "                        'Average Training Loss': np.mean([result['Training Loss'] for result in fold_results if not np.isnan(result['Training Loss'])]),\n",
    "                        'Average Validation Loss': np.mean([result['Validation Loss'] for result in fold_results if not np.isnan(result['Validation Loss'])]),\n",
    "                        'Average Test Loss': np.mean([result['Test Loss'] for result in fold_results if not np.isnan(result['Test Loss'])]),\n",
    "                        'Average Training MAE': np.mean([result['Training MAE'] for result in fold_results if not np.isnan(result['Training MAE'])]),\n",
    "                        'Average Validation MAE': np.mean([result['Validation MAE'] for result in fold_results if not np.isnan(result['Validation MAE'])]),\n",
    "                        'Average Test MAE': np.mean([result['Test MAE'] for result in fold_results if not np.isnan(result['Test MAE'])]),\n",
    "                        'Average Training MSE': np.mean([result['Training MSE'] for result in fold_results if not np.isnan(result['Training MSE'])]),\n",
    "                        'Average Validation MSE': np.mean([result['Validation MSE'] for result in fold_results if not np.isnan(result['Validation MSE'])]),\n",
    "                        'Average Test MSE': np.mean([result['Test MSE'] for result in fold_results if not np.isnan(result['Test MSE'])]),\n",
    "                        'Average Training RMSE': np.mean([result['Training RMSE'] for result in fold_results if not np.isnan(result['Training RMSE'])]),\n",
    "                        'Average Validation RMSE': np.mean([result['Validation RMSE'] for result in fold_results if not np.isnan(result['Validation RMSE'])]),\n",
    "                        'Average Test RMSE': np.mean([result['Test RMSE'] for result in fold_results if not np.isnan(result['Test RMSE'])]),\n",
    "                        'XGBoost Params': params\n",
    "                    }\n",
    "\n",
    "                    # Sonuçları sakla\n",
    "                    results.append(average_fold_results)\n",
    "\n",
    "                    # Performans grafiklerini kaydet\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "\n",
    "                    # Grafik çizimi sırasında uzunluk kontrolü ekleyin\n",
    "                    if len(average_rmse['Epoch']) == len(average_rmse['Train_RMSE']) and len(average_rmse['Epoch']) == len(average_rmse['Val_RMSE']):\n",
    "                        plt.plot(average_rmse['Epoch'], average_rmse['Train_RMSE'], label='Training RMSE')\n",
    "                        plt.plot(average_rmse['Epoch'], average_rmse['Val_RMSE'], label='Validation RMSE')\n",
    "                    else:\n",
    "                        print(\"Warning: Length mismatch in RMSE data.\")\n",
    "                        print(f\"Epoch length: {len(average_rmse['Epoch'])}\")\n",
    "                        print(f\"Train RMSE length: {len(average_rmse['Train_RMSE'])}\")\n",
    "                        print(f\"Val RMSE length: {len(average_rmse['Val_RMSE'])}\")\n",
    "\n",
    "                    plt.title(f'{model_n} - RMSE over epochs')\n",
    "                    plt.xlabel('Epoch')\n",
    "                    plt.ylabel('RMSE')\n",
    "                    plt.legend()\n",
    "                    plt.savefig(f'{folder_main}/rmse_plot_{params[0]}_{params[1]}_{params[2]}_{params[3]}_{params[4]}.png')\n",
    "                    plt.close()\n",
    "\n",
    "# Sonuçları DataFrame'e dönüştür ve kaydet\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{folder_main}/xgb_lstm_gru_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{folder_main}/xgb_lstm_gru_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları DataFrame'e dönüştür ve kaydet\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{folder_main}/xgb_lstm_gru_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Size  Validation Size  Test Size  Average Training Loss  \\\n",
      "0          31626             3514       3905               0.001434   \n",
      "\n",
      "   Average Validation Loss  Average Test Loss  Average Training MAE  \\\n",
      "0                 0.005547           0.005105              0.026449   \n",
      "\n",
      "   Average Validation MAE  Average Test MAE  Average Training MSE  \\\n",
      "0                0.032305          0.031817              0.001434   \n",
      "\n",
      "   Average Validation MSE  Average Test MSE  Average Training RMSE  \\\n",
      "0                0.005547          0.005105               0.037858   \n",
      "\n",
      "   Average Validation RMSE  Average Test RMSE            XGBoost Params  \n",
      "0                 0.074104            0.07139  (200, 0.1, 12, 0.8, 0.8)  \n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collector from separate excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: exp_16_128_0.2_20240904_224552_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_128_0.3_20240904_230527_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_128_0.4_20240904_232541_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_128_0.5_20240904_234523_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_32_0.2_20240904_193857_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_32_0.3_20240904_195304_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_32_0.4_20240904_200719_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_32_0.5_20240904_202137_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_64_0.2_20240904_203638_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_64_0.3_20240904_205136_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_64_0.4_20240904_210634_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_64_0.5_20240904_212144_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_96_0.2_20240904_213734_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_96_0.3_20240904_215348_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_96_0.4_20240904_220947_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_16_96_0.5_20240904_222614_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_128_0.2_20240905_015212_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_128_0.3_20240905_020446_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_128_0.4_20240905_021647_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_128_0.5_20240905_022834_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_32_0.2_20240904_235322_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_32_0.3_20240905_000118_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_32_0.4_20240905_000914_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_32_0.5_20240905_001710_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_64_0.2_20240905_002612_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_64_0.3_20240905_003434_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_64_0.4_20240905_004253_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_64_0.5_20240905_005145_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_96_0.2_20240905_010239_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_96_0.3_20240905_011301_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_96_0.4_20240905_012338_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_32_96_0.5_20240905_013548_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_128_0.2_20240905_035858_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_128_0.3_20240905_041203_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_128_0.4_20240905_042511_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_128_0.5_20240905_043641_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_32_0.2_20240905_023411_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_32_0.3_20240905_024008_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_32_0.4_20240905_024549_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_32_0.5_20240905_025127_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_64_0.2_20240905_025734_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_64_0.3_20240905_030340_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_64_0.4_20240905_031008_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_64_0.5_20240905_031731_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_96_0.2_20240905_032555_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_96_0.3_20240905_033350_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_96_0.4_20240905_034144_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_48_96_0.5_20240905_034938_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_128_0.2_20240905_090020_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_128_0.3_20240905_091201_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_128_0.4_20240905_092529_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_128_0.5_20240905_093757_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_32_0.2_20240905_044117_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_32_0.2_20240905_072621_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_32_0.3_20240905_044558_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_32_0.3_20240905_073107_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_32_0.4_20240905_073730_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_32_0.5_20240905_074313_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_64_0.2_20240905_075154_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_64_0.3_20240905_075902_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_64_0.4_20240905_080535_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_64_0.5_20240905_081107_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_96_0.2_20240905_081831_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_96_0.3_20240905_082543_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_96_0.4_20240905_083307_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "Processing file: exp_64_96_0.5_20240905_084648_combined.xlsx\n",
      "Sheet: Cumulative Results - Satır sayısı: 1\n",
      "İkinci satırlar merged_output_20240905_103219.xlsx dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Klasör yolu ve hedef dosya yolu\n",
    "#folder_path = \"grid_analiz\"\n",
    "folder_path = \"models_exp/test_results\"\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_file = f\"merged_output_{timestamp}.xlsx\"\n",
    "output_sheet_name = \"Merged Results\"\n",
    "\n",
    "# Tüm Excel dosyalarının ikinci satırlarını toplamak için bir liste\n",
    "merged_data = []\n",
    "\n",
    "# Klasördeki tüm Excel dosyalarını tarama\n",
    "for file_namex in os.listdir(folder_path):\n",
    "    print(f\"Processing file: {file_namex}\")\n",
    "    \n",
    "    if file_namex.endswith(\".xlsx\") or file_namex.endswith(\".xls\"):\n",
    "        file_path = os.path.join(folder_path, file_namex)\n",
    "        file_path = file_path.replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        # Excel dosyasını oku ve her bir sheet'i tarayarak veri bul\n",
    "        try:\n",
    "            # Dosyadaki tüm sheet'lerin isimlerini al\n",
    "            xls = pd.ExcelFile(file_path)\n",
    "            sheet_found = False\n",
    "            \n",
    "            for sheet_name in xls.sheet_names:\n",
    "                df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "                print(f\"Sheet: {sheet_name} - Satır sayısı: {len(df)}\")\n",
    "\n",
    "                # Eğer sheet'te en az iki satır varsa ikinci satırı al\n",
    "                \"\"\"print(len(df))\n",
    "                print(df)\"\"\"\n",
    "                if len(df) >= 1:\n",
    "                    if not merged_data: \n",
    "                        # İlk sütuna dosya adını eklemek için sütun başlıklarını güncelle\n",
    "                        columns = df.columns.tolist()\n",
    "                        merged_data.append(columns)\n",
    "                    \n",
    "                    # 2. satırı al ve başına dosya adını ekle\n",
    "                    second_row = df.iloc[0].tolist()\n",
    "                    merged_data.append(second_row)\n",
    "                    sheet_found = True\n",
    "                    break  # Veriyi bulduktan sonra diğer sheet'leri arama\n",
    "\n",
    "            if not sheet_found:\n",
    "                print(f\"{file_namex} dosyasında yeterli veri yok, atlanıyor.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_namex}: {e}\")\n",
    "\n",
    "# Eğer `merged_data` boşsa, işlem yapmadan çıkış yap\n",
    "if not merged_data:\n",
    "    print(\"No data found. Please check the folder path or sheet names.\")\n",
    "else:\n",
    "    # Tüm verileri bir DataFrame'e dönüştür\n",
    "    merged_df = pd.DataFrame(merged_data[1:], columns=merged_data[0])\n",
    "\n",
    "    # Sonuçları tek bir Excel dosyasına yaz\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        merged_df.to_excel(writer, sheet_name=output_sheet_name, index=False)\n",
    "\n",
    "    print(f\"İkinci satırlar {output_file} dosyasına kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hibrit Model FİNAL v01 (XGBoost + LSTM-GRU) bitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 4s 4ms/step - loss: 0.0670 - mae: 0.1687 - mse: 0.0670 - val_loss: 0.0070 - val_mae: 0.0577 - val_mse: 0.0070\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0067 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0035 - val_mae: 0.0349 - val_mse: 0.0035\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0052 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0032 - val_mae: 0.0299 - val_mse: 0.0032\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0047 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0031 - val_mae: 0.0295 - val_mse: 0.0031\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0043 - mae: 0.0500 - mse: 0.0043 - val_loss: 0.0032 - val_mae: 0.0300 - val_mse: 0.0032\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0040 - mae: 0.0479 - mse: 0.0040 - val_loss: 0.0032 - val_mae: 0.0301 - val_mse: 0.0032\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0466 - mse: 0.0038 - val_loss: 0.0034 - val_mae: 0.0329 - val_mse: 0.0034\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0447 - mse: 0.0035 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0034 - mae: 0.0433 - mse: 0.0034 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0415 - mse: 0.0031 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0028 - mae: 0.0399 - mse: 0.0028 - val_loss: 0.0033 - val_mae: 0.0316 - val_mse: 0.0033\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0026 - mae: 0.0386 - mse: 0.0026 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0373 - mse: 0.0025 - val_loss: 0.0032 - val_mae: 0.0295 - val_mse: 0.0032\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0362 - mse: 0.0024 - val_loss: 0.0032 - val_mae: 0.0297 - val_mse: 0.0032\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0348 - mse: 0.0022 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0339 - mse: 0.0021 - val_loss: 0.0033 - val_mae: 0.0302 - val_mse: 0.0033\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0020 - mae: 0.0330 - mse: 0.0020 - val_loss: 0.0032 - val_mae: 0.0298 - val_mse: 0.0032\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0322 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0301 - val_mse: 0.0032\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0313 - mse: 0.0018 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0306 - mse: 0.0017 - val_loss: 0.0032 - val_mae: 0.0299 - val_mse: 0.0032\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0017 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0016 - val_loss: 0.0032 - val_mae: 0.0295 - val_mse: 0.0032\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0285 - mse: 0.0015 - val_loss: 0.0033 - val_mae: 0.0317 - val_mse: 0.0033\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0280 - mse: 0.0015 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0014 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0270 - mse: 0.0014 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0264 - mse: 0.0014 - val_loss: 0.0032 - val_mae: 0.0298 - val_mse: 0.0032\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0013 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0256 - mse: 0.0013 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0013 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0248 - mse: 0.0013 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0247 - mse: 0.0012 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0241 - mse: 0.0012 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0239 - mse: 0.0012 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0235 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0234 - mse: 0.0012 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0228 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0299 - val_mse: 0.0032\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0229 - mse: 0.0011 - val_loss: 0.0033 - val_mae: 0.0303 - val_mse: 0.0033\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0226 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0225 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0295 - val_mse: 0.0032\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0221 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0219 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0218 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0216 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0215 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0299 - val_mse: 0.0032\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0212 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0213 - mse: 0.0011 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8316e-04 - mae: 0.0209 - mse: 9.8316e-04 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0295 - val_mse: 0.0032\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0206 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8580e-04 - mae: 0.0205 - mse: 9.8580e-04 - val_loss: 0.0032 - val_mae: 0.0301 - val_mse: 0.0032\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.8907e-04 - mae: 0.0206 - mse: 9.8907e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8328e-04 - mae: 0.0205 - mse: 9.8328e-04 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8598e-04 - mae: 0.0205 - mse: 9.8598e-04 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7776e-04 - mae: 0.0205 - mse: 9.7776e-04 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7862e-04 - mae: 0.0203 - mse: 9.7862e-04 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0298 - val_mse: 0.0032\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9395e-04 - mae: 0.0205 - mse: 9.9395e-04 - val_loss: 0.0032 - val_mae: 0.0297 - val_mse: 0.0032\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6529e-04 - mae: 0.0202 - mse: 9.6529e-04 - val_loss: 0.0032 - val_mae: 0.0299 - val_mse: 0.0032\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.4327e-04 - mae: 0.0203 - mse: 9.4327e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8174e-04 - mae: 0.0202 - mse: 9.8174e-04 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6746e-04 - mae: 0.0202 - mse: 9.6746e-04 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8899e-04 - mae: 0.0202 - mse: 9.8899e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5554e-04 - mae: 0.0202 - mse: 9.5554e-04 - val_loss: 0.0032 - val_mae: 0.0295 - val_mse: 0.0032\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7393e-04 - mae: 0.0202 - mse: 9.7393e-04 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0298 - val_mse: 0.0032\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7292e-04 - mae: 0.0202 - mse: 9.7292e-04 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7867e-04 - mae: 0.0201 - mse: 9.7867e-04 - val_loss: 0.0032 - val_mae: 0.0297 - val_mse: 0.0032\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8647e-04 - mae: 0.0202 - mse: 9.8647e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.9509e-04 - mae: 0.0202 - mse: 9.9509e-04 - val_loss: 0.0031 - val_mae: 0.0293 - val_mse: 0.0031\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5110e-04 - mae: 0.0199 - mse: 9.5110e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4074e-04 - mae: 0.0200 - mse: 9.4074e-04 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5651e-04 - mae: 0.0200 - mse: 9.5651e-04 - val_loss: 0.0032 - val_mae: 0.0295 - val_mse: 0.0032\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7049e-04 - mae: 0.0202 - mse: 9.7049e-04 - val_loss: 0.0032 - val_mae: 0.0295 - val_mse: 0.0032\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7306e-04 - mae: 0.0200 - mse: 9.7306e-04 - val_loss: 0.0032 - val_mae: 0.0296 - val_mse: 0.0032\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4819e-04 - mae: 0.0200 - mse: 9.4819e-04 - val_loss: 0.0032 - val_mae: 0.0299 - val_mse: 0.0032\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7819e-04 - mae: 0.0200 - mse: 9.7819e-04 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6941e-04 - mae: 0.0199 - mse: 9.6941e-04 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8241e-04 - mae: 0.0200 - mse: 9.8241e-04 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.9528e-04 - mae: 0.0202 - mse: 9.9528e-04 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6522e-04 - mae: 0.0199 - mse: 9.6522e-04 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6579e-04 - mae: 0.0200 - mse: 9.6579e-04 - val_loss: 0.0032 - val_mae: 0.0297 - val_mse: 0.0032\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6197e-04 - mae: 0.0201 - mse: 9.6197e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6301e-04 - mae: 0.0200 - mse: 9.6301e-04 - val_loss: 0.0032 - val_mae: 0.0293 - val_mse: 0.0032\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0201 - mse: 0.0010 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7735e-04 - mae: 0.0200 - mse: 9.7735e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6491e-04 - mae: 0.0199 - mse: 9.6491e-04 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8205e-04 - mae: 0.0201 - mse: 9.8205e-04 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7672e-04 - mae: 0.0201 - mse: 9.7672e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8809e-04 - mae: 0.0200 - mse: 9.8809e-04 - val_loss: 0.0032 - val_mae: 0.0297 - val_mse: 0.0032\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6264e-04 - mae: 0.0200 - mse: 9.6264e-04 - val_loss: 0.0032 - val_mae: 0.0292 - val_mse: 0.0032\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6773e-04 - mae: 0.0199 - mse: 9.6773e-04 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3703e-04 - mae: 0.0199 - mse: 9.3703e-04 - val_loss: 0.0032 - val_mae: 0.0291 - val_mse: 0.0032\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9524e-04 - mae: 0.0202 - mse: 9.9524e-04 - val_loss: 0.0032 - val_mae: 0.0294 - val_mse: 0.0032\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "110/110 [==============================] - 0s 996us/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 6s 5ms/step - loss: 0.0576 - mae: 0.1551 - mse: 0.0576 - val_loss: 0.0078 - val_mae: 0.0572 - val_mse: 0.0078\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0062 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0043 - val_mae: 0.0346 - val_mse: 0.0043\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0048 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0042 - val_mae: 0.0331 - val_mse: 0.0042\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0043 - mae: 0.0503 - mse: 0.0043 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0474 - mse: 0.0039 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0036 - mae: 0.0455 - mse: 0.0036 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0034 - mae: 0.0439 - mse: 0.0034 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0031 - mae: 0.0424 - mse: 0.0031 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0407 - mse: 0.0029 - val_loss: 0.0042 - val_mae: 0.0326 - val_mse: 0.0042\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0027 - mae: 0.0394 - mse: 0.0027 - val_loss: 0.0041 - val_mae: 0.0323 - val_mse: 0.0041\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0379 - mse: 0.0025 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0368 - mse: 0.0024 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0347 - mse: 0.0022 - val_loss: 0.0041 - val_mae: 0.0320 - val_mse: 0.0041\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0341 - mse: 0.0021 - val_loss: 0.0041 - val_mae: 0.0316 - val_mse: 0.0041\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0328 - mse: 0.0019 - val_loss: 0.0042 - val_mae: 0.0336 - val_mse: 0.0042\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0019 - val_loss: 0.0042 - val_mae: 0.0325 - val_mse: 0.0042\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0316 - mse: 0.0018 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0311 - mse: 0.0018 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - val_loss: 0.0041 - val_mae: 0.0321 - val_mse: 0.0041\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0297 - mse: 0.0017 - val_loss: 0.0041 - val_mae: 0.0318 - val_mse: 0.0041\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0016 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0286 - mse: 0.0016 - val_loss: 0.0041 - val_mae: 0.0321 - val_mse: 0.0041\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0015 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0015 - mae: 0.0275 - mse: 0.0015 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0271 - mse: 0.0014 - val_loss: 0.0041 - val_mae: 0.0316 - val_mse: 0.0041\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0269 - mse: 0.0014 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0263 - mse: 0.0014 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0013 - val_loss: 0.0041 - val_mae: 0.0316 - val_mse: 0.0041\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0013 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0253 - mse: 0.0013 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0249 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0012 - val_loss: 0.0042 - val_mae: 0.0320 - val_mse: 0.0042\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0242 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0238 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0238 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0234 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0233 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0229 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0319 - val_mse: 0.0041\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0230 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0314 - val_mse: 0.0040\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0226 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0316 - val_mse: 0.0041\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0321 - val_mse: 0.0041\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0317 - val_mse: 0.0041\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0219 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0217 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0217 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0316 - val_mse: 0.0041\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0216 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0326 - val_mse: 0.0041\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8293e-04 - mae: 0.0211 - mse: 9.8293e-04 - val_loss: 0.0042 - val_mae: 0.0323 - val_mse: 0.0042\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9575e-04 - mae: 0.0212 - mse: 9.9575e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9167e-04 - mae: 0.0209 - mse: 9.9167e-04 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0317 - val_mse: 0.0041\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0318 - val_mse: 0.0041\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6852e-04 - mae: 0.0207 - mse: 9.6852e-04 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7049e-04 - mae: 0.0206 - mse: 9.7049e-04 - val_loss: 0.0041 - val_mae: 0.0318 - val_mse: 0.0041\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9938e-04 - mae: 0.0208 - mse: 9.9938e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9583e-04 - mae: 0.0206 - mse: 9.9583e-04 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7101e-04 - mae: 0.0206 - mse: 9.7101e-04 - val_loss: 0.0042 - val_mae: 0.0313 - val_mse: 0.0042\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6843e-04 - mae: 0.0205 - mse: 9.6843e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5577e-04 - mae: 0.0205 - mse: 9.5577e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7596e-04 - mae: 0.0205 - mse: 9.7596e-04 - val_loss: 0.0040 - val_mae: 0.0319 - val_mse: 0.0040\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8334e-04 - mae: 0.0204 - mse: 9.8334e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9167e-04 - mae: 0.0206 - mse: 9.9167e-04 - val_loss: 0.0040 - val_mae: 0.0311 - val_mse: 0.0040\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3640e-04 - mae: 0.0203 - mse: 9.3640e-04 - val_loss: 0.0040 - val_mae: 0.0311 - val_mse: 0.0040\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7808e-04 - mae: 0.0205 - mse: 9.7808e-04 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6834e-04 - mae: 0.0204 - mse: 9.6834e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9426e-04 - mae: 0.0204 - mse: 9.9426e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8794e-04 - mae: 0.0205 - mse: 9.8794e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8289e-04 - mae: 0.0205 - mse: 9.8289e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 9.4425e-04 - mae: 0.0201 - mse: 9.4425e-04 - val_loss: 0.0041 - val_mae: 0.0318 - val_mse: 0.0041\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 9.5691e-04 - mae: 0.0203 - mse: 9.5691e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5889e-04 - mae: 0.0202 - mse: 9.5889e-04 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7082e-04 - mae: 0.0203 - mse: 9.7082e-04 - val_loss: 0.0040 - val_mae: 0.0313 - val_mse: 0.0040\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9213e-04 - mae: 0.0204 - mse: 9.9213e-04 - val_loss: 0.0040 - val_mae: 0.0311 - val_mse: 0.0040\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7540e-04 - mae: 0.0203 - mse: 9.7540e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.3884e-04 - mae: 0.0202 - mse: 9.3884e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0314 - val_mse: 0.0040\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.9899e-04 - mae: 0.0205 - mse: 9.9899e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.5660e-04 - mae: 0.0202 - mse: 9.5660e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.7401e-04 - mae: 0.0202 - mse: 9.7401e-04 - val_loss: 0.0040 - val_mae: 0.0313 - val_mse: 0.0040\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4891e-04 - mae: 0.0202 - mse: 9.4891e-04 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7185e-04 - mae: 0.0202 - mse: 9.7185e-04 - val_loss: 0.0041 - val_mae: 0.0318 - val_mse: 0.0041\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6092e-04 - mae: 0.0202 - mse: 9.6092e-04 - val_loss: 0.0042 - val_mae: 0.0324 - val_mse: 0.0042\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9827e-04 - mae: 0.0204 - mse: 9.9827e-04 - val_loss: 0.0040 - val_mae: 0.0311 - val_mse: 0.0040\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6278e-04 - mae: 0.0202 - mse: 9.6278e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6029e-04 - mae: 0.0201 - mse: 9.6029e-04 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6802e-04 - mae: 0.0202 - mse: 9.6802e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8793e-04 - mae: 0.0204 - mse: 9.8793e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6159e-04 - mae: 0.0201 - mse: 9.6159e-04 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5564e-04 - mae: 0.0201 - mse: 9.5564e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3715e-04 - mae: 0.0201 - mse: 9.3715e-04 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4637e-04 - mae: 0.0202 - mse: 9.4637e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4507e-04 - mae: 0.0201 - mse: 9.4507e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0311 - val_mse: 0.0040\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 5s 4ms/step - loss: 0.0669 - mae: 0.1692 - mse: 0.0669 - val_loss: 0.0130 - val_mae: 0.0622 - val_mse: 0.0130\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0072 - mae: 0.0654 - mse: 0.0072 - val_loss: 0.0078 - val_mae: 0.0393 - val_mse: 0.0078\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0054 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0070 - val_mae: 0.0326 - val_mse: 0.0070\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0048 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0073 - val_mae: 0.0338 - val_mse: 0.0073\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0043 - mae: 0.0505 - mse: 0.0043 - val_loss: 0.0072 - val_mae: 0.0334 - val_mse: 0.0072\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0042 - mae: 0.0493 - mse: 0.0042 - val_loss: 0.0072 - val_mae: 0.0329 - val_mse: 0.0072\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0471 - mse: 0.0038 - val_loss: 0.0074 - val_mae: 0.0340 - val_mse: 0.0074\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0037 - mae: 0.0458 - mse: 0.0037 - val_loss: 0.0075 - val_mae: 0.0363 - val_mse: 0.0075\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0033 - mae: 0.0435 - mse: 0.0033 - val_loss: 0.0075 - val_mae: 0.0342 - val_mse: 0.0075\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0422 - mse: 0.0031 - val_loss: 0.0075 - val_mae: 0.0361 - val_mse: 0.0075\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0029 - mae: 0.0409 - mse: 0.0029 - val_loss: 0.0073 - val_mae: 0.0324 - val_mse: 0.0073\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0391 - mse: 0.0027 - val_loss: 0.0074 - val_mae: 0.0336 - val_mse: 0.0074\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0025 - mae: 0.0379 - mse: 0.0025 - val_loss: 0.0076 - val_mae: 0.0342 - val_mse: 0.0076\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0363 - mse: 0.0024 - val_loss: 0.0074 - val_mae: 0.0333 - val_mse: 0.0074\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0357 - mse: 0.0023 - val_loss: 0.0074 - val_mae: 0.0325 - val_mse: 0.0074\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0021 - val_loss: 0.0074 - val_mae: 0.0343 - val_mse: 0.0074\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0020 - mae: 0.0334 - mse: 0.0020 - val_loss: 0.0072 - val_mae: 0.0322 - val_mse: 0.0072\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0323 - mse: 0.0019 - val_loss: 0.0072 - val_mae: 0.0328 - val_mse: 0.0072\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0018 - mae: 0.0314 - mse: 0.0018 - val_loss: 0.0071 - val_mae: 0.0327 - val_mse: 0.0071\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0304 - mse: 0.0017 - val_loss: 0.0073 - val_mae: 0.0324 - val_mse: 0.0073\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0017 - val_loss: 0.0073 - val_mae: 0.0326 - val_mse: 0.0073\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0016 - val_loss: 0.0073 - val_mae: 0.0326 - val_mse: 0.0073\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0285 - mse: 0.0015 - val_loss: 0.0072 - val_mae: 0.0324 - val_mse: 0.0072\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0015 - val_loss: 0.0073 - val_mae: 0.0326 - val_mse: 0.0073\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0015 - val_loss: 0.0074 - val_mae: 0.0326 - val_mse: 0.0074\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0269 - mse: 0.0014 - val_loss: 0.0072 - val_mae: 0.0327 - val_mse: 0.0072\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0264 - mse: 0.0014 - val_loss: 0.0073 - val_mae: 0.0330 - val_mse: 0.0073\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0013 - val_loss: 0.0073 - val_mae: 0.0323 - val_mse: 0.0073\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0013 - val_loss: 0.0073 - val_mae: 0.0329 - val_mse: 0.0073\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0249 - mse: 0.0012 - val_loss: 0.0073 - val_mae: 0.0323 - val_mse: 0.0073\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0247 - mse: 0.0012 - val_loss: 0.0074 - val_mae: 0.0324 - val_mse: 0.0074\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0243 - mse: 0.0012 - val_loss: 0.0074 - val_mae: 0.0323 - val_mse: 0.0074\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0241 - mse: 0.0012 - val_loss: 0.0072 - val_mae: 0.0329 - val_mse: 0.0072\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0237 - mse: 0.0012 - val_loss: 0.0074 - val_mae: 0.0325 - val_mse: 0.0074\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0234 - mse: 0.0012 - val_loss: 0.0075 - val_mae: 0.0329 - val_mse: 0.0075\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0231 - mse: 0.0011 - val_loss: 0.0074 - val_mae: 0.0327 - val_mse: 0.0074\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0229 - mse: 0.0011 - val_loss: 0.0075 - val_mae: 0.0326 - val_mse: 0.0075\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0227 - mse: 0.0011 - val_loss: 0.0074 - val_mae: 0.0326 - val_mse: 0.0074\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0226 - mse: 0.0011 - val_loss: 0.0075 - val_mae: 0.0326 - val_mse: 0.0075\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0072 - val_mae: 0.0326 - val_mse: 0.0072\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0221 - mse: 0.0011 - val_loss: 0.0074 - val_mae: 0.0324 - val_mse: 0.0074\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0074 - val_mae: 0.0332 - val_mse: 0.0074\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0073 - val_mae: 0.0323 - val_mse: 0.0073\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0218 - mse: 0.0011 - val_loss: 0.0073 - val_mae: 0.0323 - val_mse: 0.0073\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0214 - mse: 0.0010 - val_loss: 0.0073 - val_mae: 0.0325 - val_mse: 0.0073\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0215 - mse: 0.0011 - val_loss: 0.0073 - val_mae: 0.0325 - val_mse: 0.0073\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0073 - val_mae: 0.0326 - val_mse: 0.0073\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.9864e-04 - mae: 0.0211 - mse: 9.9864e-04 - val_loss: 0.0074 - val_mae: 0.0327 - val_mse: 0.0074\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8922e-04 - mae: 0.0211 - mse: 9.8922e-04 - val_loss: 0.0075 - val_mae: 0.0334 - val_mse: 0.0075\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0073 - val_mae: 0.0325 - val_mse: 0.0073\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0076 - val_mae: 0.0330 - val_mse: 0.0076\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0073 - val_mae: 0.0325 - val_mse: 0.0073\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8574e-04 - mae: 0.0206 - mse: 9.8574e-04 - val_loss: 0.0074 - val_mae: 0.0326 - val_mse: 0.0074\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8584e-04 - mae: 0.0208 - mse: 9.8584e-04 - val_loss: 0.0073 - val_mae: 0.0324 - val_mse: 0.0073\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5660e-04 - mae: 0.0207 - mse: 9.5660e-04 - val_loss: 0.0075 - val_mae: 0.0341 - val_mse: 0.0075\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8090e-04 - mae: 0.0207 - mse: 9.8090e-04 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8672e-04 - mae: 0.0207 - mse: 9.8672e-04 - val_loss: 0.0070 - val_mae: 0.0325 - val_mse: 0.0070\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5908e-04 - mae: 0.0204 - mse: 9.5908e-04 - val_loss: 0.0072 - val_mae: 0.0324 - val_mse: 0.0072\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6193e-04 - mae: 0.0205 - mse: 9.6193e-04 - val_loss: 0.0073 - val_mae: 0.0324 - val_mse: 0.0073\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.3900e-04 - mae: 0.0203 - mse: 9.3900e-04 - val_loss: 0.0073 - val_mae: 0.0324 - val_mse: 0.0073\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4428e-04 - mae: 0.0203 - mse: 9.4428e-04 - val_loss: 0.0074 - val_mae: 0.0330 - val_mse: 0.0074\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4887e-04 - mae: 0.0203 - mse: 9.4887e-04 - val_loss: 0.0073 - val_mae: 0.0332 - val_mse: 0.0073\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6944e-04 - mae: 0.0203 - mse: 9.6944e-04 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.2812e-04 - mae: 0.0202 - mse: 9.2812e-04 - val_loss: 0.0074 - val_mae: 0.0334 - val_mse: 0.0074\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7517e-04 - mae: 0.0201 - mse: 9.7517e-04 - val_loss: 0.0074 - val_mae: 0.0327 - val_mse: 0.0074\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8773e-04 - mae: 0.0204 - mse: 9.8773e-04 - val_loss: 0.0074 - val_mae: 0.0326 - val_mse: 0.0074\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6115e-04 - mae: 0.0202 - mse: 9.6115e-04 - val_loss: 0.0073 - val_mae: 0.0327 - val_mse: 0.0073\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.3945e-04 - mae: 0.0202 - mse: 9.3945e-04 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5942e-04 - mae: 0.0202 - mse: 9.5942e-04 - val_loss: 0.0072 - val_mae: 0.0324 - val_mse: 0.0072\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6838e-04 - mae: 0.0203 - mse: 9.6838e-04 - val_loss: 0.0072 - val_mae: 0.0326 - val_mse: 0.0072\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5118e-04 - mae: 0.0201 - mse: 9.5118e-04 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4312e-04 - mae: 0.0203 - mse: 9.4312e-04 - val_loss: 0.0075 - val_mae: 0.0329 - val_mse: 0.0075\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.3350e-04 - mae: 0.0201 - mse: 9.3350e-04 - val_loss: 0.0073 - val_mae: 0.0325 - val_mse: 0.0073\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.3905e-04 - mae: 0.0203 - mse: 9.3905e-04 - val_loss: 0.0074 - val_mae: 0.0325 - val_mse: 0.0074\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8502e-04 - mae: 0.0202 - mse: 9.8502e-04 - val_loss: 0.0076 - val_mae: 0.0329 - val_mse: 0.0076\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8753e-04 - mae: 0.0202 - mse: 9.8753e-04 - val_loss: 0.0074 - val_mae: 0.0324 - val_mse: 0.0074\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.2629e-04 - mae: 0.0200 - mse: 9.2629e-04 - val_loss: 0.0073 - val_mae: 0.0330 - val_mse: 0.0073\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4600e-04 - mae: 0.0200 - mse: 9.4600e-04 - val_loss: 0.0073 - val_mae: 0.0333 - val_mse: 0.0073\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8598e-04 - mae: 0.0202 - mse: 9.8598e-04 - val_loss: 0.0074 - val_mae: 0.0325 - val_mse: 0.0074\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5283e-04 - mae: 0.0201 - mse: 9.5283e-04 - val_loss: 0.0073 - val_mae: 0.0323 - val_mse: 0.0073\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5208e-04 - mae: 0.0200 - mse: 9.5208e-04 - val_loss: 0.0072 - val_mae: 0.0325 - val_mse: 0.0072\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5235e-04 - mae: 0.0201 - mse: 9.5235e-04 - val_loss: 0.0073 - val_mae: 0.0327 - val_mse: 0.0073\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.2475e-04 - mae: 0.0200 - mse: 9.2475e-04 - val_loss: 0.0074 - val_mae: 0.0327 - val_mse: 0.0074\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.7023e-04 - mae: 0.0202 - mse: 9.7023e-04 - val_loss: 0.0073 - val_mae: 0.0326 - val_mse: 0.0073\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4125e-04 - mae: 0.0201 - mse: 9.4125e-04 - val_loss: 0.0073 - val_mae: 0.0325 - val_mse: 0.0073\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5860e-04 - mae: 0.0201 - mse: 9.5860e-04 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5665e-04 - mae: 0.0198 - mse: 9.5665e-04 - val_loss: 0.0076 - val_mae: 0.0340 - val_mse: 0.0076\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.2228e-04 - mae: 0.0199 - mse: 9.2228e-04 - val_loss: 0.0074 - val_mae: 0.0325 - val_mse: 0.0074\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.2314e-04 - mae: 0.0199 - mse: 9.2314e-04 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4469e-04 - mae: 0.0199 - mse: 9.4469e-04 - val_loss: 0.0076 - val_mae: 0.0327 - val_mse: 0.0076\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5728e-04 - mae: 0.0200 - mse: 9.5728e-04 - val_loss: 0.0072 - val_mae: 0.0322 - val_mse: 0.0072\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.2044e-04 - mae: 0.0199 - mse: 9.2044e-04 - val_loss: 0.0073 - val_mae: 0.0331 - val_mse: 0.0073\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6902e-04 - mae: 0.0200 - mse: 9.6902e-04 - val_loss: 0.0070 - val_mae: 0.0328 - val_mse: 0.0070\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4196e-04 - mae: 0.0201 - mse: 9.4196e-04 - val_loss: 0.0074 - val_mae: 0.0327 - val_mse: 0.0074\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5960e-04 - mae: 0.0201 - mse: 9.5960e-04 - val_loss: 0.0073 - val_mae: 0.0323 - val_mse: 0.0073\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4863e-04 - mae: 0.0200 - mse: 9.4863e-04 - val_loss: 0.0073 - val_mae: 0.0327 - val_mse: 0.0073\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.1885e-04 - mae: 0.0199 - mse: 9.1885e-04 - val_loss: 0.0073 - val_mae: 0.0326 - val_mse: 0.0073\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4675e-04 - mae: 0.0200 - mse: 9.4675e-04 - val_loss: 0.0076 - val_mae: 0.0330 - val_mse: 0.0076\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.3025e-04 - mae: 0.0199 - mse: 9.3025e-04 - val_loss: 0.0072 - val_mae: 0.0323 - val_mse: 0.0072\n",
      "989/989 [==============================] - 1s 931us/step\n",
      "110/110 [==============================] - 0s 946us/step\n",
      "123/123 [==============================] - 0s 945us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 5s 4ms/step - loss: 0.0627 - mae: 0.1623 - mse: 0.0627 - val_loss: 0.0078 - val_mae: 0.0591 - val_mse: 0.0078\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0067 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0041 - val_mae: 0.0335 - val_mse: 0.0041\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0051 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0041 - val_mae: 0.0331 - val_mse: 0.0041\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0047 - mae: 0.0522 - mse: 0.0047 - val_loss: 0.0040 - val_mae: 0.0309 - val_mse: 0.0040\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0043 - mae: 0.0497 - mse: 0.0043 - val_loss: 0.0042 - val_mae: 0.0352 - val_mse: 0.0042\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0039 - mae: 0.0475 - mse: 0.0039 - val_loss: 0.0040 - val_mae: 0.0314 - val_mse: 0.0040\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0465 - mse: 0.0038 - val_loss: 0.0041 - val_mae: 0.0321 - val_mse: 0.0041\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0444 - mse: 0.0035 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0033 - mae: 0.0433 - mse: 0.0033 - val_loss: 0.0041 - val_mae: 0.0329 - val_mse: 0.0041\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0415 - mse: 0.0031 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0029 - mae: 0.0403 - mse: 0.0029 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0028 - mae: 0.0389 - mse: 0.0028 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0374 - mse: 0.0025 - val_loss: 0.0041 - val_mae: 0.0322 - val_mse: 0.0041\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0362 - mse: 0.0024 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0350 - mse: 0.0022 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0340 - mse: 0.0021 - val_loss: 0.0040 - val_mae: 0.0311 - val_mse: 0.0040\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0333 - mse: 0.0021 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0019 - val_loss: 0.0040 - val_mae: 0.0313 - val_mse: 0.0040\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0019 - val_loss: 0.0040 - val_mae: 0.0309 - val_mse: 0.0040\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0306 - mse: 0.0017 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0017 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0017 - mae: 0.0293 - mse: 0.0017 - val_loss: 0.0040 - val_mae: 0.0314 - val_mse: 0.0040\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0016 - mae: 0.0288 - mse: 0.0016 - val_loss: 0.0040 - val_mae: 0.0309 - val_mse: 0.0040\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0015 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0276 - mse: 0.0015 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0015 - mae: 0.0272 - mse: 0.0015 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0266 - mse: 0.0014 - val_loss: 0.0040 - val_mae: 0.0307 - val_mse: 0.0040\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0014 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0013 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0013 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0249 - mse: 0.0013 - val_loss: 0.0040 - val_mae: 0.0309 - val_mse: 0.0040\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0012 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0242 - mse: 0.0012 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0240 - mse: 0.0012 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0235 - mse: 0.0012 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0232 - mse: 0.0012 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0232 - mse: 0.0012 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0228 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0226 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0317 - val_mse: 0.0041\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0307 - val_mse: 0.0040\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0222 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0221 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0218 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0217 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0217 - mse: 0.0011 - val_loss: 0.0040 - val_mae: 0.0307 - val_mse: 0.0040\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0307 - val_mse: 0.0040\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8608e-04 - mae: 0.0206 - mse: 9.8608e-04 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0207 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0315 - val_mse: 0.0040\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0206 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9805e-04 - mae: 0.0206 - mse: 9.9805e-04 - val_loss: 0.0040 - val_mae: 0.0311 - val_mse: 0.0040\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0206 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8496e-04 - mae: 0.0204 - mse: 9.8496e-04 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4783e-04 - mae: 0.0203 - mse: 9.4783e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8658e-04 - mae: 0.0205 - mse: 9.8658e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6861e-04 - mae: 0.0205 - mse: 9.6861e-04 - val_loss: 0.0040 - val_mae: 0.0316 - val_mse: 0.0040\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9324e-04 - mae: 0.0204 - mse: 9.9324e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6797e-04 - mae: 0.0203 - mse: 9.6797e-04 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7502e-04 - mae: 0.0202 - mse: 9.7502e-04 - val_loss: 0.0040 - val_mae: 0.0309 - val_mse: 0.0040\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4202e-04 - mae: 0.0201 - mse: 9.4202e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8821e-04 - mae: 0.0203 - mse: 9.8821e-04 - val_loss: 0.0040 - val_mae: 0.0313 - val_mse: 0.0040\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8094e-04 - mae: 0.0202 - mse: 9.8094e-04 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7212e-04 - mae: 0.0203 - mse: 9.7212e-04 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6846e-04 - mae: 0.0201 - mse: 9.6846e-04 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.9931e-04 - mae: 0.0202 - mse: 9.9931e-04 - val_loss: 0.0040 - val_mae: 0.0307 - val_mse: 0.0040\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6566e-04 - mae: 0.0201 - mse: 9.6566e-04 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6363e-04 - mae: 0.0201 - mse: 9.6363e-04 - val_loss: 0.0040 - val_mae: 0.0313 - val_mse: 0.0040\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.4289e-04 - mae: 0.0200 - mse: 9.4289e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5770e-04 - mae: 0.0200 - mse: 9.5770e-04 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0309 - val_mse: 0.0040\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5970e-04 - mae: 0.0200 - mse: 9.5970e-04 - val_loss: 0.0040 - val_mae: 0.0307 - val_mse: 0.0040\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.9157e-04 - mae: 0.0201 - mse: 9.9157e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.5679e-04 - mae: 0.0199 - mse: 9.5679e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8959e-04 - mae: 0.0201 - mse: 9.8959e-04 - val_loss: 0.0040 - val_mae: 0.0307 - val_mse: 0.0040\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8304e-04 - mae: 0.0202 - mse: 9.8304e-04 - val_loss: 0.0040 - val_mae: 0.0314 - val_mse: 0.0040\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8414e-04 - mae: 0.0201 - mse: 9.8414e-04 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8951e-04 - mae: 0.0200 - mse: 9.8951e-04 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.2717e-04 - mae: 0.0200 - mse: 9.2717e-04 - val_loss: 0.0040 - val_mae: 0.0310 - val_mse: 0.0040\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6104e-04 - mae: 0.0200 - mse: 9.6104e-04 - val_loss: 0.0040 - val_mae: 0.0308 - val_mse: 0.0040\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6264e-04 - mae: 0.0201 - mse: 9.6264e-04 - val_loss: 0.0040 - val_mae: 0.0312 - val_mse: 0.0040\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3715e-04 - mae: 0.0199 - mse: 9.3715e-04 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3396e-04 - mae: 0.0199 - mse: 9.3396e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7565e-04 - mae: 0.0200 - mse: 9.7565e-04 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6753e-04 - mae: 0.0200 - mse: 9.6753e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5641e-04 - mae: 0.0200 - mse: 9.5641e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4589e-04 - mae: 0.0199 - mse: 9.4589e-04 - val_loss: 0.0040 - val_mae: 0.0306 - val_mse: 0.0040\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4744e-04 - mae: 0.0198 - mse: 9.4744e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8931e-04 - mae: 0.0200 - mse: 9.8931e-04 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3488e-04 - mae: 0.0199 - mse: 9.3488e-04 - val_loss: 0.0040 - val_mae: 0.0304 - val_mse: 0.0040\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5159e-04 - mae: 0.0200 - mse: 9.5159e-04 - val_loss: 0.0040 - val_mae: 0.0305 - val_mse: 0.0040\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 5s 5ms/step - loss: 0.0660 - mae: 0.1658 - mse: 0.0660 - val_loss: 0.0089 - val_mae: 0.0602 - val_mse: 0.0089\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0064 - mae: 0.0620 - mse: 0.0064 - val_loss: 0.0053 - val_mae: 0.0344 - val_mse: 0.0053\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0048 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0052 - val_mae: 0.0322 - val_mse: 0.0052\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0043 - mae: 0.0499 - mse: 0.0043 - val_loss: 0.0053 - val_mae: 0.0339 - val_mse: 0.0053\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0478 - mse: 0.0039 - val_loss: 0.0053 - val_mae: 0.0330 - val_mse: 0.0053\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0037 - mae: 0.0456 - mse: 0.0037 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0446 - mse: 0.0035 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0032 - mae: 0.0426 - mse: 0.0032 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0030 - mae: 0.0412 - mse: 0.0030 - val_loss: 0.0052 - val_mae: 0.0310 - val_mse: 0.0052\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0400 - mse: 0.0029 - val_loss: 0.0052 - val_mae: 0.0310 - val_mse: 0.0052\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0384 - mse: 0.0026 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0369 - mse: 0.0024 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0348 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0342 - mse: 0.0021 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0332 - mse: 0.0020 - val_loss: 0.0052 - val_mae: 0.0318 - val_mse: 0.0052\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0321 - mse: 0.0019 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0313 - mse: 0.0018 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0018 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0304 - mse: 0.0017 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0296 - mse: 0.0016 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0291 - mse: 0.0016 - val_loss: 0.0053 - val_mae: 0.0332 - val_mse: 0.0053\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0015 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0277 - mse: 0.0014 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0273 - mse: 0.0014 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0270 - mse: 0.0014 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0266 - mse: 0.0014 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0013 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0013 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0253 - mse: 0.0013 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0012 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0244 - mse: 0.0012 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0242 - mse: 0.0012 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0240 - mse: 0.0012 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0236 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0234 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0317 - val_mse: 0.0053\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0232 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0315 - val_mse: 0.0053\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0231 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0229 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0319 - val_mse: 0.0052\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0318 - val_mse: 0.0052\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0224 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0219 - mse: 0.0010 - val_loss: 0.0052 - val_mae: 0.0318 - val_mse: 0.0052\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0219 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9449e-04 - mae: 0.0217 - mse: 9.9449e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0217 - mse: 0.0010 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9775e-04 - mae: 0.0212 - mse: 9.9775e-04 - val_loss: 0.0052 - val_mae: 0.0314 - val_mse: 0.0052\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6809e-04 - mae: 0.0210 - mse: 9.6809e-04 - val_loss: 0.0052 - val_mae: 0.0317 - val_mse: 0.0052\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6567e-04 - mae: 0.0209 - mse: 9.6567e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8477e-04 - mae: 0.0211 - mse: 9.8477e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.7375e-04 - mae: 0.0208 - mse: 9.7375e-04 - val_loss: 0.0052 - val_mae: 0.0314 - val_mse: 0.0052\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7353e-04 - mae: 0.0208 - mse: 9.7353e-04 - val_loss: 0.0052 - val_mae: 0.0318 - val_mse: 0.0052\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5829e-04 - mae: 0.0207 - mse: 9.5829e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5077e-04 - mae: 0.0207 - mse: 9.5077e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7715e-04 - mae: 0.0206 - mse: 9.7715e-04 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4492e-04 - mae: 0.0205 - mse: 9.4492e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6893e-04 - mae: 0.0205 - mse: 9.6893e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4456e-04 - mae: 0.0204 - mse: 9.4456e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6395e-04 - mae: 0.0206 - mse: 9.6395e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8252e-04 - mae: 0.0203 - mse: 9.8252e-04 - val_loss: 0.0052 - val_mae: 0.0321 - val_mse: 0.0052\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5906e-04 - mae: 0.0204 - mse: 9.5906e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.1690e-04 - mae: 0.0202 - mse: 9.1690e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.5977e-04 - mae: 0.0204 - mse: 9.5977e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6789e-04 - mae: 0.0203 - mse: 9.6789e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2310e-04 - mae: 0.0201 - mse: 9.2310e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4977e-04 - mae: 0.0202 - mse: 9.4977e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.1937e-04 - mae: 0.0202 - mse: 9.1937e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.4029e-04 - mae: 0.0202 - mse: 9.4029e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.2062e-04 - mae: 0.0200 - mse: 9.2062e-04 - val_loss: 0.0052 - val_mae: 0.0314 - val_mse: 0.0052\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.6614e-04 - mae: 0.0202 - mse: 9.6614e-04 - val_loss: 0.0052 - val_mae: 0.0314 - val_mse: 0.0052\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.3658e-04 - mae: 0.0201 - mse: 9.3658e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.4730e-04 - mae: 0.0201 - mse: 9.4730e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.4611e-04 - mae: 0.0202 - mse: 9.4611e-04 - val_loss: 0.0052 - val_mae: 0.0314 - val_mse: 0.0052\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6095e-04 - mae: 0.0200 - mse: 9.6095e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3526e-04 - mae: 0.0201 - mse: 9.3526e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3825e-04 - mae: 0.0200 - mse: 9.3825e-04 - val_loss: 0.0052 - val_mae: 0.0319 - val_mse: 0.0052\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3668e-04 - mae: 0.0201 - mse: 9.3668e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5066e-04 - mae: 0.0201 - mse: 9.5066e-04 - val_loss: 0.0053 - val_mae: 0.0324 - val_mse: 0.0053\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3003e-04 - mae: 0.0200 - mse: 9.3003e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4232e-04 - mae: 0.0200 - mse: 9.4232e-04 - val_loss: 0.0052 - val_mae: 0.0314 - val_mse: 0.0052\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4623e-04 - mae: 0.0201 - mse: 9.4623e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5677e-04 - mae: 0.0201 - mse: 9.5677e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4219e-04 - mae: 0.0201 - mse: 9.4219e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.1455e-04 - mae: 0.0199 - mse: 9.1455e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 8.9663e-04 - mae: 0.0198 - mse: 8.9663e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9058e-04 - mae: 0.0202 - mse: 9.9058e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.2665e-04 - mae: 0.0200 - mse: 9.2665e-04 - val_loss: 0.0052 - val_mae: 0.0315 - val_mse: 0.0052\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.2748e-04 - mae: 0.0200 - mse: 9.2748e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.6018e-04 - mae: 0.0200 - mse: 9.6018e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2767e-04 - mae: 0.0199 - mse: 9.2767e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2641e-04 - mae: 0.0200 - mse: 9.2641e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.0741e-04 - mae: 0.0198 - mse: 9.0741e-04 - val_loss: 0.0052 - val_mae: 0.0321 - val_mse: 0.0052\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.0971e-04 - mae: 0.0198 - mse: 9.0971e-04 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.1083e-04 - mae: 0.0199 - mse: 9.1083e-04 - val_loss: 0.0052 - val_mae: 0.0310 - val_mse: 0.0052\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.3143e-04 - mae: 0.0200 - mse: 9.3143e-04 - val_loss: 0.0052 - val_mae: 0.0311 - val_mse: 0.0052\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5097e-04 - mae: 0.0200 - mse: 9.5097e-04 - val_loss: 0.0052 - val_mae: 0.0316 - val_mse: 0.0052\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2110e-04 - mae: 0.0199 - mse: 9.2110e-04 - val_loss: 0.0052 - val_mae: 0.0312 - val_mse: 0.0052\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.1447e-04 - mae: 0.0199 - mse: 9.1447e-04 - val_loss: 0.0052 - val_mae: 0.0318 - val_mse: 0.0052\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 7s 5ms/step - loss: 0.0651 - mae: 0.1682 - mse: 0.0651 - val_loss: 0.0087 - val_mae: 0.0623 - val_mse: 0.0087\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0069 - mae: 0.0647 - mse: 0.0069 - val_loss: 0.0042 - val_mae: 0.0324 - val_mse: 0.0042\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0054 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0050 - mae: 0.0535 - mse: 0.0050 - val_loss: 0.0042 - val_mae: 0.0315 - val_mse: 0.0042\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0045 - mae: 0.0513 - mse: 0.0045 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0042 - mae: 0.0490 - mse: 0.0042 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0473 - mse: 0.0039 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0037 - mae: 0.0458 - mse: 0.0037 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0446 - mse: 0.0035 - val_loss: 0.0041 - val_mae: 0.0317 - val_mse: 0.0041\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0032 - mae: 0.0426 - mse: 0.0032 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0030 - mae: 0.0413 - mse: 0.0030 - val_loss: 0.0042 - val_mae: 0.0324 - val_mse: 0.0042\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0028 - mae: 0.0398 - mse: 0.0028 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0382 - mse: 0.0026 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0370 - mse: 0.0025 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0021 - mae: 0.0346 - mse: 0.0021 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0337 - mse: 0.0020 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0020 - mae: 0.0328 - mse: 0.0020 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0019 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0018 - mae: 0.0312 - mse: 0.0018 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0017 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0016 - mae: 0.0288 - mse: 0.0016 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 4s 6ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0015 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0015 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0015 - mae: 0.0271 - mse: 0.0015 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0014 - mae: 0.0267 - mse: 0.0014 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0013 - val_loss: 0.0041 - val_mae: 0.0315 - val_mse: 0.0041\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0013 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0013 - val_loss: 0.0041 - val_mae: 0.0316 - val_mse: 0.0041\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0310 - val_mse: 0.0041\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0245 - mse: 0.0013 - val_loss: 0.0042 - val_mae: 0.0317 - val_mse: 0.0042\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0241 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0310 - val_mse: 0.0041\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0237 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0305 - val_mse: 0.0041\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0234 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0231 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0231 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0230 - mse: 0.0012 - val_loss: 0.0043 - val_mae: 0.0323 - val_mse: 0.0043\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0225 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0224 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0219 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0217 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0214 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0215 - mse: 0.0011 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0212 - mse: 0.0010 - val_loss: 0.0042 - val_mae: 0.0313 - val_mse: 0.0042\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8467e-04 - mae: 0.0211 - mse: 9.8467e-04 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0212 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0207 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8213e-04 - mae: 0.0205 - mse: 9.8213e-04 - val_loss: 0.0041 - val_mae: 0.0318 - val_mse: 0.0041\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8695e-04 - mae: 0.0205 - mse: 9.8695e-04 - val_loss: 0.0041 - val_mae: 0.0316 - val_mse: 0.0041\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6123e-04 - mae: 0.0203 - mse: 9.6123e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0206 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8982e-04 - mae: 0.0206 - mse: 9.8982e-04 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6855e-04 - mae: 0.0203 - mse: 9.6855e-04 - val_loss: 0.0041 - val_mae: 0.0310 - val_mse: 0.0041\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7773e-04 - mae: 0.0202 - mse: 9.7773e-04 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6798e-04 - mae: 0.0202 - mse: 9.6798e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8365e-04 - mae: 0.0202 - mse: 9.8365e-04 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7746e-04 - mae: 0.0201 - mse: 9.7746e-04 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0305 - val_mse: 0.0041\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9804e-04 - mae: 0.0203 - mse: 9.9804e-04 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7567e-04 - mae: 0.0202 - mse: 9.7567e-04 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6367e-04 - mae: 0.0200 - mse: 9.6367e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7068e-04 - mae: 0.0201 - mse: 9.7068e-04 - val_loss: 0.0041 - val_mae: 0.0314 - val_mse: 0.0041\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8601e-04 - mae: 0.0202 - mse: 9.8601e-04 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8578e-04 - mae: 0.0203 - mse: 9.8578e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5708e-04 - mae: 0.0201 - mse: 9.5708e-04 - val_loss: 0.0041 - val_mae: 0.0310 - val_mse: 0.0041\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0310 - val_mse: 0.0041\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9719e-04 - mae: 0.0200 - mse: 9.9719e-04 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8388e-04 - mae: 0.0201 - mse: 9.8388e-04 - val_loss: 0.0041 - val_mae: 0.0311 - val_mse: 0.0041\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7294e-04 - mae: 0.0202 - mse: 9.7294e-04 - val_loss: 0.0041 - val_mae: 0.0309 - val_mse: 0.0041\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6411e-04 - mae: 0.0200 - mse: 9.6411e-04 - val_loss: 0.0041 - val_mae: 0.0305 - val_mse: 0.0041\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8640e-04 - mae: 0.0202 - mse: 9.8640e-04 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6432e-04 - mae: 0.0200 - mse: 9.6432e-04 - val_loss: 0.0041 - val_mae: 0.0305 - val_mse: 0.0041\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6870e-04 - mae: 0.0200 - mse: 9.6870e-04 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6647e-04 - mae: 0.0200 - mse: 9.6647e-04 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7951e-04 - mae: 0.0201 - mse: 9.7951e-04 - val_loss: 0.0041 - val_mae: 0.0308 - val_mse: 0.0041\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8475e-04 - mae: 0.0201 - mse: 9.8475e-04 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8587e-04 - mae: 0.0201 - mse: 9.8587e-04 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7568e-04 - mae: 0.0201 - mse: 9.7568e-04 - val_loss: 0.0041 - val_mae: 0.0307 - val_mse: 0.0041\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9152e-04 - mae: 0.0200 - mse: 9.9152e-04 - val_loss: 0.0041 - val_mae: 0.0313 - val_mse: 0.0041\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5290e-04 - mae: 0.0199 - mse: 9.5290e-04 - val_loss: 0.0041 - val_mae: 0.0305 - val_mse: 0.0041\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5865e-04 - mae: 0.0199 - mse: 9.5865e-04 - val_loss: 0.0041 - val_mae: 0.0312 - val_mse: 0.0041\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7530e-04 - mae: 0.0199 - mse: 9.7530e-04 - val_loss: 0.0041 - val_mae: 0.0305 - val_mse: 0.0041\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4858e-04 - mae: 0.0199 - mse: 9.4858e-04 - val_loss: 0.0041 - val_mae: 0.0306 - val_mse: 0.0041\n",
      "989/989 [==============================] - 2s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 6s 5ms/step - loss: 0.0569 - mae: 0.1539 - mse: 0.0569 - val_loss: 0.0086 - val_mae: 0.0572 - val_mse: 0.0086\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0060 - mae: 0.0601 - mse: 0.0060 - val_loss: 0.0068 - val_mae: 0.0341 - val_mse: 0.0068\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0048 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0069 - val_mae: 0.0388 - val_mse: 0.0069\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0043 - mae: 0.0496 - mse: 0.0043 - val_loss: 0.0065 - val_mae: 0.0356 - val_mse: 0.0065\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0473 - mse: 0.0039 - val_loss: 0.0065 - val_mae: 0.0342 - val_mse: 0.0065\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0449 - mse: 0.0035 - val_loss: 0.0063 - val_mae: 0.0324 - val_mse: 0.0063\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0034 - mae: 0.0438 - mse: 0.0034 - val_loss: 0.0063 - val_mae: 0.0323 - val_mse: 0.0063\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0031 - mae: 0.0417 - mse: 0.0031 - val_loss: 0.0063 - val_mae: 0.0322 - val_mse: 0.0063\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0402 - mse: 0.0029 - val_loss: 0.0062 - val_mae: 0.0323 - val_mse: 0.0062\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0027 - mae: 0.0389 - mse: 0.0027 - val_loss: 0.0062 - val_mae: 0.0324 - val_mse: 0.0062\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0376 - mse: 0.0026 - val_loss: 0.0063 - val_mae: 0.0323 - val_mse: 0.0063\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0366 - mse: 0.0024 - val_loss: 0.0063 - val_mae: 0.0324 - val_mse: 0.0063\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0353 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0325 - val_mse: 0.0062\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0347 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0323 - val_mse: 0.0062\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0335 - mse: 0.0021 - val_loss: 0.0060 - val_mae: 0.0340 - val_mse: 0.0060\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0329 - mse: 0.0020 - val_loss: 0.0062 - val_mae: 0.0327 - val_mse: 0.0062\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0321 - mse: 0.0019 - val_loss: 0.0063 - val_mae: 0.0332 - val_mse: 0.0063\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0316 - mse: 0.0019 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0312 - mse: 0.0018 - val_loss: 0.0060 - val_mae: 0.0330 - val_mse: 0.0060\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0296 - mse: 0.0016 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0016 - val_loss: 0.0062 - val_mae: 0.0326 - val_mse: 0.0062\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0287 - mse: 0.0016 - val_loss: 0.0064 - val_mae: 0.0325 - val_mse: 0.0064\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0015 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015 - val_loss: 0.0062 - val_mae: 0.0322 - val_mse: 0.0062\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0015 - val_loss: 0.0061 - val_mae: 0.0325 - val_mse: 0.0061\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0270 - mse: 0.0014 - val_loss: 0.0061 - val_mae: 0.0324 - val_mse: 0.0061\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0265 - mse: 0.0014 - val_loss: 0.0061 - val_mae: 0.0322 - val_mse: 0.0061\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0262 - mse: 0.0014 - val_loss: 0.0061 - val_mae: 0.0326 - val_mse: 0.0061\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0013 - val_loss: 0.0062 - val_mae: 0.0335 - val_mse: 0.0062\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0013 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0250 - mse: 0.0013 - val_loss: 0.0062 - val_mae: 0.0325 - val_mse: 0.0062\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0250 - mse: 0.0013 - val_loss: 0.0061 - val_mae: 0.0321 - val_mse: 0.0061\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0012 - val_loss: 0.0062 - val_mae: 0.0328 - val_mse: 0.0062\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0243 - mse: 0.0012 - val_loss: 0.0061 - val_mae: 0.0321 - val_mse: 0.0061\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0239 - mse: 0.0012 - val_loss: 0.0061 - val_mae: 0.0321 - val_mse: 0.0061\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0237 - mse: 0.0012 - val_loss: 0.0061 - val_mae: 0.0320 - val_mse: 0.0061\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0235 - mse: 0.0012 - val_loss: 0.0061 - val_mae: 0.0319 - val_mse: 0.0061\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0233 - mse: 0.0011 - val_loss: 0.0061 - val_mae: 0.0320 - val_mse: 0.0061\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0231 - mse: 0.0011 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0228 - mse: 0.0011 - val_loss: 0.0061 - val_mae: 0.0319 - val_mse: 0.0061\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0226 - mse: 0.0011 - val_loss: 0.0063 - val_mae: 0.0331 - val_mse: 0.0063\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0225 - mse: 0.0011 - val_loss: 0.0062 - val_mae: 0.0321 - val_mse: 0.0062\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0224 - mse: 0.0011 - val_loss: 0.0063 - val_mae: 0.0325 - val_mse: 0.0063\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0062 - val_mae: 0.0319 - val_mse: 0.0062\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0060 - val_mae: 0.0321 - val_mse: 0.0060\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0063 - val_mae: 0.0321 - val_mse: 0.0063\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0218 - mse: 0.0010 - val_loss: 0.0060 - val_mae: 0.0326 - val_mse: 0.0060\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0218 - mse: 0.0010 - val_loss: 0.0060 - val_mae: 0.0321 - val_mse: 0.0060\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0218 - mse: 0.0011 - val_loss: 0.0064 - val_mae: 0.0325 - val_mse: 0.0064\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0063 - val_mae: 0.0331 - val_mse: 0.0063\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0215 - mse: 0.0011 - val_loss: 0.0063 - val_mae: 0.0320 - val_mse: 0.0063\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0215 - mse: 0.0011 - val_loss: 0.0061 - val_mae: 0.0324 - val_mse: 0.0061\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0214 - mse: 0.0010 - val_loss: 0.0062 - val_mae: 0.0322 - val_mse: 0.0062\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0061 - val_mae: 0.0324 - val_mse: 0.0061\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0060 - val_mae: 0.0325 - val_mse: 0.0060\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0063 - val_mae: 0.0323 - val_mse: 0.0063\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0061 - val_mae: 0.0323 - val_mse: 0.0061\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0211 - mse: 0.0011 - val_loss: 0.0062 - val_mae: 0.0319 - val_mse: 0.0062\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8614e-04 - mae: 0.0208 - mse: 9.8614e-04 - val_loss: 0.0063 - val_mae: 0.0322 - val_mse: 0.0063\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8460e-04 - mae: 0.0208 - mse: 9.8460e-04 - val_loss: 0.0062 - val_mae: 0.0321 - val_mse: 0.0062\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9806e-04 - mae: 0.0208 - mse: 9.9806e-04 - val_loss: 0.0063 - val_mae: 0.0321 - val_mse: 0.0063\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0061 - val_mae: 0.0324 - val_mse: 0.0061\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0061 - val_mae: 0.0319 - val_mse: 0.0061\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0061 - val_mae: 0.0345 - val_mse: 0.0061\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8900e-04 - mae: 0.0207 - mse: 9.8900e-04 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9475e-04 - mae: 0.0205 - mse: 9.9475e-04 - val_loss: 0.0060 - val_mae: 0.0320 - val_mse: 0.0060\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9590e-04 - mae: 0.0206 - mse: 9.9590e-04 - val_loss: 0.0061 - val_mae: 0.0324 - val_mse: 0.0061\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9722e-04 - mae: 0.0206 - mse: 9.9722e-04 - val_loss: 0.0063 - val_mae: 0.0320 - val_mse: 0.0063\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0207 - mse: 0.0010 - val_loss: 0.0061 - val_mae: 0.0323 - val_mse: 0.0061\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9982e-04 - mae: 0.0206 - mse: 9.9982e-04 - val_loss: 0.0060 - val_mae: 0.0321 - val_mse: 0.0060\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9407e-04 - mae: 0.0206 - mse: 9.9407e-04 - val_loss: 0.0062 - val_mae: 0.0319 - val_mse: 0.0062\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5528e-04 - mae: 0.0203 - mse: 9.5528e-04 - val_loss: 0.0061 - val_mae: 0.0321 - val_mse: 0.0061\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7518e-04 - mae: 0.0204 - mse: 9.7518e-04 - val_loss: 0.0060 - val_mae: 0.0323 - val_mse: 0.0060\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0207 - mse: 0.0010 - val_loss: 0.0064 - val_mae: 0.0326 - val_mse: 0.0064\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8776e-04 - mae: 0.0206 - mse: 9.8776e-04 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8223e-04 - mae: 0.0205 - mse: 9.8223e-04 - val_loss: 0.0062 - val_mae: 0.0341 - val_mse: 0.0062\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0205 - mse: 0.0010 - val_loss: 0.0063 - val_mae: 0.0341 - val_mse: 0.0063\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9285e-04 - mae: 0.0204 - mse: 9.9285e-04 - val_loss: 0.0060 - val_mae: 0.0320 - val_mse: 0.0060\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9682e-04 - mae: 0.0204 - mse: 9.9682e-04 - val_loss: 0.0061 - val_mae: 0.0321 - val_mse: 0.0061\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6548e-04 - mae: 0.0204 - mse: 9.6548e-04 - val_loss: 0.0062 - val_mae: 0.0324 - val_mse: 0.0062\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9555e-04 - mae: 0.0205 - mse: 9.9555e-04 - val_loss: 0.0062 - val_mae: 0.0319 - val_mse: 0.0062\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9742e-04 - mae: 0.0205 - mse: 9.9742e-04 - val_loss: 0.0061 - val_mae: 0.0320 - val_mse: 0.0061\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7665e-04 - mae: 0.0204 - mse: 9.7665e-04 - val_loss: 0.0061 - val_mae: 0.0319 - val_mse: 0.0061\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8383e-04 - mae: 0.0205 - mse: 9.8383e-04 - val_loss: 0.0061 - val_mae: 0.0329 - val_mse: 0.0061\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7892e-04 - mae: 0.0204 - mse: 9.7892e-04 - val_loss: 0.0062 - val_mae: 0.0319 - val_mse: 0.0062\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0205 - mse: 0.0010 - val_loss: 0.0062 - val_mae: 0.0327 - val_mse: 0.0062\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9164e-04 - mae: 0.0205 - mse: 9.9164e-04 - val_loss: 0.0064 - val_mae: 0.0324 - val_mse: 0.0064\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7946e-04 - mae: 0.0203 - mse: 9.7946e-04 - val_loss: 0.0062 - val_mae: 0.0322 - val_mse: 0.0062\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5791e-04 - mae: 0.0202 - mse: 9.5791e-04 - val_loss: 0.0061 - val_mae: 0.0319 - val_mse: 0.0061\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0207 - mse: 0.0011 - val_loss: 0.0060 - val_mae: 0.0321 - val_mse: 0.0060\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5469e-04 - mae: 0.0202 - mse: 9.5469e-04 - val_loss: 0.0060 - val_mae: 0.0321 - val_mse: 0.0060\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9685e-04 - mae: 0.0204 - mse: 9.9685e-04 - val_loss: 0.0060 - val_mae: 0.0321 - val_mse: 0.0060\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0062 - val_mae: 0.0325 - val_mse: 0.0062\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0203 - mse: 0.0010 - val_loss: 0.0062 - val_mae: 0.0319 - val_mse: 0.0062\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9724e-04 - mae: 0.0203 - mse: 9.9724e-04 - val_loss: 0.0061 - val_mae: 0.0321 - val_mse: 0.0061\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0062 - val_mae: 0.0320 - val_mse: 0.0062\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6432e-04 - mae: 0.0202 - mse: 9.6432e-04 - val_loss: 0.0063 - val_mae: 0.0329 - val_mse: 0.0063\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9271e-04 - mae: 0.0203 - mse: 9.9271e-04 - val_loss: 0.0061 - val_mae: 0.0319 - val_mse: 0.0061\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7908e-04 - mae: 0.0202 - mse: 9.7908e-04 - val_loss: 0.0062 - val_mae: 0.0318 - val_mse: 0.0062\n",
      "989/989 [==============================] - 2s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 6s 5ms/step - loss: 0.0613 - mae: 0.1611 - mse: 0.0613 - val_loss: 0.0102 - val_mae: 0.0604 - val_mse: 0.0102\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0067 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0083 - val_mae: 0.0377 - val_mse: 0.0083\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0052 - mae: 0.0547 - mse: 0.0052 - val_loss: 0.0082 - val_mae: 0.0367 - val_mse: 0.0082\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0046 - mae: 0.0517 - mse: 0.0046 - val_loss: 0.0080 - val_mae: 0.0325 - val_mse: 0.0080\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0042 - mae: 0.0491 - mse: 0.0042 - val_loss: 0.0081 - val_mae: 0.0379 - val_mse: 0.0081\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0471 - mse: 0.0039 - val_loss: 0.0078 - val_mae: 0.0333 - val_mse: 0.0078\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0036 - mae: 0.0454 - mse: 0.0036 - val_loss: 0.0077 - val_mae: 0.0330 - val_mse: 0.0077\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0034 - mae: 0.0438 - mse: 0.0034 - val_loss: 0.0078 - val_mae: 0.0322 - val_mse: 0.0078\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0031 - mae: 0.0419 - mse: 0.0031 - val_loss: 0.0077 - val_mae: 0.0332 - val_mse: 0.0077\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0030 - mae: 0.0408 - mse: 0.0030 - val_loss: 0.0076 - val_mae: 0.0324 - val_mse: 0.0076\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0027 - mae: 0.0388 - mse: 0.0027 - val_loss: 0.0077 - val_mae: 0.0322 - val_mse: 0.0077\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0378 - mse: 0.0025 - val_loss: 0.0077 - val_mae: 0.0325 - val_mse: 0.0077\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0363 - mse: 0.0024 - val_loss: 0.0077 - val_mae: 0.0333 - val_mse: 0.0077\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0353 - mse: 0.0023 - val_loss: 0.0078 - val_mae: 0.0347 - val_mse: 0.0078\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0021 - val_loss: 0.0077 - val_mae: 0.0324 - val_mse: 0.0077\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0334 - mse: 0.0021 - val_loss: 0.0078 - val_mae: 0.0323 - val_mse: 0.0078\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0325 - mse: 0.0020 - val_loss: 0.0076 - val_mae: 0.0328 - val_mse: 0.0076\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0317 - mse: 0.0019 - val_loss: 0.0078 - val_mae: 0.0327 - val_mse: 0.0078\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0309 - mse: 0.0018 - val_loss: 0.0076 - val_mae: 0.0322 - val_mse: 0.0076\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0302 - mse: 0.0017 - val_loss: 0.0076 - val_mae: 0.0323 - val_mse: 0.0076\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0017 - val_loss: 0.0076 - val_mae: 0.0327 - val_mse: 0.0076\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - val_loss: 0.0076 - val_mae: 0.0325 - val_mse: 0.0076\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0015 - val_loss: 0.0078 - val_mae: 0.0330 - val_mse: 0.0078\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0015 - val_loss: 0.0076 - val_mae: 0.0341 - val_mse: 0.0076\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0276 - mse: 0.0015 - val_loss: 0.0078 - val_mae: 0.0333 - val_mse: 0.0078\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0272 - mse: 0.0015 - val_loss: 0.0078 - val_mae: 0.0328 - val_mse: 0.0078\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0266 - mse: 0.0014 - val_loss: 0.0077 - val_mae: 0.0324 - val_mse: 0.0077\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0013 - val_loss: 0.0076 - val_mae: 0.0326 - val_mse: 0.0076\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0256 - mse: 0.0013 - val_loss: 0.0075 - val_mae: 0.0325 - val_mse: 0.0075\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0013 - val_loss: 0.0076 - val_mae: 0.0320 - val_mse: 0.0076\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0245 - mse: 0.0012 - val_loss: 0.0077 - val_mae: 0.0321 - val_mse: 0.0077\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0243 - mse: 0.0013 - val_loss: 0.0076 - val_mae: 0.0321 - val_mse: 0.0076\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0242 - mse: 0.0012 - val_loss: 0.0077 - val_mae: 0.0323 - val_mse: 0.0077\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0238 - mse: 0.0012 - val_loss: 0.0078 - val_mae: 0.0323 - val_mse: 0.0078\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0012 - mae: 0.0236 - mse: 0.0012 - val_loss: 0.0077 - val_mae: 0.0327 - val_mse: 0.0077\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0231 - mse: 0.0011 - val_loss: 0.0076 - val_mae: 0.0321 - val_mse: 0.0076\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0230 - mse: 0.0011 - val_loss: 0.0077 - val_mae: 0.0321 - val_mse: 0.0077\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0227 - mse: 0.0011 - val_loss: 0.0075 - val_mae: 0.0323 - val_mse: 0.0075\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0078 - val_mae: 0.0321 - val_mse: 0.0078\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0222 - mse: 0.0010 - val_loss: 0.0076 - val_mae: 0.0322 - val_mse: 0.0076\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0076 - val_mae: 0.0321 - val_mse: 0.0076\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0076 - val_mae: 0.0322 - val_mse: 0.0076\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0217 - mse: 0.0010 - val_loss: 0.0074 - val_mae: 0.0326 - val_mse: 0.0074\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0216 - mse: 0.0010 - val_loss: 0.0075 - val_mae: 0.0321 - val_mse: 0.0075\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0214 - mse: 0.0010 - val_loss: 0.0075 - val_mae: 0.0324 - val_mse: 0.0075\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0214 - mse: 0.0010 - val_loss: 0.0077 - val_mae: 0.0320 - val_mse: 0.0077\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0076 - val_mae: 0.0341 - val_mse: 0.0076\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0075 - val_mae: 0.0322 - val_mse: 0.0075\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9684e-04 - mae: 0.0210 - mse: 9.9684e-04 - val_loss: 0.0075 - val_mae: 0.0323 - val_mse: 0.0075\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0075 - val_mae: 0.0320 - val_mse: 0.0075\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 4s 5ms/step - loss: 0.0010 - mae: 0.0207 - mse: 0.0010 - val_loss: 0.0078 - val_mae: 0.0328 - val_mse: 0.0078\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0075 - val_mae: 0.0320 - val_mse: 0.0075\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6148e-04 - mae: 0.0207 - mse: 9.6148e-04 - val_loss: 0.0077 - val_mae: 0.0321 - val_mse: 0.0077\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9729e-04 - mae: 0.0207 - mse: 9.9729e-04 - val_loss: 0.0076 - val_mae: 0.0326 - val_mse: 0.0076\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7971e-04 - mae: 0.0205 - mse: 9.7971e-04 - val_loss: 0.0075 - val_mae: 0.0326 - val_mse: 0.0075\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0206 - mse: 0.0010 - val_loss: 0.0078 - val_mae: 0.0321 - val_mse: 0.0078\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9205e-04 - mae: 0.0205 - mse: 9.9205e-04 - val_loss: 0.0076 - val_mae: 0.0321 - val_mse: 0.0076\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9566e-04 - mae: 0.0205 - mse: 9.9566e-04 - val_loss: 0.0076 - val_mae: 0.0320 - val_mse: 0.0076\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6635e-04 - mae: 0.0203 - mse: 9.6635e-04 - val_loss: 0.0077 - val_mae: 0.0323 - val_mse: 0.0077\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5384e-04 - mae: 0.0203 - mse: 9.5384e-04 - val_loss: 0.0076 - val_mae: 0.0321 - val_mse: 0.0076\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5998e-04 - mae: 0.0202 - mse: 9.5998e-04 - val_loss: 0.0076 - val_mae: 0.0324 - val_mse: 0.0076\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7263e-04 - mae: 0.0203 - mse: 9.7263e-04 - val_loss: 0.0076 - val_mae: 0.0346 - val_mse: 0.0076\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7868e-04 - mae: 0.0203 - mse: 9.7868e-04 - val_loss: 0.0077 - val_mae: 0.0320 - val_mse: 0.0077\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7240e-04 - mae: 0.0202 - mse: 9.7240e-04 - val_loss: 0.0076 - val_mae: 0.0327 - val_mse: 0.0076\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5864e-04 - mae: 0.0201 - mse: 9.5864e-04 - val_loss: 0.0078 - val_mae: 0.0322 - val_mse: 0.0078\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8509e-04 - mae: 0.0203 - mse: 9.8509e-04 - val_loss: 0.0077 - val_mae: 0.0320 - val_mse: 0.0077\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7691e-04 - mae: 0.0202 - mse: 9.7691e-04 - val_loss: 0.0080 - val_mae: 0.0333 - val_mse: 0.0080\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4512e-04 - mae: 0.0200 - mse: 9.4512e-04 - val_loss: 0.0076 - val_mae: 0.0320 - val_mse: 0.0076\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6645e-04 - mae: 0.0201 - mse: 9.6645e-04 - val_loss: 0.0076 - val_mae: 0.0326 - val_mse: 0.0076\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0201 - mse: 0.0010 - val_loss: 0.0076 - val_mae: 0.0323 - val_mse: 0.0076\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7344e-04 - mae: 0.0201 - mse: 9.7344e-04 - val_loss: 0.0078 - val_mae: 0.0328 - val_mse: 0.0078\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7835e-04 - mae: 0.0203 - mse: 9.7835e-04 - val_loss: 0.0077 - val_mae: 0.0324 - val_mse: 0.0077\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6993e-04 - mae: 0.0200 - mse: 9.6993e-04 - val_loss: 0.0076 - val_mae: 0.0326 - val_mse: 0.0076\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6832e-04 - mae: 0.0200 - mse: 9.6832e-04 - val_loss: 0.0078 - val_mae: 0.0323 - val_mse: 0.0078\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8613e-04 - mae: 0.0201 - mse: 9.8613e-04 - val_loss: 0.0077 - val_mae: 0.0325 - val_mse: 0.0077\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5270e-04 - mae: 0.0199 - mse: 9.5270e-04 - val_loss: 0.0076 - val_mae: 0.0326 - val_mse: 0.0076\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8129e-04 - mae: 0.0200 - mse: 9.8129e-04 - val_loss: 0.0077 - val_mae: 0.0321 - val_mse: 0.0077\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3545e-04 - mae: 0.0198 - mse: 9.3545e-04 - val_loss: 0.0076 - val_mae: 0.0320 - val_mse: 0.0076\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4133e-04 - mae: 0.0199 - mse: 9.4133e-04 - val_loss: 0.0076 - val_mae: 0.0322 - val_mse: 0.0076\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5349e-04 - mae: 0.0200 - mse: 9.5349e-04 - val_loss: 0.0075 - val_mae: 0.0327 - val_mse: 0.0075\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6217e-04 - mae: 0.0199 - mse: 9.6217e-04 - val_loss: 0.0076 - val_mae: 0.0324 - val_mse: 0.0076\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3131e-04 - mae: 0.0199 - mse: 9.3131e-04 - val_loss: 0.0075 - val_mae: 0.0322 - val_mse: 0.0075\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7119e-04 - mae: 0.0200 - mse: 9.7119e-04 - val_loss: 0.0076 - val_mae: 0.0323 - val_mse: 0.0076\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4087e-04 - mae: 0.0198 - mse: 9.4087e-04 - val_loss: 0.0077 - val_mae: 0.0320 - val_mse: 0.0077\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4227e-04 - mae: 0.0198 - mse: 9.4227e-04 - val_loss: 0.0079 - val_mae: 0.0325 - val_mse: 0.0079\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4300e-04 - mae: 0.0199 - mse: 9.4300e-04 - val_loss: 0.0076 - val_mae: 0.0324 - val_mse: 0.0076\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4014e-04 - mae: 0.0199 - mse: 9.4014e-04 - val_loss: 0.0074 - val_mae: 0.0326 - val_mse: 0.0074\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3775e-04 - mae: 0.0198 - mse: 9.3775e-04 - val_loss: 0.0076 - val_mae: 0.0332 - val_mse: 0.0076\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2729e-04 - mae: 0.0198 - mse: 9.2729e-04 - val_loss: 0.0075 - val_mae: 0.0327 - val_mse: 0.0075\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6631e-04 - mae: 0.0199 - mse: 9.6631e-04 - val_loss: 0.0075 - val_mae: 0.0327 - val_mse: 0.0075\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6680e-04 - mae: 0.0199 - mse: 9.6680e-04 - val_loss: 0.0076 - val_mae: 0.0323 - val_mse: 0.0076\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5656e-04 - mae: 0.0199 - mse: 9.5656e-04 - val_loss: 0.0077 - val_mae: 0.0324 - val_mse: 0.0077\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2908e-04 - mae: 0.0197 - mse: 9.2908e-04 - val_loss: 0.0076 - val_mae: 0.0327 - val_mse: 0.0076\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5375e-04 - mae: 0.0198 - mse: 9.5375e-04 - val_loss: 0.0078 - val_mae: 0.0325 - val_mse: 0.0078\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4138e-04 - mae: 0.0198 - mse: 9.4138e-04 - val_loss: 0.0077 - val_mae: 0.0321 - val_mse: 0.0077\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8253e-04 - mae: 0.0198 - mse: 9.8253e-04 - val_loss: 0.0077 - val_mae: 0.0321 - val_mse: 0.0077\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3702e-04 - mae: 0.0197 - mse: 9.3702e-04 - val_loss: 0.0077 - val_mae: 0.0320 - val_mse: 0.0077\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3516e-04 - mae: 0.0198 - mse: 9.3516e-04 - val_loss: 0.0076 - val_mae: 0.0324 - val_mse: 0.0076\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3688e-04 - mae: 0.0197 - mse: 9.3688e-04 - val_loss: 0.0077 - val_mae: 0.0330 - val_mse: 0.0077\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3910e-04 - mae: 0.0197 - mse: 9.3910e-04 - val_loss: 0.0076 - val_mae: 0.0320 - val_mse: 0.0076\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 6s 5ms/step - loss: 0.0616 - mae: 0.1599 - mse: 0.0616 - val_loss: 0.0077 - val_mae: 0.0554 - val_mse: 0.0077\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0062 - mae: 0.0609 - mse: 0.0062 - val_loss: 0.0046 - val_mae: 0.0324 - val_mse: 0.0046\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0049 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0047 - val_mae: 0.0346 - val_mse: 0.0047\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0044 - mae: 0.0507 - mse: 0.0044 - val_loss: 0.0045 - val_mae: 0.0316 - val_mse: 0.0045\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0041 - mae: 0.0485 - mse: 0.0041 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0037 - mae: 0.0462 - mse: 0.0037 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0448 - mse: 0.0035 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0033 - mae: 0.0430 - mse: 0.0033 - val_loss: 0.0045 - val_mae: 0.0315 - val_mse: 0.0045\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0031 - mae: 0.0418 - mse: 0.0031 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0402 - mse: 0.0029 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0026 - val_loss: 0.0048 - val_mae: 0.0363 - val_mse: 0.0048\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0370 - mse: 0.0025 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0349 - mse: 0.0022 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0341 - mse: 0.0021 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0333 - mse: 0.0020 - val_loss: 0.0046 - val_mae: 0.0316 - val_mse: 0.0046\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0325 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0310 - mse: 0.0018 - val_loss: 0.0045 - val_mae: 0.0314 - val_mse: 0.0045\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0305 - mse: 0.0017 - val_loss: 0.0045 - val_mae: 0.0316 - val_mse: 0.0045\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0297 - mse: 0.0017 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0016 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0016 - mae: 0.0286 - mse: 0.0016 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0280 - mse: 0.0015 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0015 - mae: 0.0275 - mse: 0.0015 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0271 - mse: 0.0014 - val_loss: 0.0045 - val_mae: 0.0315 - val_mse: 0.0045\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0268 - mse: 0.0014 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0014 - mae: 0.0263 - mse: 0.0014 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0013 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0013 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0249 - mse: 0.0012 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0248 - mse: 0.0013 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0246 - mse: 0.0013 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0240 - mse: 0.0012 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0240 - mse: 0.0012 - val_loss: 0.0046 - val_mae: 0.0321 - val_mse: 0.0046\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0236 - mse: 0.0012 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0234 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0316 - val_mse: 0.0045\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0230 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0229 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0313 - val_mse: 0.0045\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0226 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011 - val_loss: 0.0046 - val_mae: 0.0328 - val_mse: 0.0046\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0223 - mse: 0.0011 - val_loss: 0.0046 - val_mae: 0.0315 - val_mse: 0.0046\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0221 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0313 - val_mse: 0.0045\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0219 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0313 - val_mse: 0.0045\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0217 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.9901e-04 - mae: 0.0213 - mse: 9.9901e-04 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0213 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0313 - val_mse: 0.0045\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0212 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0212 - mse: 0.0011 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.9618e-04 - mae: 0.0208 - mse: 9.9618e-04 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0046 - val_mae: 0.0319 - val_mse: 0.0046\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.8871e-04 - mae: 0.0208 - mse: 9.8871e-04 - val_loss: 0.0045 - val_mae: 0.0314 - val_mse: 0.0045\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.9733e-04 - mae: 0.0206 - mse: 9.9733e-04 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0208 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.6760e-04 - mae: 0.0205 - mse: 9.6760e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0206 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0206 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0306 - val_mse: 0.0045\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.9229e-04 - mae: 0.0204 - mse: 9.9229e-04 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.6881e-04 - mae: 0.0204 - mse: 9.6881e-04 - val_loss: 0.0046 - val_mae: 0.0325 - val_mse: 0.0046\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0205 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.7672e-04 - mae: 0.0204 - mse: 9.7672e-04 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7312e-04 - mae: 0.0204 - mse: 9.7312e-04 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4901e-04 - mae: 0.0202 - mse: 9.4901e-04 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7326e-04 - mae: 0.0203 - mse: 9.7326e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5178e-04 - mae: 0.0202 - mse: 9.5178e-04 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9916e-04 - mae: 0.0204 - mse: 9.9916e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9343e-04 - mae: 0.0202 - mse: 9.9343e-04 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9129e-04 - mae: 0.0203 - mse: 9.9129e-04 - val_loss: 0.0045 - val_mae: 0.0313 - val_mse: 0.0045\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4052e-04 - mae: 0.0201 - mse: 9.4052e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6809e-04 - mae: 0.0202 - mse: 9.6809e-04 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7337e-04 - mae: 0.0203 - mse: 9.7337e-04 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7745e-04 - mae: 0.0203 - mse: 9.7745e-04 - val_loss: 0.0045 - val_mae: 0.0311 - val_mse: 0.0045\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7459e-04 - mae: 0.0202 - mse: 9.7459e-04 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5395e-04 - mae: 0.0202 - mse: 9.5395e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9357e-04 - mae: 0.0201 - mse: 9.9357e-04 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4042e-04 - mae: 0.0200 - mse: 9.4042e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3376e-04 - mae: 0.0200 - mse: 9.3376e-04 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5205e-04 - mae: 0.0201 - mse: 9.5205e-04 - val_loss: 0.0046 - val_mae: 0.0317 - val_mse: 0.0046\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6777e-04 - mae: 0.0201 - mse: 9.6777e-04 - val_loss: 0.0045 - val_mae: 0.0315 - val_mse: 0.0045\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5372e-04 - mae: 0.0200 - mse: 9.5372e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6528e-04 - mae: 0.0201 - mse: 9.6528e-04 - val_loss: 0.0045 - val_mae: 0.0310 - val_mse: 0.0045\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7961e-04 - mae: 0.0201 - mse: 9.7961e-04 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6902e-04 - mae: 0.0200 - mse: 9.6902e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6986e-04 - mae: 0.0200 - mse: 9.6986e-04 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6813e-04 - mae: 0.0201 - mse: 9.6813e-04 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5665e-04 - mae: 0.0201 - mse: 9.5665e-04 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5302e-04 - mae: 0.0199 - mse: 9.5302e-04 - val_loss: 0.0045 - val_mae: 0.0307 - val_mse: 0.0045\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6589e-04 - mae: 0.0201 - mse: 9.6589e-04 - val_loss: 0.0046 - val_mae: 0.0328 - val_mse: 0.0046\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7819e-04 - mae: 0.0202 - mse: 9.7819e-04 - val_loss: 0.0045 - val_mae: 0.0308 - val_mse: 0.0045\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.9170e-04 - mae: 0.0201 - mse: 9.9170e-04 - val_loss: 0.0045 - val_mae: 0.0314 - val_mse: 0.0045\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4547e-04 - mae: 0.0200 - mse: 9.4547e-04 - val_loss: 0.0045 - val_mae: 0.0312 - val_mse: 0.0045\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4759e-04 - mae: 0.0200 - mse: 9.4759e-04 - val_loss: 0.0045 - val_mae: 0.0309 - val_mse: 0.0045\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 985us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\4221429961.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "659/659 [==============================] - 6s 5ms/step - loss: 0.0673 - mae: 0.1701 - mse: 0.0673 - val_loss: 0.0089 - val_mae: 0.0605 - val_mse: 0.0089\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0070 - mae: 0.0649 - mse: 0.0070 - val_loss: 0.0055 - val_mae: 0.0328 - val_mse: 0.0055\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0053 - mae: 0.0554 - mse: 0.0053 - val_loss: 0.0054 - val_mae: 0.0324 - val_mse: 0.0054\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0047 - mae: 0.0521 - mse: 0.0047 - val_loss: 0.0055 - val_mae: 0.0345 - val_mse: 0.0055\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0043 - mae: 0.0499 - mse: 0.0043 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0040 - mae: 0.0480 - mse: 0.0040 - val_loss: 0.0054 - val_mae: 0.0324 - val_mse: 0.0054\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0038 - mae: 0.0464 - mse: 0.0038 - val_loss: 0.0054 - val_mae: 0.0341 - val_mse: 0.0054\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0448 - mse: 0.0035 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0032 - mae: 0.0429 - mse: 0.0032 - val_loss: 0.0054 - val_mae: 0.0336 - val_mse: 0.0054\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0031 - mae: 0.0419 - mse: 0.0031 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0028 - mae: 0.0400 - mse: 0.0028 - val_loss: 0.0053 - val_mae: 0.0320 - val_mse: 0.0053\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0027 - mae: 0.0388 - mse: 0.0027 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0373 - mse: 0.0025 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0362 - mse: 0.0024 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0347 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0341 - mse: 0.0021 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0330 - mse: 0.0020 - val_loss: 0.0054 - val_mae: 0.0324 - val_mse: 0.0054\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0020 - val_loss: 0.0053 - val_mae: 0.0321 - val_mse: 0.0053\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0317 - mse: 0.0018 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0018 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0017 - val_loss: 0.0054 - val_mae: 0.0324 - val_mse: 0.0054\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0016 - val_loss: 0.0054 - val_mae: 0.0314 - val_mse: 0.0054\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0015 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0015 - val_loss: 0.0055 - val_mae: 0.0337 - val_mse: 0.0055\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0015 - val_loss: 0.0053 - val_mae: 0.0319 - val_mse: 0.0053\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0014 - mae: 0.0270 - mse: 0.0014 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0013 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0014 - mae: 0.0260 - mse: 0.0014 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0013 - mae: 0.0254 - mse: 0.0013 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0253 - mse: 0.0013 - val_loss: 0.0054 - val_mae: 0.0332 - val_mse: 0.0054\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0013 - mae: 0.0248 - mse: 0.0013 - val_loss: 0.0054 - val_mae: 0.0326 - val_mse: 0.0054\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0243 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 33/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0240 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0331 - val_mse: 0.0053\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0012 - mae: 0.0237 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0012 - mae: 0.0234 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0231 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0228 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0318 - val_mse: 0.0053\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0226 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0224 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0319 - val_mse: 0.0053\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0225 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0313 - val_mse: 0.0052\n",
      "Epoch 42/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0218 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0317 - val_mse: 0.0053\n",
      "Epoch 43/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0011 - mae: 0.0218 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0215 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0214 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.8623e-04 - mae: 0.0211 - mse: 9.8623e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 0.0010 - mae: 0.0214 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0315 - val_mse: 0.0053\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0211 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0320 - val_mse: 0.0053\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.8415e-04 - mae: 0.0209 - mse: 9.8415e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0317 - val_mse: 0.0053\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.9855e-04 - mae: 0.0208 - mse: 9.9855e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.4281e-04 - mae: 0.0206 - mse: 9.4281e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 54/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.9968e-04 - mae: 0.0206 - mse: 9.9968e-04 - val_loss: 0.0053 - val_mae: 0.0319 - val_mse: 0.0053\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 2s 3ms/step - loss: 9.6061e-04 - mae: 0.0206 - mse: 9.6061e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 2s 4ms/step - loss: 9.6627e-04 - mae: 0.0204 - mse: 9.6627e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 0.0010 - mae: 0.0204 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0317 - val_mse: 0.0053\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 3s 4ms/step - loss: 9.4265e-04 - mae: 0.0203 - mse: 9.4265e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7821e-04 - mae: 0.0203 - mse: 9.7821e-04 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8821e-04 - mae: 0.0204 - mse: 9.8821e-04 - val_loss: 0.0054 - val_mae: 0.0311 - val_mse: 0.0054\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4510e-04 - mae: 0.0203 - mse: 9.4510e-04 - val_loss: 0.0054 - val_mae: 0.0315 - val_mse: 0.0054\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5614e-04 - mae: 0.0202 - mse: 9.5614e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6840e-04 - mae: 0.0203 - mse: 9.6840e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8543e-04 - mae: 0.0203 - mse: 9.8543e-04 - val_loss: 0.0053 - val_mae: 0.0318 - val_mse: 0.0053\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3763e-04 - mae: 0.0202 - mse: 9.3763e-04 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 66/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8120e-04 - mae: 0.0202 - mse: 9.8120e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 67/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8881e-04 - mae: 0.0201 - mse: 9.8881e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 68/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0053 - val_mae: 0.0315 - val_mse: 0.0053\n",
      "Epoch 69/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7359e-04 - mae: 0.0202 - mse: 9.7359e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 70/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7361e-04 - mae: 0.0200 - mse: 9.7361e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 71/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3668e-04 - mae: 0.0200 - mse: 9.3668e-04 - val_loss: 0.0053 - val_mae: 0.0315 - val_mse: 0.0053\n",
      "Epoch 72/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3315e-04 - mae: 0.0200 - mse: 9.3315e-04 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 73/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3022e-04 - mae: 0.0200 - mse: 9.3022e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 74/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3440e-04 - mae: 0.0200 - mse: 9.3440e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 75/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3300e-04 - mae: 0.0199 - mse: 9.3300e-04 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 76/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8789e-04 - mae: 0.0201 - mse: 9.8789e-04 - val_loss: 0.0054 - val_mae: 0.0314 - val_mse: 0.0054\n",
      "Epoch 77/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6664e-04 - mae: 0.0200 - mse: 9.6664e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 78/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3072e-04 - mae: 0.0198 - mse: 9.3072e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 79/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3510e-04 - mae: 0.0199 - mse: 9.3510e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 80/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3417e-04 - mae: 0.0199 - mse: 9.3417e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 81/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7041e-04 - mae: 0.0200 - mse: 9.7041e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 82/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3034e-04 - mae: 0.0198 - mse: 9.3034e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 83/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2470e-04 - mae: 0.0199 - mse: 9.2470e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 84/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8822e-04 - mae: 0.0201 - mse: 9.8822e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 85/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7843e-04 - mae: 0.0201 - mse: 9.7843e-04 - val_loss: 0.0053 - val_mae: 0.0316 - val_mse: 0.0053\n",
      "Epoch 86/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.3787e-04 - mae: 0.0198 - mse: 9.3787e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 87/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6901e-04 - mae: 0.0200 - mse: 9.6901e-04 - val_loss: 0.0054 - val_mae: 0.0318 - val_mse: 0.0054\n",
      "Epoch 88/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5007e-04 - mae: 0.0201 - mse: 9.5007e-04 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 89/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6091e-04 - mae: 0.0199 - mse: 9.6091e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "Epoch 90/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2159e-04 - mae: 0.0198 - mse: 9.2159e-04 - val_loss: 0.0053 - val_mae: 0.0311 - val_mse: 0.0053\n",
      "Epoch 91/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2705e-04 - mae: 0.0198 - mse: 9.2705e-04 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 92/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2852e-04 - mae: 0.0198 - mse: 9.2852e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 93/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6349e-04 - mae: 0.0199 - mse: 9.6349e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 94/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2044e-04 - mae: 0.0198 - mse: 9.2044e-04 - val_loss: 0.0053 - val_mae: 0.0310 - val_mse: 0.0053\n",
      "Epoch 95/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.4124e-04 - mae: 0.0198 - mse: 9.4124e-04 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 96/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.6794e-04 - mae: 0.0199 - mse: 9.6794e-04 - val_loss: 0.0053 - val_mae: 0.0314 - val_mse: 0.0053\n",
      "Epoch 97/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.7148e-04 - mae: 0.0200 - mse: 9.7148e-04 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 98/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.2200e-04 - mae: 0.0198 - mse: 9.2200e-04 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 99/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.5357e-04 - mae: 0.0200 - mse: 9.5357e-04 - val_loss: 0.0053 - val_mae: 0.0313 - val_mse: 0.0053\n",
      "Epoch 100/100\n",
      "659/659 [==============================] - 3s 5ms/step - loss: 9.8494e-04 - mae: 0.0201 - mse: 9.8494e-04 - val_loss: 0.0053 - val_mae: 0.0312 - val_mse: 0.0053\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n",
      "Results saved to models_exp/Ensemble_XGBoost_LSTM_GRU/exp_20240905_192622/exp_48_128_0.2/exp_48_128_0.2_20240905_201514.xlsx\n",
      "Results for cycle written to models_exp/Ensemble_XGBoost_LSTM_GRU/exp_20240905_192622/exp_48_128_0.2_20240905_201514_combined.xlsx\n",
      "Model eğitimi ve değerlendirmesi tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import xgboost as xgb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Batch size'leri tanımla\n",
    "batch_sizes = [48]\n",
    "unit_sizes = [128]\n",
    "dropout_sizes = [0.2]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"n_estimators_list = [100, 200, 300]\n",
    "learning_rate_list = [0.01, 0.1, 0.2]\n",
    "max_depth_list = [6, 8, 10, 12]\n",
    "subsample_list = [0.7, 0.8, 0.9]\n",
    "colsample_bytree_list = [0.7, 0.8, 0.9]\"\"\"\n",
    "n_estimators = 300\n",
    "learning_rate = 0.1\n",
    "max_depth = 10\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "\n",
    "                   \n",
    "\n",
    "model_n = 'Ensemble_XGBoost_LSTM_GRU'\n",
    "# Klasör oluşturma\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder_main = f'models_exp/{model_n}'\n",
    "os.makedirs(folder_main, exist_ok=True)\n",
    "\n",
    "folder = f'{folder_main}/exp_{timestamp}'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for unit_size in unit_sizes:\n",
    "        for dropout_size in dropout_sizes:\n",
    "            fold_no = 1\n",
    "            all_fold_histories = []\n",
    "            params = []\n",
    "            fold_results = []\n",
    "\n",
    "            # Model parameters\n",
    "            params.append({\n",
    "                'File name': selected_file,\n",
    "                'Total Fold': 10,\n",
    "                'LSTM Units': unit_size,\n",
    "                'GRU Units': unit_size,\n",
    "                'Dropout Rate': dropout_size,\n",
    "                'Dense Units': 100,\n",
    "                'Batch Size': batch_size,\n",
    "                'Epochs': 100,\n",
    "                'LearningRate': '0.001',\n",
    "                'Normalizasyon': selected_norm,\n",
    "            })\n",
    "\n",
    "            kf = KFold(n_splits=params[0]['Total Fold'], shuffle=False)\n",
    "\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                # Create train/validation splits within each fold\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                # Feature extraction with XGBoost\n",
    "                # XGBoost model\n",
    "                xgb_model = xgb.XGBRegressor(\n",
    "                    n_estimators=n_estimators,\n",
    "                    learning_rate=learning_rate,\n",
    "                    max_depth=max_depth,\n",
    "                    subsample=subsample,\n",
    "                    colsample_bytree=colsample_bytree\n",
    "                )\n",
    "                xgb_model.fit(X_train_fold, y_train_fold)\n",
    "                X_train_fold_xgb = xgb_model.predict(X_train_fold).reshape(-1, 1)\n",
    "                X_val_fold_xgb = xgb_model.predict(X_val_fold).reshape(-1, 1)\n",
    "                X_test_xgb = xgb_model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "                # Reshape the data\n",
    "                X_train_fold_xgb = np.array(X_train_fold_xgb).reshape((X_train_fold_xgb.shape[0], X_train_fold_xgb.shape[1], 1))\n",
    "                X_val_fold_xgb = np.array(X_val_fold_xgb).reshape((X_val_fold_xgb.shape[0], X_val_fold_xgb.shape[1], 1))\n",
    "                X_test_xgb = np.array(X_test_xgb).reshape((X_test_xgb.shape[0], X_test_xgb.shape[1], 1))\n",
    "\n",
    "                # Define the model\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(units=params[0]['LSTM Units'], activation='tanh', input_shape=(X_train_fold_xgb.shape[1], X_train_fold_xgb.shape[2]), return_sequences=True))\n",
    "                model.add(Dropout(params[0]['Dropout Rate']))\n",
    "                model.add(GRU(units=params[0]['GRU Units'], activation='tanh', return_sequences=True))\n",
    "                model.add(Dropout(params[0]['Dropout Rate']))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(params[0]['Dense Units'], activation='relu'))\n",
    "                model.add(Dropout(params[0]['Dropout Rate']))\n",
    "                model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "\n",
    "                # Train the model\n",
    "                history = model.fit(X_train_fold_xgb, y_train_fold, validation_data=(X_val_fold_xgb, y_val_fold), epochs=params[0]['Epochs'], batch_size=params[0]['Batch Size'])\n",
    "\n",
    "                # Store fold history\n",
    "                all_fold_histories.append(history.history)\n",
    "\n",
    "                # Calculate RMSE for training, validation, and test sets\n",
    "                train_rmse = np.sqrt(history.history['mse'][-1])\n",
    "                val_rmse = np.sqrt(history.history['val_mse'][-1])\n",
    "\n",
    "                test_results = model.evaluate(X_test_xgb, y_test, verbose=0)\n",
    "                test_rmse = np.sqrt(test_results[2])\n",
    "\n",
    "                # Calculate R^2 scores\n",
    "                y_pred_train = model.predict(X_train_fold_xgb).flatten()\n",
    "                y_pred_val = model.predict(X_val_fold_xgb).flatten()\n",
    "                y_pred_test = model.predict(X_test_xgb).flatten()\n",
    "\n",
    "                r2_train = r2_score(y_train_fold, y_pred_train)\n",
    "                r2_val = r2_score(y_val_fold, y_pred_val)\n",
    "                r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "                # Store fold results\n",
    "                fold_results.append({\n",
    "                    'Fold': fold_no,\n",
    "                    'Training Size': len(X_train_fold),\n",
    "                    'Validation Size': len(X_val_fold),\n",
    "                    'Test Size': len(X_test_xgb),\n",
    "                    'Training Loss': history.history['loss'][-1],\n",
    "                    'Validation Loss': history.history['val_loss'][-1],\n",
    "                    'Training MAE': history.history['mae'][-1],\n",
    "                    'Validation MAE': history.history['val_mae'][-1],\n",
    "                    'Training MSE': history.history['mse'][-1],\n",
    "                    'Validation MSE': history.history['val_mse'][-1],\n",
    "                    'Test Loss': test_results[0],\n",
    "                    'Test MAE': test_results[1],\n",
    "                    'Test MSE': test_results[2],\n",
    "                    'Training RMSE': train_rmse,\n",
    "                    'Validation RMSE': val_rmse,\n",
    "                    'Test RMSE': test_rmse,\n",
    "                    'Training R^2': r2_train,\n",
    "                    'Validation R^2': r2_val,\n",
    "                    'Test R^2': r2_test\n",
    "                })\n",
    "\n",
    "                fold_no += 1\n",
    "\n",
    "            # Tüm fold'ların sonuçlarını ortalama alma\n",
    "            average_history = {\n",
    "                'Epoch': np.arange(1, params[0]['Epochs'] + 1),\n",
    "                'Loss': np.mean(np.array([h['loss'] for h in all_fold_histories]).T, axis=1),\n",
    "                'Val_Loss': np.mean(np.array([h['val_loss'] for h in all_fold_histories]).T, axis=1),\n",
    "                'MAE': np.mean(np.array([h['mae'] for h in all_fold_histories]).T, axis=1),\n",
    "                'Val_MAE': np.mean(np.array([h['val_mae'] for h in all_fold_histories]).T, axis=1),\n",
    "                'MSE': np.mean(np.array([h['mse'] for h in all_fold_histories]).T, axis=1),\n",
    "                'Val_MSE': np.mean(np.array([h['val_mse'] for h in all_fold_histories]).T, axis=1),\n",
    "            }\n",
    "\n",
    "            # Ortalama RMSE hesaplama\n",
    "            average_rmse = {\n",
    "                'Epoch': average_history['Epoch'],\n",
    "                'Train_RMSE': np.sqrt(average_history['MSE']),\n",
    "                'Val_RMSE': np.sqrt(average_history['Val_MSE'])\n",
    "            }\n",
    "\n",
    "            # Ortalama fold sonuçlarını hesapla\n",
    "            average_fold_results = {\n",
    "                'Training Size': len(X_train_fold),\n",
    "                'Validation Size': len(X_val_fold),\n",
    "                'Test Size': len(X_test_xgb),\n",
    "                'Average Training Loss': np.mean([result['Training Loss'] for result in fold_results if not np.isnan(result['Training Loss'])]),\n",
    "                'Average Validation Loss': np.mean([result['Validation Loss'] for result in fold_results if not np.isnan(result['Validation Loss'])]),\n",
    "                'Average Test Loss': np.mean([result['Test Loss'] for result in fold_results if not np.isnan(result['Test Loss'])]),\n",
    "                'Average Training MAE': np.mean([result['Training MAE'] for result in fold_results if not np.isnan(result['Training MAE'])]),\n",
    "                'Average Validation MAE': np.mean([result['Validation MAE'] for result in fold_results if not np.isnan(result['Validation MAE'])]),\n",
    "                'Average Test MAE': np.mean([result['Test MAE'] for result in fold_results if not np.isnan(result['Test MAE'])]),\n",
    "                'Average Training MSE': np.mean([result['Training MSE'] for result in fold_results if not np.isnan(result['Training MSE'])]),\n",
    "                'Average Validation MSE': np.mean([result['Validation MSE'] for result in fold_results if not np.isnan(result['Validation MSE'])]),\n",
    "                'Average Test MSE': np.mean([result['Test MSE'] for result in fold_results if not np.isnan(result['Test MSE'])]),\n",
    "                'Average Training RMSE': np.mean([result['Training RMSE'] for result in fold_results if not np.isnan(result['Training RMSE'])]),\n",
    "                'Average Validation RMSE': np.mean([result['Validation RMSE'] for result in fold_results if not np.isnan(result['Validation RMSE'])]),\n",
    "                'Average Test RMSE': np.mean([result['Test RMSE'] for result in fold_results if not np.isnan(result['Test RMSE'])]),\n",
    "                'Average Training R^2': np.mean([result['Training R^2'] for result in fold_results if not np.isnan(result['Training R^2'])]),\n",
    "                'Average Validation R^2': np.mean([result['Validation R^2'] for result in fold_results if not np.isnan(result['Validation R^2'])]),\n",
    "                'Average Test R^2': np.mean([result['Test R^2'] for result in fold_results if not np.isnan(result['Test R^2'])]),\n",
    "            }\n",
    "\n",
    "            # Sonuçları ve model parametrelerini Excel dosyasına kaydetme\n",
    "            results_df = pd.DataFrame(average_history)\n",
    "            params_df = pd.DataFrame(params)\n",
    "            fold_results_df = pd.DataFrame(fold_results)\n",
    "            average_rmse_df = pd.DataFrame(average_rmse)\n",
    "            average_fold_results_df = pd.DataFrame([average_fold_results])\n",
    "\n",
    "            # Klasör oluşturma\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            name_detailed = f\"exp_{batch_size}_{unit_size}_{dropout_size}\"\n",
    "            folder_name = f'{folder}/{name_detailed}'\n",
    "            os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "            # Dosya adı oluşturma\n",
    "            file_name = f'{name_detailed}_{timestamp}.xlsx'  \n",
    "            file_path = os.path.join(folder_name, file_name)\n",
    "            file_path = file_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama kaybını çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_history['Epoch'], average_history['Loss'], label='Training Loss (average)')\n",
    "            plt.plot(average_history['Epoch'], average_history['Val_Loss'], label='Validation Loss (average)')\n",
    "            plt.title('Model Loss - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_loss.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama MAE'yi çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_history['Epoch'], average_history['MAE'], label='Training MAE (average)')\n",
    "            plt.plot(average_history['Epoch'], average_history['Val_MAE'], label='Validation MAE (average)')\n",
    "            plt.title('Model MAE - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_mae.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama MSE'yi çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_history['Epoch'], average_history['MSE'], label='Training MSE (average)')\n",
    "            plt.plot(average_history['Epoch'], average_history['Val_MSE'], label='Validation MSE (average)')\n",
    "            plt.title('Model MSE - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_mse.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama RMSE'sini çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_rmse['Epoch'], average_rmse['Train_RMSE'], label='Training RMSE (average)')\n",
    "            plt.plot(average_rmse['Epoch'], average_rmse['Val_RMSE'], label='Validation RMSE (average)')\n",
    "            plt.title('Model RMSE - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_rmse.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Excel dosyasına veri yazma\n",
    "            with pd.ExcelWriter(file_path) as writer:\n",
    "                results_df.to_excel(writer, sheet_name='Average History', index=False)\n",
    "                params_df.to_excel(writer, sheet_name='Model Parameters', index=False)\n",
    "                fold_results_df.to_excel(writer, sheet_name='Fold Results', index=False)\n",
    "                average_rmse_df.to_excel(writer, sheet_name='Average RMSE', index=False)\n",
    "                average_fold_results_df.to_excel(writer, sheet_name='Average Fold Results', index=False)\n",
    "\n",
    "            print(f'Results saved to {file_path}')\n",
    "            \n",
    "            # İki veri çerçevesini yatay olarak birleştir (axis=1 ile)\n",
    "            combined_df = pd.concat([params_df, average_fold_results_df], axis=1)\n",
    "\n",
    "            file_name2 = f'{name_detailed}_{timestamp}_combined.xlsx'  \n",
    "            file_path2 = os.path.join(folder, file_name2)\n",
    "            file_path2 = file_path2.replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            # ExcelWriter ile dosyayı aç ve veri çerçevesini yaz\n",
    "            with pd.ExcelWriter(file_path2, engine='openpyxl') as writer:\n",
    "                combined_df.to_excel(writer, sheet_name='Cumulative Results', index=False)\n",
    "\n",
    "            print(f\"Results for cycle written to {file_path2}\")\n",
    "\n",
    "print(\"Model eğitimi ve değerlendirmesi tamamlandı.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_hyrid_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hibrit Model FİNAL v02 TimeSeriesSplit (XGBoost + LSTM-GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 3s 10ms/step - loss: 0.0805 - mae: 0.2015 - mse: 0.0805 - val_loss: 0.0237 - val_mae: 0.1013 - val_mse: 0.0237\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0830 - mse: 0.0118 - val_loss: 0.0171 - val_mae: 0.0708 - val_mse: 0.0171\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0066 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0165 - val_mae: 0.0636 - val_mse: 0.0165\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0565 - mse: 0.0053 - val_loss: 0.0164 - val_mae: 0.0625 - val_mse: 0.0164\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0544 - mse: 0.0048 - val_loss: 0.0162 - val_mae: 0.0604 - val_mse: 0.0162\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0521 - mse: 0.0045 - val_loss: 0.0163 - val_mae: 0.0606 - val_mse: 0.0163\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0511 - mse: 0.0043 - val_loss: 0.0160 - val_mae: 0.0608 - val_mse: 0.0160\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0499 - mse: 0.0041 - val_loss: 0.0161 - val_mae: 0.0605 - val_mse: 0.0161\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0480 - mse: 0.0038 - val_loss: 0.0164 - val_mae: 0.0632 - val_mse: 0.0164\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0039 - mae: 0.0474 - mse: 0.0039 - val_loss: 0.0163 - val_mae: 0.0641 - val_mse: 0.0163\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0037 - mae: 0.0469 - mse: 0.0037 - val_loss: 0.0160 - val_mae: 0.0607 - val_mse: 0.0160\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0457 - mse: 0.0036 - val_loss: 0.0161 - val_mae: 0.0608 - val_mse: 0.0161\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0439 - mse: 0.0033 - val_loss: 0.0160 - val_mae: 0.0605 - val_mse: 0.0160\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0441 - mse: 0.0033 - val_loss: 0.0160 - val_mae: 0.0608 - val_mse: 0.0160\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0438 - mse: 0.0033 - val_loss: 0.0163 - val_mae: 0.0656 - val_mse: 0.0163\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0431 - mse: 0.0031 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0425 - mse: 0.0030 - val_loss: 0.0162 - val_mae: 0.0623 - val_mse: 0.0162\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0419 - mse: 0.0031 - val_loss: 0.0159 - val_mae: 0.0606 - val_mse: 0.0159\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0418 - mse: 0.0029 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0403 - mse: 0.0028 - val_loss: 0.0159 - val_mae: 0.0604 - val_mse: 0.0159\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0412 - mse: 0.0028 - val_loss: 0.0161 - val_mae: 0.0617 - val_mse: 0.0161\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0405 - mse: 0.0028 - val_loss: 0.0161 - val_mae: 0.0622 - val_mse: 0.0161\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0387 - mse: 0.0025 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0393 - mse: 0.0027 - val_loss: 0.0161 - val_mae: 0.0625 - val_mse: 0.0161\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0403 - mse: 0.0027 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0024 - val_loss: 0.0163 - val_mae: 0.0615 - val_mse: 0.0163\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0372 - mse: 0.0024 - val_loss: 0.0160 - val_mae: 0.0619 - val_mse: 0.0160\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0383 - mse: 0.0025 - val_loss: 0.0161 - val_mae: 0.0610 - val_mse: 0.0161\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0386 - mse: 0.0025 - val_loss: 0.0159 - val_mae: 0.0604 - val_mse: 0.0159\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0384 - mse: 0.0025 - val_loss: 0.0159 - val_mae: 0.0604 - val_mse: 0.0159\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0024 - mae: 0.0372 - mse: 0.0024 - val_loss: 0.0161 - val_mae: 0.0619 - val_mse: 0.0161\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0383 - mse: 0.0025 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0359 - mse: 0.0022 - val_loss: 0.0159 - val_mae: 0.0622 - val_mse: 0.0159\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0370 - mse: 0.0023 - val_loss: 0.0161 - val_mae: 0.0609 - val_mse: 0.0161\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0346 - mse: 0.0021 - val_loss: 0.0159 - val_mae: 0.0604 - val_mse: 0.0159\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0348 - mse: 0.0020 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0355 - mse: 0.0023 - val_loss: 0.0165 - val_mae: 0.0623 - val_mse: 0.0165\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0340 - mse: 0.0020 - val_loss: 0.0161 - val_mae: 0.0617 - val_mse: 0.0161\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0345 - mse: 0.0021 - val_loss: 0.0159 - val_mae: 0.0604 - val_mse: 0.0159\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0339 - mse: 0.0019 - val_loss: 0.0161 - val_mae: 0.0608 - val_mse: 0.0161\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0347 - mse: 0.0021 - val_loss: 0.0160 - val_mae: 0.0603 - val_mse: 0.0160\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0342 - mse: 0.0022 - val_loss: 0.0173 - val_mae: 0.0653 - val_mse: 0.0173\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0338 - mse: 0.0020 - val_loss: 0.0163 - val_mae: 0.0621 - val_mse: 0.0163\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0324 - mse: 0.0018 - val_loss: 0.0163 - val_mae: 0.0612 - val_mse: 0.0163\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0313 - mse: 0.0017 - val_loss: 0.0161 - val_mae: 0.0604 - val_mse: 0.0161\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0320 - mse: 0.0017 - val_loss: 0.0162 - val_mae: 0.0605 - val_mse: 0.0162\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0312 - mse: 0.0017 - val_loss: 0.0162 - val_mae: 0.0609 - val_mse: 0.0162\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0309 - mse: 0.0016 - val_loss: 0.0162 - val_mae: 0.0603 - val_mse: 0.0162\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0312 - mse: 0.0018 - val_loss: 0.0161 - val_mae: 0.0608 - val_mse: 0.0161\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0322 - mse: 0.0018 - val_loss: 0.0160 - val_mae: 0.0622 - val_mse: 0.0160\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0311 - mse: 0.0016 - val_loss: 0.0162 - val_mae: 0.0616 - val_mse: 0.0162\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0303 - mse: 0.0015 - val_loss: 0.0161 - val_mae: 0.0609 - val_mse: 0.0161\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0305 - mse: 0.0016 - val_loss: 0.0160 - val_mae: 0.0611 - val_mse: 0.0160\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0307 - mse: 0.0016 - val_loss: 0.0167 - val_mae: 0.0650 - val_mse: 0.0167\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0323 - mse: 0.0019 - val_loss: 0.0159 - val_mae: 0.0606 - val_mse: 0.0159\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0292 - mse: 0.0014 - val_loss: 0.0159 - val_mae: 0.0607 - val_mse: 0.0159\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.0161 - val_mae: 0.0606 - val_mse: 0.0161\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0276 - mse: 0.0013 - val_loss: 0.0160 - val_mae: 0.0608 - val_mse: 0.0160\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0283 - mse: 0.0014 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0282 - mse: 0.0014 - val_loss: 0.0162 - val_mae: 0.0627 - val_mse: 0.0162\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0287 - mse: 0.0014 - val_loss: 0.0162 - val_mae: 0.0609 - val_mse: 0.0162\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.0158 - val_mae: 0.0605 - val_mse: 0.0158\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0013 - val_loss: 0.0160 - val_mae: 0.0604 - val_mse: 0.0160\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0293 - mse: 0.0017 - val_loss: 0.0164 - val_mae: 0.0659 - val_mse: 0.0164\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0314 - mse: 0.0019 - val_loss: 0.0158 - val_mae: 0.0604 - val_mse: 0.0158\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0013 - val_loss: 0.0160 - val_mae: 0.0623 - val_mse: 0.0160\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0013 - val_loss: 0.0161 - val_mae: 0.0637 - val_mse: 0.0161\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0258 - mse: 0.0012 - val_loss: 0.0161 - val_mae: 0.0612 - val_mse: 0.0161\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0251 - mse: 0.0011 - val_loss: 0.0159 - val_mae: 0.0605 - val_mse: 0.0159\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0292 - mse: 0.0017 - val_loss: 0.0162 - val_mae: 0.0640 - val_mse: 0.0162\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0013 - val_loss: 0.0159 - val_mae: 0.0606 - val_mse: 0.0159\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0263 - mse: 0.0013 - val_loss: 0.0159 - val_mae: 0.0610 - val_mse: 0.0159\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0268 - mse: 0.0014 - val_loss: 0.0160 - val_mae: 0.0604 - val_mse: 0.0160\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0245 - mse: 0.0011 - val_loss: 0.0158 - val_mae: 0.0608 - val_mse: 0.0158\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0262 - mse: 0.0014 - val_loss: 0.0158 - val_mae: 0.0606 - val_mse: 0.0158\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0012 - val_loss: 0.0159 - val_mae: 0.0614 - val_mse: 0.0159\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0234 - mse: 0.0010 - val_loss: 0.0159 - val_mae: 0.0610 - val_mse: 0.0159\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015 - val_loss: 0.0159 - val_mae: 0.0614 - val_mse: 0.0159\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0242 - mse: 0.0011 - val_loss: 0.0161 - val_mae: 0.0611 - val_mse: 0.0161\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0235 - mse: 0.0011 - val_loss: 0.0165 - val_mae: 0.0626 - val_mse: 0.0165\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0238 - mse: 0.0010 - val_loss: 0.0162 - val_mae: 0.0619 - val_mse: 0.0162\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0238 - mse: 0.0011 - val_loss: 0.0161 - val_mae: 0.0611 - val_mse: 0.0161\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0236 - mse: 0.0010 - val_loss: 0.0158 - val_mae: 0.0603 - val_mse: 0.0158\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0012 - val_loss: 0.0160 - val_mae: 0.0628 - val_mse: 0.0160\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0249 - mse: 0.0012 - val_loss: 0.0158 - val_mae: 0.0607 - val_mse: 0.0158\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0233 - mse: 0.0010 - val_loss: 0.0161 - val_mae: 0.0627 - val_mse: 0.0161\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 9.8483e-04 - mae: 0.0234 - mse: 9.8483e-04 - val_loss: 0.0160 - val_mae: 0.0612 - val_mse: 0.0160\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0237 - mse: 0.0011 - val_loss: 0.0159 - val_mae: 0.0605 - val_mse: 0.0159\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0015 - val_loss: 0.0163 - val_mae: 0.0621 - val_mse: 0.0163\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 9.8890e-04 - mae: 0.0232 - mse: 9.8890e-04 - val_loss: 0.0159 - val_mae: 0.0607 - val_mse: 0.0159\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0235 - mse: 0.0010 - val_loss: 0.0163 - val_mae: 0.0621 - val_mse: 0.0163\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0233 - mse: 0.0010 - val_loss: 0.0160 - val_mae: 0.0619 - val_mse: 0.0160\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 8.8926e-04 - mae: 0.0219 - mse: 8.8926e-04 - val_loss: 0.0162 - val_mae: 0.0613 - val_mse: 0.0162\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 9.6883e-04 - mae: 0.0222 - mse: 9.6883e-04 - val_loss: 0.0160 - val_mae: 0.0607 - val_mse: 0.0160\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 9.2175e-04 - mae: 0.0224 - mse: 9.2175e-04 - val_loss: 0.0159 - val_mae: 0.0605 - val_mse: 0.0159\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 9.7804e-04 - mae: 0.0225 - mse: 9.7804e-04 - val_loss: 0.0162 - val_mae: 0.0606 - val_mse: 0.0162\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0228 - mse: 0.0010 - val_loss: 0.0160 - val_mae: 0.0632 - val_mse: 0.0160\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0253 - mse: 0.0013 - val_loss: 0.0162 - val_mae: 0.0610 - val_mse: 0.0162\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 9.4865e-04 - mae: 0.0219 - mse: 9.4865e-04 - val_loss: 0.0159 - val_mae: 0.0603 - val_mse: 0.0159\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 9.6738e-04 - mae: 0.0219 - mse: 9.6738e-04 - val_loss: 0.0158 - val_mae: 0.0604 - val_mse: 0.0158\n",
      "100/100 [==============================] - 1s 954us/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 974us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "134/134 [==============================] - 3s 7ms/step - loss: 0.0479 - mae: 0.1433 - mse: 0.0479 - val_loss: 0.0145 - val_mae: 0.0591 - val_mse: 0.0145\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0063 - mae: 0.0614 - mse: 0.0063 - val_loss: 0.0128 - val_mae: 0.0524 - val_mse: 0.0128\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0133 - val_mae: 0.0545 - val_mse: 0.0133\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0049 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0132 - val_mae: 0.0576 - val_mse: 0.0132\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0505 - mse: 0.0043 - val_loss: 0.0130 - val_mae: 0.0524 - val_mse: 0.0130\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0486 - mse: 0.0040 - val_loss: 0.0133 - val_mae: 0.0529 - val_mse: 0.0133\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0039 - mae: 0.0484 - mse: 0.0039 - val_loss: 0.0129 - val_mae: 0.0518 - val_mse: 0.0129\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0486 - mse: 0.0040 - val_loss: 0.0144 - val_mae: 0.0635 - val_mse: 0.0144\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0470 - mse: 0.0037 - val_loss: 0.0129 - val_mae: 0.0522 - val_mse: 0.0129\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0455 - mse: 0.0036 - val_loss: 0.0129 - val_mae: 0.0519 - val_mse: 0.0129\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0434 - mse: 0.0032 - val_loss: 0.0127 - val_mae: 0.0519 - val_mse: 0.0127\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0446 - mse: 0.0034 - val_loss: 0.0133 - val_mae: 0.0543 - val_mse: 0.0133\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0430 - mse: 0.0032 - val_loss: 0.0128 - val_mae: 0.0520 - val_mse: 0.0128\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0421 - mse: 0.0030 - val_loss: 0.0127 - val_mae: 0.0523 - val_mse: 0.0127\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0422 - mse: 0.0030 - val_loss: 0.0130 - val_mae: 0.0525 - val_mse: 0.0130\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0411 - mse: 0.0030 - val_loss: 0.0127 - val_mae: 0.0520 - val_mse: 0.0127\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0406 - mse: 0.0029 - val_loss: 0.0129 - val_mae: 0.0572 - val_mse: 0.0129\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0417 - mse: 0.0030 - val_loss: 0.0127 - val_mae: 0.0523 - val_mse: 0.0127\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0025 - val_loss: 0.0129 - val_mae: 0.0517 - val_mse: 0.0129\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0390 - mse: 0.0027 - val_loss: 0.0135 - val_mae: 0.0554 - val_mse: 0.0135\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0031 - mae: 0.0410 - mse: 0.0031 - val_loss: 0.0128 - val_mae: 0.0518 - val_mse: 0.0128\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0377 - mse: 0.0025 - val_loss: 0.0129 - val_mae: 0.0521 - val_mse: 0.0129\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0371 - mse: 0.0024 - val_loss: 0.0126 - val_mae: 0.0545 - val_mse: 0.0126\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0366 - mse: 0.0024 - val_loss: 0.0128 - val_mae: 0.0521 - val_mse: 0.0128\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0372 - mse: 0.0025 - val_loss: 0.0127 - val_mae: 0.0542 - val_mse: 0.0127\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0361 - mse: 0.0023 - val_loss: 0.0127 - val_mae: 0.0521 - val_mse: 0.0127\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0349 - mse: 0.0022 - val_loss: 0.0128 - val_mae: 0.0524 - val_mse: 0.0128\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0127 - val_mae: 0.0522 - val_mse: 0.0127\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0345 - mse: 0.0021 - val_loss: 0.0131 - val_mae: 0.0525 - val_mse: 0.0131\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0332 - mse: 0.0020 - val_loss: 0.0129 - val_mae: 0.0518 - val_mse: 0.0129\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0331 - mse: 0.0020 - val_loss: 0.0129 - val_mae: 0.0518 - val_mse: 0.0129\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0349 - mse: 0.0023 - val_loss: 0.0127 - val_mae: 0.0528 - val_mse: 0.0127\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0351 - mse: 0.0023 - val_loss: 0.0130 - val_mae: 0.0521 - val_mse: 0.0130\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0332 - mse: 0.0020 - val_loss: 0.0129 - val_mae: 0.0524 - val_mse: 0.0129\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0316 - mse: 0.0019 - val_loss: 0.0128 - val_mae: 0.0516 - val_mse: 0.0128\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0020 - val_loss: 0.0133 - val_mae: 0.0542 - val_mse: 0.0133\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0315 - mse: 0.0019 - val_loss: 0.0148 - val_mae: 0.0655 - val_mse: 0.0148\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0388 - mse: 0.0028 - val_loss: 0.0131 - val_mae: 0.0546 - val_mse: 0.0131\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0313 - mse: 0.0019 - val_loss: 0.0130 - val_mae: 0.0527 - val_mse: 0.0130\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - val_loss: 0.0131 - val_mae: 0.0531 - val_mse: 0.0131\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0317 - mse: 0.0019 - val_loss: 0.0126 - val_mae: 0.0525 - val_mse: 0.0126\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0302 - mse: 0.0017 - val_loss: 0.0131 - val_mae: 0.0538 - val_mse: 0.0131\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0298 - mse: 0.0018 - val_loss: 0.0130 - val_mae: 0.0518 - val_mse: 0.0130\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.0128 - val_mae: 0.0517 - val_mse: 0.0128\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.0128 - val_mae: 0.0517 - val_mse: 0.0128\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - val_loss: 0.0129 - val_mae: 0.0521 - val_mse: 0.0129\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0292 - mse: 0.0018 - val_loss: 0.0133 - val_mae: 0.0537 - val_mse: 0.0133\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0290 - mse: 0.0016 - val_loss: 0.0129 - val_mae: 0.0520 - val_mse: 0.0129\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0287 - mse: 0.0016 - val_loss: 0.0128 - val_mae: 0.0540 - val_mse: 0.0128\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - val_loss: 0.0129 - val_mae: 0.0523 - val_mse: 0.0129\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0017 - val_loss: 0.0134 - val_mae: 0.0525 - val_mse: 0.0134\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0292 - mse: 0.0017 - val_loss: 0.0130 - val_mae: 0.0536 - val_mse: 0.0130\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0016 - val_loss: 0.0127 - val_mae: 0.0525 - val_mse: 0.0127\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0290 - mse: 0.0018 - val_loss: 0.0129 - val_mae: 0.0527 - val_mse: 0.0129\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0285 - mse: 0.0016 - val_loss: 0.0128 - val_mae: 0.0545 - val_mse: 0.0128\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0286 - mse: 0.0017 - val_loss: 0.0125 - val_mae: 0.0530 - val_mse: 0.0125\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0288 - mse: 0.0017 - val_loss: 0.0131 - val_mae: 0.0537 - val_mse: 0.0131\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0015 - val_loss: 0.0129 - val_mae: 0.0520 - val_mse: 0.0129\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0290 - mse: 0.0017 - val_loss: 0.0133 - val_mae: 0.0539 - val_mse: 0.0133\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0283 - mse: 0.0016 - val_loss: 0.0127 - val_mae: 0.0521 - val_mse: 0.0127\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015 - val_loss: 0.0128 - val_mae: 0.0527 - val_mse: 0.0128\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0015 - val_loss: 0.0129 - val_mae: 0.0520 - val_mse: 0.0129\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0292 - mse: 0.0017 - val_loss: 0.0131 - val_mae: 0.0531 - val_mse: 0.0131\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0280 - mse: 0.0016 - val_loss: 0.0128 - val_mae: 0.0522 - val_mse: 0.0128\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0283 - mse: 0.0017 - val_loss: 0.0133 - val_mae: 0.0533 - val_mse: 0.0133\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0288 - mse: 0.0017 - val_loss: 0.0131 - val_mae: 0.0526 - val_mse: 0.0131\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0280 - mse: 0.0016 - val_loss: 0.0125 - val_mae: 0.0557 - val_mse: 0.0125\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0284 - mse: 0.0016 - val_loss: 0.0130 - val_mae: 0.0524 - val_mse: 0.0130\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0275 - mse: 0.0015 - val_loss: 0.0127 - val_mae: 0.0518 - val_mse: 0.0127\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0306 - mse: 0.0021 - val_loss: 0.0133 - val_mae: 0.0531 - val_mse: 0.0133\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015 - val_loss: 0.0129 - val_mae: 0.0526 - val_mse: 0.0129\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0287 - mse: 0.0017 - val_loss: 0.0129 - val_mae: 0.0524 - val_mse: 0.0129\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0269 - mse: 0.0014 - val_loss: 0.0127 - val_mae: 0.0544 - val_mse: 0.0127\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0278 - mse: 0.0016 - val_loss: 0.0138 - val_mae: 0.0563 - val_mse: 0.0138\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0278 - mse: 0.0016 - val_loss: 0.0127 - val_mae: 0.0529 - val_mse: 0.0127\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0282 - mse: 0.0016 - val_loss: 0.0128 - val_mae: 0.0537 - val_mse: 0.0128\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0276 - mse: 0.0016 - val_loss: 0.0128 - val_mae: 0.0517 - val_mse: 0.0128\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0286 - mse: 0.0016 - val_loss: 0.0127 - val_mae: 0.0530 - val_mse: 0.0127\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0284 - mse: 0.0017 - val_loss: 0.0127 - val_mae: 0.0518 - val_mse: 0.0127\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0282 - mse: 0.0016 - val_loss: 0.0129 - val_mae: 0.0519 - val_mse: 0.0129\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0286 - mse: 0.0016 - val_loss: 0.0130 - val_mae: 0.0535 - val_mse: 0.0130\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0276 - mse: 0.0015 - val_loss: 0.0128 - val_mae: 0.0520 - val_mse: 0.0128\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0015 - val_loss: 0.0125 - val_mae: 0.0528 - val_mse: 0.0125\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0297 - mse: 0.0019 - val_loss: 0.0129 - val_mae: 0.0520 - val_mse: 0.0129\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0015 - val_loss: 0.0127 - val_mae: 0.0518 - val_mse: 0.0127\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0280 - mse: 0.0016 - val_loss: 0.0129 - val_mae: 0.0520 - val_mse: 0.0129\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0274 - mse: 0.0016 - val_loss: 0.0127 - val_mae: 0.0529 - val_mse: 0.0127\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0015 - val_loss: 0.0129 - val_mae: 0.0534 - val_mse: 0.0129\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0277 - mse: 0.0016 - val_loss: 0.0126 - val_mae: 0.0522 - val_mse: 0.0126\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0271 - mse: 0.0015 - val_loss: 0.0126 - val_mae: 0.0527 - val_mse: 0.0126\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0289 - mse: 0.0018 - val_loss: 0.0129 - val_mae: 0.0523 - val_mse: 0.0129\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0015 - val_loss: 0.0133 - val_mae: 0.0531 - val_mse: 0.0133\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0286 - mse: 0.0017 - val_loss: 0.0127 - val_mae: 0.0550 - val_mse: 0.0127\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0279 - mse: 0.0016 - val_loss: 0.0127 - val_mae: 0.0522 - val_mse: 0.0127\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0270 - mse: 0.0015 - val_loss: 0.0131 - val_mae: 0.0520 - val_mse: 0.0131\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0269 - mse: 0.0015 - val_loss: 0.0130 - val_mae: 0.0527 - val_mse: 0.0130\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0014 - mae: 0.0273 - mse: 0.0014 - val_loss: 0.0126 - val_mae: 0.0519 - val_mse: 0.0126\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0283 - mse: 0.0016 - val_loss: 0.0129 - val_mae: 0.0523 - val_mse: 0.0129\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0272 - mse: 0.0015 - val_loss: 0.0127 - val_mae: 0.0523 - val_mse: 0.0127\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0282 - mse: 0.0016 - val_loss: 0.0128 - val_mae: 0.0529 - val_mse: 0.0128\n",
      "200/200 [==============================] - 1s 942us/step\n",
      "100/100 [==============================] - 0s 932us/step\n",
      "123/123 [==============================] - 0s 959us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 3s 6ms/step - loss: 0.0354 - mae: 0.1194 - mse: 0.0354 - val_loss: 0.0086 - val_mae: 0.0500 - val_mse: 0.0086\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0058 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0082 - val_mae: 0.0458 - val_mse: 0.0082\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0051 - mae: 0.0540 - mse: 0.0051 - val_loss: 0.0081 - val_mae: 0.0460 - val_mse: 0.0081\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0046 - mae: 0.0520 - mse: 0.0046 - val_loss: 0.0080 - val_mae: 0.0458 - val_mse: 0.0080\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0043 - mae: 0.0503 - mse: 0.0043 - val_loss: 0.0080 - val_mae: 0.0458 - val_mse: 0.0080\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0041 - mae: 0.0490 - mse: 0.0041 - val_loss: 0.0087 - val_mae: 0.0526 - val_mse: 0.0087\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0040 - mae: 0.0480 - mse: 0.0040 - val_loss: 0.0086 - val_mae: 0.0523 - val_mse: 0.0086\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0037 - mae: 0.0465 - mse: 0.0037 - val_loss: 0.0080 - val_mae: 0.0463 - val_mse: 0.0080\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0034 - mae: 0.0445 - mse: 0.0034 - val_loss: 0.0082 - val_mae: 0.0486 - val_mse: 0.0082\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0437 - mse: 0.0033 - val_loss: 0.0081 - val_mae: 0.0466 - val_mse: 0.0081\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0436 - mse: 0.0033 - val_loss: 0.0089 - val_mae: 0.0505 - val_mse: 0.0089\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0416 - mse: 0.0030 - val_loss: 0.0086 - val_mae: 0.0475 - val_mse: 0.0086\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0418 - mse: 0.0032 - val_loss: 0.0081 - val_mae: 0.0471 - val_mse: 0.0081\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0407 - mse: 0.0030 - val_loss: 0.0087 - val_mae: 0.0504 - val_mse: 0.0087\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0394 - mse: 0.0028 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0391 - mse: 0.0028 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0385 - mse: 0.0027 - val_loss: 0.0085 - val_mae: 0.0481 - val_mse: 0.0085\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0026 - mae: 0.0375 - mse: 0.0026 - val_loss: 0.0084 - val_mae: 0.0465 - val_mse: 0.0084\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0379 - mse: 0.0028 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0365 - mse: 0.0025 - val_loss: 0.0081 - val_mae: 0.0469 - val_mse: 0.0081\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0358 - mse: 0.0024 - val_loss: 0.0079 - val_mae: 0.0457 - val_mse: 0.0079\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0343 - mse: 0.0022 - val_loss: 0.0080 - val_mae: 0.0457 - val_mse: 0.0080\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0340 - mse: 0.0022 - val_loss: 0.0080 - val_mae: 0.0462 - val_mse: 0.0080\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0337 - mse: 0.0022 - val_loss: 0.0083 - val_mae: 0.0495 - val_mse: 0.0083\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0333 - mse: 0.0021 - val_loss: 0.0085 - val_mae: 0.0485 - val_mse: 0.0085\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0333 - mse: 0.0021 - val_loss: 0.0080 - val_mae: 0.0458 - val_mse: 0.0080\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0328 - mse: 0.0021 - val_loss: 0.0083 - val_mae: 0.0485 - val_mse: 0.0083\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0335 - mse: 0.0023 - val_loss: 0.0079 - val_mae: 0.0459 - val_mse: 0.0079\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0323 - mse: 0.0021 - val_loss: 0.0089 - val_mae: 0.0484 - val_mse: 0.0089\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0326 - mse: 0.0021 - val_loss: 0.0082 - val_mae: 0.0456 - val_mse: 0.0082\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0318 - mse: 0.0021 - val_loss: 0.0080 - val_mae: 0.0468 - val_mse: 0.0080\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0321 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0460 - val_mse: 0.0081\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0307 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0456 - val_mse: 0.0080\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0083 - val_mae: 0.0462 - val_mse: 0.0083\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0319 - mse: 0.0020 - val_loss: 0.0080 - val_mae: 0.0461 - val_mse: 0.0080\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0312 - mse: 0.0020 - val_loss: 0.0083 - val_mae: 0.0461 - val_mse: 0.0083\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0305 - mse: 0.0020 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0307 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0457 - val_mse: 0.0080\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0080 - val_mae: 0.0467 - val_mse: 0.0080\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0080 - val_mae: 0.0457 - val_mse: 0.0080\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0302 - mse: 0.0018 - val_loss: 0.0082 - val_mae: 0.0459 - val_mse: 0.0082\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0080 - val_mae: 0.0462 - val_mse: 0.0080\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0306 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0080 - val_mae: 0.0458 - val_mse: 0.0080\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0506 - val_mse: 0.0084\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0297 - mse: 0.0018 - val_loss: 0.0081 - val_mae: 0.0456 - val_mse: 0.0081\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0458 - val_mse: 0.0080\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0461 - val_mse: 0.0081\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0082 - val_mae: 0.0462 - val_mse: 0.0082\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0306 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0466 - val_mse: 0.0080\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0310 - mse: 0.0021 - val_loss: 0.0080 - val_mae: 0.0460 - val_mse: 0.0080\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0322 - mse: 0.0023 - val_loss: 0.0083 - val_mae: 0.0464 - val_mse: 0.0083\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0306 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0466 - val_mse: 0.0080\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0306 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0474 - val_mse: 0.0081\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0455 - val_mse: 0.0081\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0312 - mse: 0.0022 - val_loss: 0.0080 - val_mae: 0.0456 - val_mse: 0.0080\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0306 - mse: 0.0021 - val_loss: 0.0081 - val_mae: 0.0455 - val_mse: 0.0081\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0301 - mse: 0.0019 - val_loss: 0.0082 - val_mae: 0.0465 - val_mse: 0.0082\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0473 - val_mse: 0.0080\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0299 - mse: 0.0018 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0298 - mse: 0.0018 - val_loss: 0.0082 - val_mae: 0.0471 - val_mse: 0.0082\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0297 - mse: 0.0018 - val_loss: 0.0081 - val_mae: 0.0457 - val_mse: 0.0081\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0315 - mse: 0.0022 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0307 - mse: 0.0020 - val_loss: 0.0082 - val_mae: 0.0463 - val_mse: 0.0082\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0300 - mse: 0.0018 - val_loss: 0.0081 - val_mae: 0.0474 - val_mse: 0.0081\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0294 - mse: 0.0018 - val_loss: 0.0086 - val_mae: 0.0462 - val_mse: 0.0086\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0468 - val_mse: 0.0081\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0299 - mse: 0.0018 - val_loss: 0.0082 - val_mae: 0.0488 - val_mse: 0.0082\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0308 - mse: 0.0021 - val_loss: 0.0081 - val_mae: 0.0459 - val_mse: 0.0081\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0310 - mse: 0.0022 - val_loss: 0.0081 - val_mae: 0.0466 - val_mse: 0.0081\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0300 - mse: 0.0019 - val_loss: 0.0081 - val_mae: 0.0456 - val_mse: 0.0081\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0303 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0468 - val_mse: 0.0080\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0307 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0464 - val_mse: 0.0081\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0299 - mse: 0.0020 - val_loss: 0.0085 - val_mae: 0.0508 - val_mse: 0.0085\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0086 - val_mae: 0.0464 - val_mse: 0.0086\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0303 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0482 - val_mse: 0.0083\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0483 - val_mse: 0.0084\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0300 - mse: 0.0018 - val_loss: 0.0082 - val_mae: 0.0470 - val_mse: 0.0082\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0293 - mse: 0.0018 - val_loss: 0.0082 - val_mae: 0.0466 - val_mse: 0.0082\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0299 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0456 - val_mse: 0.0080\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0297 - mse: 0.0018 - val_loss: 0.0085 - val_mae: 0.0460 - val_mse: 0.0085\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0298 - mse: 0.0018 - val_loss: 0.0081 - val_mae: 0.0472 - val_mse: 0.0081\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0085 - val_mae: 0.0470 - val_mse: 0.0085\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0298 - mse: 0.0018 - val_loss: 0.0081 - val_mae: 0.0472 - val_mse: 0.0081\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0457 - val_mse: 0.0080\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0297 - mse: 0.0019 - val_loss: 0.0080 - val_mae: 0.0464 - val_mse: 0.0080\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0297 - mse: 0.0018 - val_loss: 0.0080 - val_mae: 0.0456 - val_mse: 0.0080\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0084 - val_mae: 0.0493 - val_mse: 0.0084\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0301 - mse: 0.0019 - val_loss: 0.0082 - val_mae: 0.0479 - val_mse: 0.0082\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0305 - mse: 0.0020 - val_loss: 0.0082 - val_mae: 0.0477 - val_mse: 0.0082\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0294 - mse: 0.0018 - val_loss: 0.0083 - val_mae: 0.0472 - val_mse: 0.0083\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0296 - mse: 0.0018 - val_loss: 0.0080 - val_mae: 0.0459 - val_mse: 0.0080\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0297 - mse: 0.0019 - val_loss: 0.0081 - val_mae: 0.0463 - val_mse: 0.0081\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0299 - mse: 0.0019 - val_loss: 0.0082 - val_mae: 0.0481 - val_mse: 0.0082\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0304 - mse: 0.0020 - val_loss: 0.0092 - val_mae: 0.0527 - val_mse: 0.0092\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0457 - val_mse: 0.0083\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0082 - val_mae: 0.0471 - val_mse: 0.0082\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0296 - mse: 0.0018 - val_loss: 0.0083 - val_mae: 0.0460 - val_mse: 0.0083\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0307 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0459 - val_mse: 0.0081\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0302 - mse: 0.0020 - val_loss: 0.0081 - val_mae: 0.0470 - val_mse: 0.0081\n",
      "300/300 [==============================] - 1s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "267/267 [==============================] - 4s 7ms/step - loss: 0.0261 - mae: 0.1029 - mse: 0.0261 - val_loss: 0.0084 - val_mae: 0.0469 - val_mse: 0.0084\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0053 - mae: 0.0555 - mse: 0.0053 - val_loss: 0.0088 - val_mae: 0.0513 - val_mse: 0.0088\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0517 - mse: 0.0046 - val_loss: 0.0084 - val_mae: 0.0468 - val_mse: 0.0084\n",
      "Epoch 4/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0043 - mae: 0.0492 - mse: 0.0043 - val_loss: 0.0088 - val_mae: 0.0487 - val_mse: 0.0088\n",
      "Epoch 5/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0038 - mae: 0.0466 - mse: 0.0038 - val_loss: 0.0083 - val_mae: 0.0461 - val_mse: 0.0083\n",
      "Epoch 6/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0450 - mse: 0.0035 - val_loss: 0.0082 - val_mae: 0.0457 - val_mse: 0.0082\n",
      "Epoch 7/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0431 - mse: 0.0032 - val_loss: 0.0083 - val_mae: 0.0465 - val_mse: 0.0083\n",
      "Epoch 8/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0423 - mse: 0.0032 - val_loss: 0.0085 - val_mae: 0.0477 - val_mse: 0.0085\n",
      "Epoch 9/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0424 - mse: 0.0032 - val_loss: 0.0084 - val_mae: 0.0471 - val_mse: 0.0084\n",
      "Epoch 10/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0403 - mse: 0.0030 - val_loss: 0.0085 - val_mae: 0.0484 - val_mse: 0.0085\n",
      "Epoch 11/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0401 - mse: 0.0029 - val_loss: 0.0083 - val_mae: 0.0458 - val_mse: 0.0083\n",
      "Epoch 12/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0399 - mse: 0.0029 - val_loss: 0.0088 - val_mae: 0.0493 - val_mse: 0.0088\n",
      "Epoch 13/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0385 - mse: 0.0027 - val_loss: 0.0083 - val_mae: 0.0459 - val_mse: 0.0083\n",
      "Epoch 14/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0370 - mse: 0.0025 - val_loss: 0.0084 - val_mae: 0.0465 - val_mse: 0.0084\n",
      "Epoch 15/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0368 - mse: 0.0025 - val_loss: 0.0086 - val_mae: 0.0480 - val_mse: 0.0086\n",
      "Epoch 16/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0364 - mse: 0.0025 - val_loss: 0.0087 - val_mae: 0.0509 - val_mse: 0.0087\n",
      "Epoch 17/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0352 - mse: 0.0023 - val_loss: 0.0083 - val_mae: 0.0460 - val_mse: 0.0083\n",
      "Epoch 18/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0347 - mse: 0.0024 - val_loss: 0.0095 - val_mae: 0.0555 - val_mse: 0.0095\n",
      "Epoch 19/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0351 - mse: 0.0024 - val_loss: 0.0084 - val_mae: 0.0482 - val_mse: 0.0084\n",
      "Epoch 20/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0341 - mse: 0.0022 - val_loss: 0.0085 - val_mae: 0.0478 - val_mse: 0.0085\n",
      "Epoch 21/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0342 - mse: 0.0022 - val_loss: 0.0083 - val_mae: 0.0457 - val_mse: 0.0083\n",
      "Epoch 22/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0331 - mse: 0.0021 - val_loss: 0.0084 - val_mae: 0.0469 - val_mse: 0.0084\n",
      "Epoch 23/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0314 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0468 - val_mse: 0.0084\n",
      "Epoch 24/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0322 - mse: 0.0021 - val_loss: 0.0083 - val_mae: 0.0466 - val_mse: 0.0083\n",
      "Epoch 25/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0319 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0467 - val_mse: 0.0084\n",
      "Epoch 26/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0317 - mse: 0.0020 - val_loss: 0.0085 - val_mae: 0.0480 - val_mse: 0.0085\n",
      "Epoch 27/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0086 - val_mae: 0.0494 - val_mse: 0.0086\n",
      "Epoch 28/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0312 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0464 - val_mse: 0.0083\n",
      "Epoch 29/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0308 - mse: 0.0019 - val_loss: 0.0089 - val_mae: 0.0502 - val_mse: 0.0089\n",
      "Epoch 30/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0321 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0466 - val_mse: 0.0084\n",
      "Epoch 31/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0477 - val_mse: 0.0084\n",
      "Epoch 32/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0308 - mse: 0.0019 - val_loss: 0.0088 - val_mae: 0.0509 - val_mse: 0.0088\n",
      "Epoch 33/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0307 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0456 - val_mse: 0.0083\n",
      "Epoch 34/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0316 - mse: 0.0020 - val_loss: 0.0083 - val_mae: 0.0459 - val_mse: 0.0083\n",
      "Epoch 35/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0082 - val_mae: 0.0458 - val_mse: 0.0082\n",
      "Epoch 36/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0311 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0472 - val_mse: 0.0084\n",
      "Epoch 37/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0311 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0483 - val_mse: 0.0084\n",
      "Epoch 38/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0312 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0472 - val_mse: 0.0084\n",
      "Epoch 39/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0085 - val_mae: 0.0468 - val_mse: 0.0085\n",
      "Epoch 40/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - mse: 0.0019 - val_loss: 0.0086 - val_mae: 0.0488 - val_mse: 0.0086\n",
      "Epoch 41/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0307 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0470 - val_mse: 0.0083\n",
      "Epoch 42/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0084 - val_mae: 0.0460 - val_mse: 0.0084\n",
      "Epoch 43/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0304 - mse: 0.0020 - val_loss: 0.0083 - val_mae: 0.0462 - val_mse: 0.0083\n",
      "Epoch 44/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0299 - mse: 0.0018 - val_loss: 0.0083 - val_mae: 0.0458 - val_mse: 0.0083\n",
      "Epoch 45/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0308 - mse: 0.0021 - val_loss: 0.0084 - val_mae: 0.0468 - val_mse: 0.0084\n",
      "Epoch 46/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0316 - mse: 0.0021 - val_loss: 0.0084 - val_mae: 0.0459 - val_mse: 0.0084\n",
      "Epoch 47/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0305 - mse: 0.0020 - val_loss: 0.0085 - val_mae: 0.0468 - val_mse: 0.0085\n",
      "Epoch 48/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0306 - mse: 0.0019 - val_loss: 0.0085 - val_mae: 0.0489 - val_mse: 0.0085\n",
      "Epoch 49/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0305 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0460 - val_mse: 0.0083\n",
      "Epoch 50/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0302 - mse: 0.0019 - val_loss: 0.0086 - val_mae: 0.0480 - val_mse: 0.0086\n",
      "Epoch 51/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0091 - val_mae: 0.0513 - val_mse: 0.0091\n",
      "Epoch 52/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0305 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0461 - val_mse: 0.0084\n",
      "Epoch 53/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0462 - val_mse: 0.0084\n",
      "Epoch 54/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0309 - mse: 0.0021 - val_loss: 0.0089 - val_mae: 0.0507 - val_mse: 0.0089\n",
      "Epoch 55/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0305 - mse: 0.0019 - val_loss: 0.0085 - val_mae: 0.0471 - val_mse: 0.0085\n",
      "Epoch 56/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0301 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0473 - val_mse: 0.0084\n",
      "Epoch 57/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0306 - mse: 0.0020 - val_loss: 0.0083 - val_mae: 0.0460 - val_mse: 0.0083\n",
      "Epoch 58/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0306 - mse: 0.0019 - val_loss: 0.0085 - val_mae: 0.0486 - val_mse: 0.0085\n",
      "Epoch 59/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0299 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0463 - val_mse: 0.0084\n",
      "Epoch 60/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0303 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0460 - val_mse: 0.0083\n",
      "Epoch 61/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0309 - mse: 0.0021 - val_loss: 0.0085 - val_mae: 0.0485 - val_mse: 0.0085\n",
      "Epoch 62/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0303 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0467 - val_mse: 0.0084\n",
      "Epoch 63/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0084 - val_mae: 0.0473 - val_mse: 0.0084\n",
      "Epoch 64/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0307 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0465 - val_mse: 0.0084\n",
      "Epoch 65/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0303 - mse: 0.0019 - val_loss: 0.0086 - val_mae: 0.0485 - val_mse: 0.0086\n",
      "Epoch 66/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0305 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0459 - val_mse: 0.0083\n",
      "Epoch 67/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0309 - mse: 0.0021 - val_loss: 0.0084 - val_mae: 0.0467 - val_mse: 0.0084\n",
      "Epoch 68/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0299 - mse: 0.0019 - val_loss: 0.0085 - val_mae: 0.0476 - val_mse: 0.0085\n",
      "Epoch 69/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0302 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0463 - val_mse: 0.0084\n",
      "Epoch 70/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0302 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0473 - val_mse: 0.0084\n",
      "Epoch 71/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0300 - mse: 0.0019 - val_loss: 0.0085 - val_mae: 0.0461 - val_mse: 0.0085\n",
      "Epoch 72/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0302 - mse: 0.0020 - val_loss: 0.0083 - val_mae: 0.0459 - val_mse: 0.0083\n",
      "Epoch 73/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0303 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0461 - val_mse: 0.0084\n",
      "Epoch 74/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0300 - mse: 0.0019 - val_loss: 0.0086 - val_mae: 0.0487 - val_mse: 0.0086\n",
      "Epoch 75/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0303 - mse: 0.0019 - val_loss: 0.0085 - val_mae: 0.0464 - val_mse: 0.0085\n",
      "Epoch 76/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0297 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0460 - val_mse: 0.0083\n",
      "Epoch 77/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0296 - mse: 0.0018 - val_loss: 0.0084 - val_mae: 0.0473 - val_mse: 0.0084\n",
      "Epoch 78/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0086 - val_mae: 0.0481 - val_mse: 0.0086\n",
      "Epoch 79/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0087 - val_mae: 0.0475 - val_mse: 0.0087\n",
      "Epoch 80/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0300 - mse: 0.0018 - val_loss: 0.0085 - val_mae: 0.0478 - val_mse: 0.0085\n",
      "Epoch 81/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0298 - mse: 0.0018 - val_loss: 0.0084 - val_mae: 0.0459 - val_mse: 0.0084\n",
      "Epoch 82/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0083 - val_mae: 0.0463 - val_mse: 0.0083\n",
      "Epoch 83/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0298 - mse: 0.0019 - val_loss: 0.0088 - val_mae: 0.0486 - val_mse: 0.0088\n",
      "Epoch 84/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0299 - mse: 0.0018 - val_loss: 0.0084 - val_mae: 0.0470 - val_mse: 0.0084\n",
      "Epoch 85/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0297 - mse: 0.0018 - val_loss: 0.0084 - val_mae: 0.0463 - val_mse: 0.0084\n",
      "Epoch 86/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0305 - mse: 0.0019 - val_loss: 0.0086 - val_mae: 0.0468 - val_mse: 0.0086\n",
      "Epoch 87/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0084 - val_mae: 0.0468 - val_mse: 0.0084\n",
      "Epoch 88/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0293 - mse: 0.0017 - val_loss: 0.0084 - val_mae: 0.0460 - val_mse: 0.0084\n",
      "Epoch 89/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0301 - mse: 0.0019 - val_loss: 0.0084 - val_mae: 0.0463 - val_mse: 0.0084\n",
      "Epoch 90/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0085 - val_mae: 0.0472 - val_mse: 0.0085\n",
      "Epoch 91/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0303 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0465 - val_mse: 0.0083\n",
      "Epoch 92/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0297 - mse: 0.0019 - val_loss: 0.0087 - val_mae: 0.0481 - val_mse: 0.0087\n",
      "Epoch 93/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0306 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0467 - val_mse: 0.0084\n",
      "Epoch 94/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0296 - mse: 0.0018 - val_loss: 0.0083 - val_mae: 0.0461 - val_mse: 0.0083\n",
      "Epoch 95/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0296 - mse: 0.0018 - val_loss: 0.0084 - val_mae: 0.0465 - val_mse: 0.0084\n",
      "Epoch 96/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0299 - mse: 0.0018 - val_loss: 0.0084 - val_mae: 0.0470 - val_mse: 0.0084\n",
      "Epoch 97/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0085 - val_mae: 0.0478 - val_mse: 0.0085\n",
      "Epoch 98/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0305 - mse: 0.0020 - val_loss: 0.0089 - val_mae: 0.0493 - val_mse: 0.0089\n",
      "Epoch 99/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0305 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0461 - val_mse: 0.0083\n",
      "Epoch 100/100\n",
      "267/267 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0302 - mse: 0.0020 - val_loss: 0.0084 - val_mae: 0.0470 - val_mse: 0.0084\n",
      "400/400 [==============================] - 1s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "333/333 [==============================] - 4s 6ms/step - loss: 0.0211 - mae: 0.0908 - mse: 0.0211 - val_loss: 0.0073 - val_mae: 0.0431 - val_mse: 0.0073\n",
      "Epoch 2/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0051 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0072 - val_mae: 0.0445 - val_mse: 0.0072\n",
      "Epoch 3/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0045 - mae: 0.0512 - mse: 0.0045 - val_loss: 0.0071 - val_mae: 0.0426 - val_mse: 0.0071\n",
      "Epoch 4/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0040 - mae: 0.0478 - mse: 0.0040 - val_loss: 0.0076 - val_mae: 0.0483 - val_mse: 0.0076\n",
      "Epoch 5/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0038 - mae: 0.0467 - mse: 0.0038 - val_loss: 0.0071 - val_mae: 0.0429 - val_mse: 0.0071\n",
      "Epoch 6/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0034 - mae: 0.0445 - mse: 0.0034 - val_loss: 0.0071 - val_mae: 0.0429 - val_mse: 0.0071\n",
      "Epoch 7/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0033 - mae: 0.0429 - mse: 0.0033 - val_loss: 0.0071 - val_mae: 0.0438 - val_mse: 0.0071\n",
      "Epoch 8/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0034 - mae: 0.0428 - mse: 0.0034 - val_loss: 0.0070 - val_mae: 0.0429 - val_mse: 0.0070\n",
      "Epoch 9/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0030 - mae: 0.0408 - mse: 0.0030 - val_loss: 0.0070 - val_mae: 0.0430 - val_mse: 0.0070\n",
      "Epoch 10/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0029 - mae: 0.0402 - mse: 0.0029 - val_loss: 0.0077 - val_mae: 0.0475 - val_mse: 0.0077\n",
      "Epoch 11/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0029 - mae: 0.0393 - mse: 0.0029 - val_loss: 0.0073 - val_mae: 0.0439 - val_mse: 0.0073\n",
      "Epoch 12/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0028 - mae: 0.0383 - mse: 0.0028 - val_loss: 0.0076 - val_mae: 0.0463 - val_mse: 0.0076\n",
      "Epoch 13/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0026 - mae: 0.0370 - mse: 0.0026 - val_loss: 0.0074 - val_mae: 0.0478 - val_mse: 0.0074\n",
      "Epoch 14/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0027 - mae: 0.0375 - mse: 0.0027 - val_loss: 0.0071 - val_mae: 0.0427 - val_mse: 0.0071\n",
      "Epoch 15/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0351 - mse: 0.0023 - val_loss: 0.0071 - val_mae: 0.0441 - val_mse: 0.0071\n",
      "Epoch 16/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0342 - mse: 0.0022 - val_loss: 0.0069 - val_mae: 0.0432 - val_mse: 0.0069\n",
      "Epoch 17/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0342 - mse: 0.0023 - val_loss: 0.0073 - val_mae: 0.0436 - val_mse: 0.0073\n",
      "Epoch 18/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0328 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0435 - val_mse: 0.0071\n",
      "Epoch 19/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0334 - mse: 0.0022 - val_loss: 0.0072 - val_mae: 0.0432 - val_mse: 0.0072\n",
      "Epoch 20/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0335 - mse: 0.0023 - val_loss: 0.0070 - val_mae: 0.0431 - val_mse: 0.0070\n",
      "Epoch 21/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0328 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0428 - val_mse: 0.0070\n",
      "Epoch 22/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0324 - mse: 0.0021 - val_loss: 0.0072 - val_mae: 0.0456 - val_mse: 0.0072\n",
      "Epoch 23/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0330 - mse: 0.0023 - val_loss: 0.0072 - val_mae: 0.0449 - val_mse: 0.0072\n",
      "Epoch 24/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0077 - val_mae: 0.0463 - val_mse: 0.0077\n",
      "Epoch 25/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0072 - val_mae: 0.0435 - val_mse: 0.0072\n",
      "Epoch 26/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0314 - mse: 0.0020 - val_loss: 0.0080 - val_mae: 0.0441 - val_mse: 0.0080\n",
      "Epoch 27/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0312 - mse: 0.0020 - val_loss: 0.0071 - val_mae: 0.0434 - val_mse: 0.0071\n",
      "Epoch 28/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0449 - val_mse: 0.0071\n",
      "Epoch 29/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0315 - mse: 0.0020 - val_loss: 0.0069 - val_mae: 0.0431 - val_mse: 0.0069\n",
      "Epoch 30/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0311 - mse: 0.0020 - val_loss: 0.0075 - val_mae: 0.0440 - val_mse: 0.0075\n",
      "Epoch 31/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0327 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0428 - val_mse: 0.0070\n",
      "Epoch 32/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0426 - val_mse: 0.0070\n",
      "Epoch 33/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0075 - val_mae: 0.0434 - val_mse: 0.0075\n",
      "Epoch 34/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0073 - val_mae: 0.0439 - val_mse: 0.0073\n",
      "Epoch 35/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0426 - val_mse: 0.0071\n",
      "Epoch 36/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0069 - val_mae: 0.0428 - val_mse: 0.0069\n",
      "Epoch 37/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0312 - mse: 0.0020 - val_loss: 0.0071 - val_mae: 0.0428 - val_mse: 0.0071\n",
      "Epoch 38/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0078 - val_mae: 0.0471 - val_mse: 0.0078\n",
      "Epoch 39/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0316 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0427 - val_mse: 0.0071\n",
      "Epoch 40/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0429 - val_mse: 0.0070\n",
      "Epoch 41/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0069 - val_mae: 0.0434 - val_mse: 0.0069\n",
      "Epoch 42/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0314 - mse: 0.0020 - val_loss: 0.0069 - val_mae: 0.0428 - val_mse: 0.0069\n",
      "Epoch 43/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0074 - val_mae: 0.0453 - val_mse: 0.0074\n",
      "Epoch 44/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0425 - val_mse: 0.0071\n",
      "Epoch 45/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0071 - val_mae: 0.0441 - val_mse: 0.0071\n",
      "Epoch 46/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0077 - val_mae: 0.0458 - val_mse: 0.0077\n",
      "Epoch 47/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0069 - val_mae: 0.0430 - val_mse: 0.0069\n",
      "Epoch 48/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0311 - mse: 0.0020 - val_loss: 0.0072 - val_mae: 0.0426 - val_mse: 0.0072\n",
      "Epoch 49/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0075 - val_mae: 0.0434 - val_mse: 0.0075\n",
      "Epoch 50/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0071 - val_mae: 0.0432 - val_mse: 0.0071\n",
      "Epoch 51/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0072 - val_mae: 0.0436 - val_mse: 0.0072\n",
      "Epoch 52/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0324 - mse: 0.0024 - val_loss: 0.0072 - val_mae: 0.0464 - val_mse: 0.0072\n",
      "Epoch 53/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0319 - mse: 0.0021 - val_loss: 0.0073 - val_mae: 0.0467 - val_mse: 0.0073\n",
      "Epoch 54/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0069 - val_mae: 0.0427 - val_mse: 0.0069\n",
      "Epoch 55/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0072 - val_mae: 0.0427 - val_mse: 0.0072\n",
      "Epoch 56/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0072 - val_mae: 0.0439 - val_mse: 0.0072\n",
      "Epoch 57/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0312 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0426 - val_mse: 0.0070\n",
      "Epoch 58/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0074 - val_mae: 0.0475 - val_mse: 0.0074\n",
      "Epoch 59/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0073 - val_mae: 0.0428 - val_mse: 0.0073\n",
      "Epoch 60/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0072 - val_mae: 0.0439 - val_mse: 0.0072\n",
      "Epoch 61/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0307 - mse: 0.0020 - val_loss: 0.0072 - val_mae: 0.0425 - val_mse: 0.0072\n",
      "Epoch 62/100\n",
      "333/333 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0319 - mse: 0.0023 - val_loss: 0.0071 - val_mae: 0.0429 - val_mse: 0.0071\n",
      "Epoch 63/100\n",
      "333/333 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0071 - val_mae: 0.0461 - val_mse: 0.0071\n",
      "Epoch 64/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0069 - val_mae: 0.0429 - val_mse: 0.0069\n",
      "Epoch 65/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0074 - val_mae: 0.0469 - val_mse: 0.0074\n",
      "Epoch 66/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0312 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0429 - val_mse: 0.0070\n",
      "Epoch 67/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0069 - val_mae: 0.0428 - val_mse: 0.0069\n",
      "Epoch 68/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0433 - val_mse: 0.0071\n",
      "Epoch 69/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0307 - mse: 0.0020 - val_loss: 0.0072 - val_mae: 0.0442 - val_mse: 0.0072\n",
      "Epoch 70/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0431 - val_mse: 0.0071\n",
      "Epoch 71/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0444 - val_mse: 0.0070\n",
      "Epoch 72/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0075 - val_mae: 0.0429 - val_mse: 0.0075\n",
      "Epoch 73/100\n",
      "333/333 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0312 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0440 - val_mse: 0.0071\n",
      "Epoch 74/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0436 - val_mse: 0.0070\n",
      "Epoch 75/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0072 - val_mae: 0.0459 - val_mse: 0.0072\n",
      "Epoch 76/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0441 - val_mse: 0.0070\n",
      "Epoch 77/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0429 - val_mse: 0.0071\n",
      "Epoch 78/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0074 - val_mae: 0.0430 - val_mse: 0.0074\n",
      "Epoch 79/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0319 - mse: 0.0023 - val_loss: 0.0069 - val_mae: 0.0435 - val_mse: 0.0069\n",
      "Epoch 80/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0316 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0446 - val_mse: 0.0070\n",
      "Epoch 81/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0074 - val_mae: 0.0436 - val_mse: 0.0074\n",
      "Epoch 82/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0438 - val_mse: 0.0071\n",
      "Epoch 83/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0074 - val_mae: 0.0442 - val_mse: 0.0074\n",
      "Epoch 84/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0074 - val_mae: 0.0467 - val_mse: 0.0074\n",
      "Epoch 85/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0311 - mse: 0.0020 - val_loss: 0.0069 - val_mae: 0.0428 - val_mse: 0.0069\n",
      "Epoch 86/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0427 - val_mse: 0.0070\n",
      "Epoch 87/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0310 - mse: 0.0020 - val_loss: 0.0071 - val_mae: 0.0431 - val_mse: 0.0071\n",
      "Epoch 88/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0073 - val_mae: 0.0447 - val_mse: 0.0073\n",
      "Epoch 89/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0307 - mse: 0.0019 - val_loss: 0.0071 - val_mae: 0.0449 - val_mse: 0.0071\n",
      "Epoch 90/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0428 - val_mse: 0.0070\n",
      "Epoch 91/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0428 - val_mse: 0.0070\n",
      "Epoch 92/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0072 - val_mae: 0.0439 - val_mse: 0.0072\n",
      "Epoch 93/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0309 - mse: 0.0020 - val_loss: 0.0072 - val_mae: 0.0437 - val_mse: 0.0072\n",
      "Epoch 94/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0072 - val_mae: 0.0436 - val_mse: 0.0072\n",
      "Epoch 95/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0309 - mse: 0.0021 - val_loss: 0.0074 - val_mae: 0.0440 - val_mse: 0.0074\n",
      "Epoch 96/100\n",
      "333/333 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0071 - val_mae: 0.0432 - val_mse: 0.0071\n",
      "Epoch 97/100\n",
      "333/333 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0308 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0429 - val_mse: 0.0071\n",
      "Epoch 98/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0073 - val_mae: 0.0432 - val_mse: 0.0073\n",
      "Epoch 99/100\n",
      "333/333 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0432 - val_mse: 0.0070\n",
      "Epoch 100/100\n",
      "333/333 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0428 - val_mse: 0.0070\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 991us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "400/400 [==============================] - 4s 4ms/step - loss: 0.0215 - mae: 0.0935 - mse: 0.0215 - val_loss: 0.0068 - val_mae: 0.0433 - val_mse: 0.0068\n",
      "Epoch 2/100\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 0.0056 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0067 - val_mae: 0.0425 - val_mse: 0.0067\n",
      "Epoch 3/100\n",
      "400/400 [==============================] - 2s 4ms/step - loss: 0.0048 - mae: 0.0527 - mse: 0.0048 - val_loss: 0.0067 - val_mae: 0.0426 - val_mse: 0.0067\n",
      "Epoch 4/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0044 - mae: 0.0496 - mse: 0.0044 - val_loss: 0.0067 - val_mae: 0.0427 - val_mse: 0.0067\n",
      "Epoch 5/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0039 - mae: 0.0468 - mse: 0.0039 - val_loss: 0.0065 - val_mae: 0.0415 - val_mse: 0.0065\n",
      "Epoch 6/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0037 - mae: 0.0452 - mse: 0.0037 - val_loss: 0.0066 - val_mae: 0.0413 - val_mse: 0.0066\n",
      "Epoch 7/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0033 - mae: 0.0428 - mse: 0.0033 - val_loss: 0.0068 - val_mae: 0.0447 - val_mse: 0.0068\n",
      "Epoch 8/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0029 - mae: 0.0403 - mse: 0.0029 - val_loss: 0.0067 - val_mae: 0.0421 - val_mse: 0.0067\n",
      "Epoch 9/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0029 - mae: 0.0396 - mse: 0.0029 - val_loss: 0.0067 - val_mae: 0.0420 - val_mse: 0.0067\n",
      "Epoch 10/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0027 - mae: 0.0380 - mse: 0.0027 - val_loss: 0.0065 - val_mae: 0.0418 - val_mse: 0.0065\n",
      "Epoch 11/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0026 - mae: 0.0369 - mse: 0.0026 - val_loss: 0.0065 - val_mae: 0.0422 - val_mse: 0.0065\n",
      "Epoch 12/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0026 - mae: 0.0365 - mse: 0.0026 - val_loss: 0.0069 - val_mae: 0.0454 - val_mse: 0.0069\n",
      "Epoch 13/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0025 - mae: 0.0351 - mse: 0.0025 - val_loss: 0.0065 - val_mae: 0.0414 - val_mse: 0.0065\n",
      "Epoch 14/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0343 - mse: 0.0024 - val_loss: 0.0065 - val_mae: 0.0419 - val_mse: 0.0065\n",
      "Epoch 15/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0339 - mse: 0.0024 - val_loss: 0.0065 - val_mae: 0.0409 - val_mse: 0.0065\n",
      "Epoch 16/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0331 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0410 - val_mse: 0.0065\n",
      "Epoch 17/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0327 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0413 - val_mse: 0.0065\n",
      "Epoch 18/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0337 - mse: 0.0024 - val_loss: 0.0067 - val_mae: 0.0440 - val_mse: 0.0067\n",
      "Epoch 19/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0333 - mse: 0.0023 - val_loss: 0.0065 - val_mae: 0.0417 - val_mse: 0.0065\n",
      "Epoch 20/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0065 - val_mae: 0.0422 - val_mse: 0.0065\n",
      "Epoch 21/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0066 - val_mae: 0.0421 - val_mse: 0.0066\n",
      "Epoch 22/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0064 - val_mae: 0.0411 - val_mse: 0.0064\n",
      "Epoch 23/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0070 - val_mae: 0.0453 - val_mse: 0.0070\n",
      "Epoch 24/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0318 - mse: 0.0021 - val_loss: 0.0068 - val_mae: 0.0438 - val_mse: 0.0068\n",
      "Epoch 25/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0426 - val_mse: 0.0067\n",
      "Epoch 26/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0066 - val_mae: 0.0425 - val_mse: 0.0066\n",
      "Epoch 27/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0066 - val_mae: 0.0429 - val_mse: 0.0066\n",
      "Epoch 28/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0319 - mse: 0.0021 - val_loss: 0.0068 - val_mae: 0.0422 - val_mse: 0.0068\n",
      "Epoch 29/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0318 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0427 - val_mse: 0.0065\n",
      "Epoch 30/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0330 - mse: 0.0024 - val_loss: 0.0065 - val_mae: 0.0415 - val_mse: 0.0065\n",
      "Epoch 31/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0066 - val_mae: 0.0413 - val_mse: 0.0066\n",
      "Epoch 32/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0319 - mse: 0.0021 - val_loss: 0.0067 - val_mae: 0.0444 - val_mse: 0.0067\n",
      "Epoch 33/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0409 - val_mse: 0.0065\n",
      "Epoch 34/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0065 - val_mae: 0.0418 - val_mse: 0.0065\n",
      "Epoch 35/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0414 - val_mse: 0.0065\n",
      "Epoch 36/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0316 - mse: 0.0021 - val_loss: 0.0067 - val_mae: 0.0443 - val_mse: 0.0067\n",
      "Epoch 37/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0424 - val_mse: 0.0067\n",
      "Epoch 38/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0410 - val_mse: 0.0065\n",
      "Epoch 39/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0066 - val_mae: 0.0416 - val_mse: 0.0066\n",
      "Epoch 40/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0330 - mse: 0.0024 - val_loss: 0.0065 - val_mae: 0.0420 - val_mse: 0.0065\n",
      "Epoch 41/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0319 - mse: 0.0023 - val_loss: 0.0066 - val_mae: 0.0414 - val_mse: 0.0066\n",
      "Epoch 42/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0068 - val_mae: 0.0432 - val_mse: 0.0068\n",
      "Epoch 43/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0438 - val_mse: 0.0067\n",
      "Epoch 44/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0066 - val_mae: 0.0427 - val_mse: 0.0066\n",
      "Epoch 45/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0067 - val_mae: 0.0441 - val_mse: 0.0067\n",
      "Epoch 46/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0066 - val_mae: 0.0429 - val_mse: 0.0066\n",
      "Epoch 47/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0068 - val_mae: 0.0428 - val_mse: 0.0068\n",
      "Epoch 48/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0066 - val_mae: 0.0417 - val_mse: 0.0066\n",
      "Epoch 49/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0411 - val_mse: 0.0065\n",
      "Epoch 50/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0066 - val_mae: 0.0423 - val_mse: 0.0066\n",
      "Epoch 51/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0418 - val_mse: 0.0065\n",
      "Epoch 52/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0477 - val_mse: 0.0070\n",
      "Epoch 53/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0318 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0460 - val_mse: 0.0071\n",
      "Epoch 54/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0413 - val_mse: 0.0065\n",
      "Epoch 55/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0413 - val_mse: 0.0065\n",
      "Epoch 56/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0313 - mse: 0.0020 - val_loss: 0.0065 - val_mae: 0.0413 - val_mse: 0.0065\n",
      "Epoch 57/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0068 - val_mae: 0.0422 - val_mse: 0.0068\n",
      "Epoch 58/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0071 - val_mae: 0.0459 - val_mse: 0.0071\n",
      "Epoch 59/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0476 - val_mse: 0.0070\n",
      "Epoch 60/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0066 - val_mae: 0.0414 - val_mse: 0.0066\n",
      "Epoch 61/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0410 - val_mse: 0.0065\n",
      "Epoch 62/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0412 - val_mse: 0.0065\n",
      "Epoch 63/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0418 - val_mse: 0.0065\n",
      "Epoch 64/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0073 - val_mae: 0.0451 - val_mse: 0.0073\n",
      "Epoch 65/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0071 - val_mae: 0.0458 - val_mse: 0.0071\n",
      "Epoch 66/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0318 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0423 - val_mse: 0.0065\n",
      "Epoch 67/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0410 - val_mse: 0.0065\n",
      "Epoch 68/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0069 - val_mae: 0.0437 - val_mse: 0.0069\n",
      "Epoch 69/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0414 - val_mse: 0.0065\n",
      "Epoch 70/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0313 - mse: 0.0021 - val_loss: 0.0066 - val_mae: 0.0433 - val_mse: 0.0066\n",
      "Epoch 71/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0421 - val_mse: 0.0065\n",
      "Epoch 72/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0312 - mse: 0.0020 - val_loss: 0.0066 - val_mae: 0.0434 - val_mse: 0.0066\n",
      "Epoch 73/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0412 - val_mse: 0.0065\n",
      "Epoch 74/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0066 - val_mae: 0.0426 - val_mse: 0.0066\n",
      "Epoch 75/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0413 - val_mse: 0.0065\n",
      "Epoch 76/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0314 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0414 - val_mse: 0.0065\n",
      "Epoch 77/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0440 - val_mse: 0.0067\n",
      "Epoch 78/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0069 - val_mae: 0.0454 - val_mse: 0.0069\n",
      "Epoch 79/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0068 - val_mae: 0.0444 - val_mse: 0.0068\n",
      "Epoch 80/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0412 - val_mse: 0.0065\n",
      "Epoch 81/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0415 - val_mse: 0.0065\n",
      "Epoch 82/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0066 - val_mae: 0.0419 - val_mse: 0.0066\n",
      "Epoch 83/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0067 - val_mae: 0.0435 - val_mse: 0.0067\n",
      "Epoch 84/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0312 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0410 - val_mse: 0.0065\n",
      "Epoch 85/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0417 - val_mse: 0.0065\n",
      "Epoch 86/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0411 - val_mse: 0.0065\n",
      "Epoch 87/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0316 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0458 - val_mse: 0.0071\n",
      "Epoch 88/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0425 - val_mse: 0.0067\n",
      "Epoch 89/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0421 - val_mse: 0.0065\n",
      "Epoch 90/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0432 - val_mse: 0.0067\n",
      "Epoch 91/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0025 - mae: 0.0331 - mse: 0.0025 - val_loss: 0.0067 - val_mae: 0.0414 - val_mse: 0.0067\n",
      "Epoch 92/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0312 - mse: 0.0021 - val_loss: 0.0067 - val_mae: 0.0422 - val_mse: 0.0067\n",
      "Epoch 93/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0066 - val_mae: 0.0422 - val_mse: 0.0066\n",
      "Epoch 94/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0312 - mse: 0.0020 - val_loss: 0.0065 - val_mae: 0.0414 - val_mse: 0.0065\n",
      "Epoch 95/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0021 - val_loss: 0.0066 - val_mae: 0.0435 - val_mse: 0.0066\n",
      "Epoch 96/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0068 - val_mae: 0.0431 - val_mse: 0.0068\n",
      "Epoch 97/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0417 - val_mse: 0.0065\n",
      "Epoch 98/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0069 - val_mae: 0.0437 - val_mse: 0.0069\n",
      "Epoch 99/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0020 - mae: 0.0311 - mse: 0.0020 - val_loss: 0.0067 - val_mae: 0.0413 - val_mse: 0.0067\n",
      "Epoch 100/100\n",
      "400/400 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0410 - val_mse: 0.0065\n",
      "600/600 [==============================] - 1s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "466/466 [==============================] - 5s 5ms/step - loss: 0.0176 - mae: 0.0821 - mse: 0.0176 - val_loss: 0.0104 - val_mae: 0.0424 - val_mse: 0.0104\n",
      "Epoch 2/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0046 - mae: 0.0516 - mse: 0.0046 - val_loss: 0.0101 - val_mae: 0.0437 - val_mse: 0.0101\n",
      "Epoch 3/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0041 - mae: 0.0478 - mse: 0.0041 - val_loss: 0.0102 - val_mae: 0.0450 - val_mse: 0.0102\n",
      "Epoch 4/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0036 - mae: 0.0454 - mse: 0.0036 - val_loss: 0.0098 - val_mae: 0.0429 - val_mse: 0.0098\n",
      "Epoch 5/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0442 - mse: 0.0035 - val_loss: 0.0100 - val_mae: 0.0429 - val_mse: 0.0100\n",
      "Epoch 6/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0035 - mae: 0.0432 - mse: 0.0035 - val_loss: 0.0102 - val_mae: 0.0481 - val_mse: 0.0102\n",
      "Epoch 7/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0412 - mse: 0.0031 - val_loss: 0.0103 - val_mae: 0.0448 - val_mse: 0.0103\n",
      "Epoch 8/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0029 - mae: 0.0397 - mse: 0.0029 - val_loss: 0.0109 - val_mae: 0.0464 - val_mse: 0.0109\n",
      "Epoch 9/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0028 - mae: 0.0386 - mse: 0.0028 - val_loss: 0.0102 - val_mae: 0.0469 - val_mse: 0.0102\n",
      "Epoch 10/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0373 - mse: 0.0027 - val_loss: 0.0103 - val_mae: 0.0477 - val_mse: 0.0103\n",
      "Epoch 11/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0364 - mse: 0.0025 - val_loss: 0.0101 - val_mae: 0.0427 - val_mse: 0.0101\n",
      "Epoch 12/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0355 - mse: 0.0024 - val_loss: 0.0114 - val_mae: 0.0580 - val_mse: 0.0114\n",
      "Epoch 13/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0357 - mse: 0.0025 - val_loss: 0.0100 - val_mae: 0.0468 - val_mse: 0.0100\n",
      "Epoch 14/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0348 - mse: 0.0024 - val_loss: 0.0100 - val_mae: 0.0440 - val_mse: 0.0100\n",
      "Epoch 15/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0340 - mse: 0.0023 - val_loss: 0.0100 - val_mae: 0.0429 - val_mse: 0.0100\n",
      "Epoch 16/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0337 - mse: 0.0023 - val_loss: 0.0101 - val_mae: 0.0466 - val_mse: 0.0101\n",
      "Epoch 17/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0332 - mse: 0.0022 - val_loss: 0.0105 - val_mae: 0.0429 - val_mse: 0.0105\n",
      "Epoch 18/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0331 - mse: 0.0022 - val_loss: 0.0103 - val_mae: 0.0443 - val_mse: 0.0103\n",
      "Epoch 19/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0326 - mse: 0.0022 - val_loss: 0.0105 - val_mae: 0.0423 - val_mse: 0.0105\n",
      "Epoch 20/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0333 - mse: 0.0023 - val_loss: 0.0101 - val_mae: 0.0457 - val_mse: 0.0101\n",
      "Epoch 21/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0332 - mse: 0.0023 - val_loss: 0.0102 - val_mae: 0.0476 - val_mse: 0.0102\n",
      "Epoch 22/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0330 - mse: 0.0023 - val_loss: 0.0100 - val_mae: 0.0436 - val_mse: 0.0100\n",
      "Epoch 23/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0332 - mse: 0.0024 - val_loss: 0.0097 - val_mae: 0.0436 - val_mse: 0.0097\n",
      "Epoch 24/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0107 - val_mae: 0.0436 - val_mse: 0.0107\n",
      "Epoch 25/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0098 - val_mae: 0.0429 - val_mse: 0.0098\n",
      "Epoch 26/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0327 - mse: 0.0022 - val_loss: 0.0101 - val_mae: 0.0451 - val_mse: 0.0101\n",
      "Epoch 27/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0098 - val_mae: 0.0429 - val_mse: 0.0098\n",
      "Epoch 28/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0104 - val_mae: 0.0424 - val_mse: 0.0104\n",
      "Epoch 29/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0326 - mse: 0.0022 - val_loss: 0.0101 - val_mae: 0.0425 - val_mse: 0.0101\n",
      "Epoch 30/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0332 - mse: 0.0023 - val_loss: 0.0109 - val_mae: 0.0443 - val_mse: 0.0109\n",
      "Epoch 31/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0113 - val_mae: 0.0476 - val_mse: 0.0113\n",
      "Epoch 32/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0105 - val_mae: 0.0426 - val_mse: 0.0105\n",
      "Epoch 33/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0099 - val_mae: 0.0432 - val_mse: 0.0099\n",
      "Epoch 34/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0100 - val_mae: 0.0447 - val_mse: 0.0100\n",
      "Epoch 35/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0321 - mse: 0.0021 - val_loss: 0.0100 - val_mae: 0.0427 - val_mse: 0.0100\n",
      "Epoch 36/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0098 - val_mae: 0.0431 - val_mse: 0.0098\n",
      "Epoch 37/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0103 - val_mae: 0.0459 - val_mse: 0.0103\n",
      "Epoch 38/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0105 - val_mae: 0.0473 - val_mse: 0.0105\n",
      "Epoch 39/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0105 - val_mae: 0.0439 - val_mse: 0.0105\n",
      "Epoch 40/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0097 - val_mae: 0.0427 - val_mse: 0.0097\n",
      "Epoch 41/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0101 - val_mae: 0.0428 - val_mse: 0.0101\n",
      "Epoch 42/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0098 - val_mae: 0.0440 - val_mse: 0.0098\n",
      "Epoch 43/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0106 - val_mae: 0.0429 - val_mse: 0.0106\n",
      "Epoch 44/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0103 - val_mae: 0.0436 - val_mse: 0.0103\n",
      "Epoch 45/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0100 - val_mae: 0.0437 - val_mse: 0.0100\n",
      "Epoch 46/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0099 - val_mae: 0.0436 - val_mse: 0.0099\n",
      "Epoch 47/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0103 - val_mae: 0.0427 - val_mse: 0.0103\n",
      "Epoch 48/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0096 - val_mae: 0.0442 - val_mse: 0.0096\n",
      "Epoch 49/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0097 - val_mae: 0.0446 - val_mse: 0.0097\n",
      "Epoch 50/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0098 - val_mae: 0.0431 - val_mse: 0.0098\n",
      "Epoch 51/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0108 - val_mae: 0.0445 - val_mse: 0.0108\n",
      "Epoch 52/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0103 - val_mae: 0.0439 - val_mse: 0.0103\n",
      "Epoch 53/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0102 - val_mae: 0.0431 - val_mse: 0.0102\n",
      "Epoch 54/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0102 - val_mae: 0.0438 - val_mse: 0.0102\n",
      "Epoch 55/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0327 - mse: 0.0022 - val_loss: 0.0100 - val_mae: 0.0424 - val_mse: 0.0100\n",
      "Epoch 56/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0100 - val_mae: 0.0450 - val_mse: 0.0100\n",
      "Epoch 57/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0099 - val_mae: 0.0426 - val_mse: 0.0099\n",
      "Epoch 58/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0097 - val_mae: 0.0433 - val_mse: 0.0097\n",
      "Epoch 59/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0101 - val_mae: 0.0432 - val_mse: 0.0101\n",
      "Epoch 60/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0321 - mse: 0.0021 - val_loss: 0.0099 - val_mae: 0.0427 - val_mse: 0.0099\n",
      "Epoch 61/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0100 - val_mae: 0.0427 - val_mse: 0.0100\n",
      "Epoch 62/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0102 - val_mae: 0.0428 - val_mse: 0.0102\n",
      "Epoch 63/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0330 - mse: 0.0024 - val_loss: 0.0097 - val_mae: 0.0430 - val_mse: 0.0097\n",
      "Epoch 64/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0099 - val_mae: 0.0422 - val_mse: 0.0099\n",
      "Epoch 65/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0318 - mse: 0.0021 - val_loss: 0.0100 - val_mae: 0.0427 - val_mse: 0.0100\n",
      "Epoch 66/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0328 - mse: 0.0024 - val_loss: 0.0103 - val_mae: 0.0425 - val_mse: 0.0103\n",
      "Epoch 67/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0097 - val_mae: 0.0427 - val_mse: 0.0097\n",
      "Epoch 68/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0100 - val_mae: 0.0431 - val_mse: 0.0100\n",
      "Epoch 69/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0099 - val_mae: 0.0438 - val_mse: 0.0099\n",
      "Epoch 70/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0102 - val_mae: 0.0438 - val_mse: 0.0102\n",
      "Epoch 71/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0102 - val_mae: 0.0464 - val_mse: 0.0102\n",
      "Epoch 72/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0107 - val_mae: 0.0530 - val_mse: 0.0107\n",
      "Epoch 73/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0102 - val_mae: 0.0444 - val_mse: 0.0102\n",
      "Epoch 74/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0101 - val_mae: 0.0425 - val_mse: 0.0101\n",
      "Epoch 75/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0319 - mse: 0.0021 - val_loss: 0.0095 - val_mae: 0.0434 - val_mse: 0.0095\n",
      "Epoch 76/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0098 - val_mae: 0.0425 - val_mse: 0.0098\n",
      "Epoch 77/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0097 - val_mae: 0.0439 - val_mse: 0.0097\n",
      "Epoch 78/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0105 - val_mae: 0.0442 - val_mse: 0.0105\n",
      "Epoch 79/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0109 - val_mae: 0.0439 - val_mse: 0.0109\n",
      "Epoch 80/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0096 - val_mae: 0.0431 - val_mse: 0.0096\n",
      "Epoch 81/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0095 - val_mae: 0.0438 - val_mse: 0.0095\n",
      "Epoch 82/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0097 - val_mae: 0.0439 - val_mse: 0.0097\n",
      "Epoch 83/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0103 - val_mae: 0.0431 - val_mse: 0.0103\n",
      "Epoch 84/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0098 - val_mae: 0.0423 - val_mse: 0.0098\n",
      "Epoch 85/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0100 - val_mae: 0.0433 - val_mse: 0.0100\n",
      "Epoch 86/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0102 - val_mae: 0.0445 - val_mse: 0.0102\n",
      "Epoch 87/100\n",
      "466/466 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0103 - val_mae: 0.0433 - val_mse: 0.0103\n",
      "Epoch 88/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0100 - val_mae: 0.0423 - val_mse: 0.0100\n",
      "Epoch 89/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0099 - val_mae: 0.0423 - val_mse: 0.0099\n",
      "Epoch 90/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0105 - val_mae: 0.0463 - val_mse: 0.0105\n",
      "Epoch 91/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0108 - val_mae: 0.0426 - val_mse: 0.0108\n",
      "Epoch 92/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0099 - val_mae: 0.0428 - val_mse: 0.0099\n",
      "Epoch 93/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0097 - val_mae: 0.0423 - val_mse: 0.0097\n",
      "Epoch 94/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0100 - val_mae: 0.0426 - val_mse: 0.0100\n",
      "Epoch 95/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0097 - val_mae: 0.0423 - val_mse: 0.0097\n",
      "Epoch 96/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0099 - val_mae: 0.0433 - val_mse: 0.0099\n",
      "Epoch 97/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0100 - val_mae: 0.0435 - val_mse: 0.0100\n",
      "Epoch 98/100\n",
      "466/466 [==============================] - 2s 5ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0097 - val_mae: 0.0426 - val_mse: 0.0097\n",
      "Epoch 99/100\n",
      "466/466 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0102 - val_mae: 0.0469 - val_mse: 0.0102\n",
      "Epoch 100/100\n",
      "466/466 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0105 - val_mae: 0.0445 - val_mse: 0.0105\n",
      "699/699 [==============================] - 1s 934us/step\n",
      "100/100 [==============================] - 0s 927us/step\n",
      "123/123 [==============================] - 0s 968us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "533/533 [==============================] - 5s 5ms/step - loss: 0.0175 - mae: 0.0827 - mse: 0.0175 - val_loss: 0.0054 - val_mae: 0.0409 - val_mse: 0.0054\n",
      "Epoch 2/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0048 - mae: 0.0527 - mse: 0.0048 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 3/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0042 - mae: 0.0490 - mse: 0.0042 - val_loss: 0.0056 - val_mae: 0.0433 - val_mse: 0.0056\n",
      "Epoch 4/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0461 - mse: 0.0038 - val_loss: 0.0053 - val_mae: 0.0411 - val_mse: 0.0053\n",
      "Epoch 5/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0034 - mae: 0.0434 - mse: 0.0034 - val_loss: 0.0052 - val_mae: 0.0401 - val_mse: 0.0052\n",
      "Epoch 6/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0031 - mae: 0.0415 - mse: 0.0031 - val_loss: 0.0054 - val_mae: 0.0419 - val_mse: 0.0054\n",
      "Epoch 7/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0030 - mae: 0.0403 - mse: 0.0030 - val_loss: 0.0052 - val_mae: 0.0396 - val_mse: 0.0052\n",
      "Epoch 8/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0379 - mse: 0.0027 - val_loss: 0.0056 - val_mae: 0.0432 - val_mse: 0.0056\n",
      "Epoch 9/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0027 - mae: 0.0373 - mse: 0.0027 - val_loss: 0.0054 - val_mae: 0.0426 - val_mse: 0.0054\n",
      "Epoch 10/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0026 - mae: 0.0362 - mse: 0.0026 - val_loss: 0.0053 - val_mae: 0.0413 - val_mse: 0.0053\n",
      "Epoch 11/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0346 - mse: 0.0024 - val_loss: 0.0053 - val_mae: 0.0402 - val_mse: 0.0053\n",
      "Epoch 12/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0344 - mse: 0.0024 - val_loss: 0.0057 - val_mae: 0.0440 - val_mse: 0.0057\n",
      "Epoch 13/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0340 - mse: 0.0024 - val_loss: 0.0056 - val_mae: 0.0427 - val_mse: 0.0056\n",
      "Epoch 14/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0335 - mse: 0.0024 - val_loss: 0.0052 - val_mae: 0.0397 - val_mse: 0.0052\n",
      "Epoch 15/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0334 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0419 - val_mse: 0.0054\n",
      "Epoch 16/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0327 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0405 - val_mse: 0.0053\n",
      "Epoch 17/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0333 - mse: 0.0024 - val_loss: 0.0052 - val_mae: 0.0406 - val_mse: 0.0052\n",
      "Epoch 18/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0054 - val_mae: 0.0419 - val_mse: 0.0054\n",
      "Epoch 19/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0397 - val_mse: 0.0052\n",
      "Epoch 20/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0053 - val_mae: 0.0410 - val_mse: 0.0053\n",
      "Epoch 21/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0420 - val_mse: 0.0054\n",
      "Epoch 22/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0430 - val_mse: 0.0054\n",
      "Epoch 23/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0409 - val_mse: 0.0053\n",
      "Epoch 24/100\n",
      "533/533 [==============================] - 2s 5ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0405 - val_mse: 0.0053\n",
      "Epoch 25/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0055 - val_mae: 0.0413 - val_mse: 0.0055\n",
      "Epoch 26/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0401 - val_mse: 0.0052\n",
      "Epoch 27/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0052 - val_mae: 0.0397 - val_mse: 0.0052\n",
      "Epoch 28/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0396 - val_mse: 0.0052\n",
      "Epoch 29/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0401 - val_mse: 0.0052\n",
      "Epoch 30/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0331 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0396 - val_mse: 0.0052\n",
      "Epoch 31/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0053 - val_mae: 0.0411 - val_mse: 0.0053\n",
      "Epoch 32/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0397 - val_mse: 0.0052\n",
      "Epoch 33/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0423 - val_mse: 0.0054\n",
      "Epoch 34/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0403 - val_mse: 0.0054\n",
      "Epoch 35/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0406 - val_mse: 0.0052\n",
      "Epoch 36/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 37/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0055 - val_mae: 0.0416 - val_mse: 0.0055\n",
      "Epoch 38/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0057 - val_mae: 0.0448 - val_mse: 0.0057\n",
      "Epoch 39/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0393 - val_mse: 0.0052\n",
      "Epoch 40/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0397 - val_mse: 0.0052\n",
      "Epoch 41/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0053 - val_mae: 0.0396 - val_mse: 0.0053\n",
      "Epoch 42/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0054 - val_mae: 0.0402 - val_mse: 0.0054\n",
      "Epoch 43/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0055 - val_mae: 0.0438 - val_mse: 0.0055\n",
      "Epoch 44/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0053 - val_mae: 0.0406 - val_mse: 0.0053\n",
      "Epoch 45/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0319 - mse: 0.0021 - val_loss: 0.0055 - val_mae: 0.0428 - val_mse: 0.0055\n",
      "Epoch 46/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0396 - val_mse: 0.0052\n",
      "Epoch 47/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0407 - val_mse: 0.0054\n",
      "Epoch 48/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0410 - val_mse: 0.0053\n",
      "Epoch 49/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0054 - val_mae: 0.0423 - val_mse: 0.0054\n",
      "Epoch 50/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0399 - val_mse: 0.0053\n",
      "Epoch 51/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0398 - val_mse: 0.0052\n",
      "Epoch 52/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0394 - val_mse: 0.0052\n",
      "Epoch 53/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0052 - val_mae: 0.0393 - val_mse: 0.0052\n",
      "Epoch 54/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0414 - val_mse: 0.0053\n",
      "Epoch 55/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0393 - val_mse: 0.0052\n",
      "Epoch 56/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0052 - val_mae: 0.0400 - val_mse: 0.0052\n",
      "Epoch 57/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 58/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0055 - val_mae: 0.0427 - val_mse: 0.0055\n",
      "Epoch 59/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0051 - val_mae: 0.0394 - val_mse: 0.0051\n",
      "Epoch 60/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0055 - val_mae: 0.0414 - val_mse: 0.0055\n",
      "Epoch 61/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0056 - val_mae: 0.0413 - val_mse: 0.0056\n",
      "Epoch 62/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0051 - val_mae: 0.0395 - val_mse: 0.0051\n",
      "Epoch 63/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0398 - val_mse: 0.0052\n",
      "Epoch 64/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0398 - val_mse: 0.0052\n",
      "Epoch 65/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 66/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0054 - val_mae: 0.0412 - val_mse: 0.0054\n",
      "Epoch 67/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0054 - val_mae: 0.0411 - val_mse: 0.0054\n",
      "Epoch 68/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0404 - val_mse: 0.0052\n",
      "Epoch 69/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 70/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0398 - val_mse: 0.0052\n",
      "Epoch 71/100\n",
      "533/533 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 72/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0054 - val_mae: 0.0419 - val_mse: 0.0054\n",
      "Epoch 73/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0318 - mse: 0.0021 - val_loss: 0.0053 - val_mae: 0.0403 - val_mse: 0.0053\n",
      "Epoch 74/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0403 - val_mse: 0.0052\n",
      "Epoch 75/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0394 - val_mse: 0.0052\n",
      "Epoch 76/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0399 - val_mse: 0.0052\n",
      "Epoch 77/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0053 - val_mae: 0.0407 - val_mse: 0.0053\n",
      "Epoch 78/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0053 - val_mae: 0.0403 - val_mse: 0.0053\n",
      "Epoch 79/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0400 - val_mse: 0.0052\n",
      "Epoch 80/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0406 - val_mse: 0.0053\n",
      "Epoch 81/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0399 - val_mse: 0.0052\n",
      "Epoch 82/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0403 - val_mse: 0.0052\n",
      "Epoch 83/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0397 - val_mse: 0.0052\n",
      "Epoch 84/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0398 - val_mse: 0.0052\n",
      "Epoch 85/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0321 - mse: 0.0021 - val_loss: 0.0051 - val_mae: 0.0394 - val_mse: 0.0051\n",
      "Epoch 86/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0396 - val_mse: 0.0052\n",
      "Epoch 87/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0399 - val_mse: 0.0052\n",
      "Epoch 88/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0322 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0463 - val_mse: 0.0059\n",
      "Epoch 89/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0404 - val_mse: 0.0054\n",
      "Epoch 90/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0053 - val_mae: 0.0395 - val_mse: 0.0053\n",
      "Epoch 91/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0054 - val_mae: 0.0407 - val_mse: 0.0054\n",
      "Epoch 92/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0316 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0392 - val_mse: 0.0052\n",
      "Epoch 93/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0054 - val_mae: 0.0405 - val_mse: 0.0054\n",
      "Epoch 94/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0053 - val_mae: 0.0397 - val_mse: 0.0053\n",
      "Epoch 95/100\n",
      "533/533 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0316 - mse: 0.0021 - val_loss: 0.0052 - val_mae: 0.0398 - val_mse: 0.0052\n",
      "Epoch 96/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 97/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0054 - val_mae: 0.0409 - val_mse: 0.0054\n",
      "Epoch 98/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0396 - val_mse: 0.0052\n",
      "Epoch 99/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0395 - val_mse: 0.0052\n",
      "Epoch 100/100\n",
      "533/533 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0052 - val_mae: 0.0400 - val_mse: 0.0052\n",
      "799/799 [==============================] - 1s 977us/step\n",
      "100/100 [==============================] - 0s 968us/step\n",
      "123/123 [==============================] - 0s 968us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "599/599 [==============================] - 4s 4ms/step - loss: 0.0140 - mae: 0.0744 - mse: 0.0140 - val_loss: 0.0060 - val_mae: 0.0396 - val_mse: 0.0060\n",
      "Epoch 2/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0042 - mae: 0.0492 - mse: 0.0042 - val_loss: 0.0060 - val_mae: 0.0389 - val_mse: 0.0060\n",
      "Epoch 3/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0037 - mae: 0.0455 - mse: 0.0037 - val_loss: 0.0065 - val_mae: 0.0445 - val_mse: 0.0065\n",
      "Epoch 4/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0034 - mae: 0.0435 - mse: 0.0034 - val_loss: 0.0060 - val_mae: 0.0389 - val_mse: 0.0060\n",
      "Epoch 5/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0031 - mae: 0.0416 - mse: 0.0031 - val_loss: 0.0066 - val_mae: 0.0460 - val_mse: 0.0066\n",
      "Epoch 6/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0030 - mae: 0.0402 - mse: 0.0030 - val_loss: 0.0061 - val_mae: 0.0403 - val_mse: 0.0061\n",
      "Epoch 7/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0029 - mae: 0.0390 - mse: 0.0029 - val_loss: 0.0059 - val_mae: 0.0392 - val_mse: 0.0059\n",
      "Epoch 8/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0027 - mae: 0.0370 - mse: 0.0027 - val_loss: 0.0062 - val_mae: 0.0401 - val_mse: 0.0062\n",
      "Epoch 9/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0026 - mae: 0.0365 - mse: 0.0026 - val_loss: 0.0060 - val_mae: 0.0401 - val_mse: 0.0060\n",
      "Epoch 10/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0025 - mae: 0.0355 - mse: 0.0025 - val_loss: 0.0062 - val_mae: 0.0407 - val_mse: 0.0062\n",
      "Epoch 11/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0344 - mse: 0.0024 - val_loss: 0.0061 - val_mae: 0.0387 - val_mse: 0.0061\n",
      "Epoch 12/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0026 - mae: 0.0349 - mse: 0.0026 - val_loss: 0.0062 - val_mae: 0.0408 - val_mse: 0.0062\n",
      "Epoch 13/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0337 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0400 - val_mse: 0.0060\n",
      "Epoch 14/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0334 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0395 - val_mse: 0.0059\n",
      "Epoch 15/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0328 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0398 - val_mse: 0.0060\n",
      "Epoch 16/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0381 - val_mse: 0.0060\n",
      "Epoch 17/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0330 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0390 - val_mse: 0.0061\n",
      "Epoch 18/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0332 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0407 - val_mse: 0.0061\n",
      "Epoch 19/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0402 - val_mse: 0.0062\n",
      "Epoch 20/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0326 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0420 - val_mse: 0.0062\n",
      "Epoch 21/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0332 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0395 - val_mse: 0.0061\n",
      "Epoch 22/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0334 - mse: 0.0024 - val_loss: 0.0060 - val_mae: 0.0383 - val_mse: 0.0060\n",
      "Epoch 23/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0403 - val_mse: 0.0062\n",
      "Epoch 24/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0392 - val_mse: 0.0059\n",
      "Epoch 25/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0386 - val_mse: 0.0060\n",
      "Epoch 26/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0390 - val_mse: 0.0059\n",
      "Epoch 27/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0330 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0392 - val_mse: 0.0060\n",
      "Epoch 28/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0333 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0391 - val_mse: 0.0059\n",
      "Epoch 29/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0330 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 30/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0330 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0393 - val_mse: 0.0060\n",
      "Epoch 31/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0385 - val_mse: 0.0059\n",
      "Epoch 32/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0066 - val_mae: 0.0432 - val_mse: 0.0066\n",
      "Epoch 33/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0390 - val_mse: 0.0059\n",
      "Epoch 34/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0384 - val_mse: 0.0059\n",
      "Epoch 35/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0390 - val_mse: 0.0060\n",
      "Epoch 36/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0409 - val_mse: 0.0063\n",
      "Epoch 37/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0061 - val_mae: 0.0411 - val_mse: 0.0061\n",
      "Epoch 38/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0399 - val_mse: 0.0062\n",
      "Epoch 39/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0421 - val_mse: 0.0063\n",
      "Epoch 40/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0402 - val_mse: 0.0061\n",
      "Epoch 41/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0390 - val_mse: 0.0061\n",
      "Epoch 42/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0330 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0384 - val_mse: 0.0059\n",
      "Epoch 43/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0389 - val_mse: 0.0060\n",
      "Epoch 44/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0398 - val_mse: 0.0062\n",
      "Epoch 45/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0383 - val_mse: 0.0059\n",
      "Epoch 46/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0061 - val_mae: 0.0410 - val_mse: 0.0061\n",
      "Epoch 47/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0395 - val_mse: 0.0062\n",
      "Epoch 48/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0069 - val_mae: 0.0488 - val_mse: 0.0069\n",
      "Epoch 49/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0329 - mse: 0.0024 - val_loss: 0.0063 - val_mae: 0.0392 - val_mse: 0.0063\n",
      "Epoch 50/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0385 - val_mse: 0.0060\n",
      "Epoch 51/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0389 - val_mse: 0.0060\n",
      "Epoch 52/100\n",
      "599/599 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0387 - val_mse: 0.0059\n",
      "Epoch 53/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0384 - val_mse: 0.0060\n",
      "Epoch 54/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0385 - val_mse: 0.0060\n",
      "Epoch 55/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0428 - val_mse: 0.0065\n",
      "Epoch 56/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0393 - val_mse: 0.0060\n",
      "Epoch 57/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0406 - val_mse: 0.0062\n",
      "Epoch 58/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0382 - val_mse: 0.0059\n",
      "Epoch 59/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0409 - val_mse: 0.0063\n",
      "Epoch 60/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0405 - val_mse: 0.0063\n",
      "Epoch 61/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0391 - val_mse: 0.0060\n",
      "Epoch 62/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0403 - val_mse: 0.0062\n",
      "Epoch 63/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0400 - val_mse: 0.0060\n",
      "Epoch 64/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0413 - val_mse: 0.0063\n",
      "Epoch 65/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0064 - val_mae: 0.0401 - val_mse: 0.0064\n",
      "Epoch 66/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0383 - val_mse: 0.0059\n",
      "Epoch 67/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0385 - val_mse: 0.0060\n",
      "Epoch 68/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 69/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0330 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0385 - val_mse: 0.0059\n",
      "Epoch 70/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0423 - val_mse: 0.0062\n",
      "Epoch 71/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0064 - val_mae: 0.0410 - val_mse: 0.0064\n",
      "Epoch 72/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0324 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0397 - val_mse: 0.0060\n",
      "Epoch 73/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0406 - val_mse: 0.0063\n",
      "Epoch 74/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0320 - mse: 0.0021 - val_loss: 0.0062 - val_mae: 0.0396 - val_mse: 0.0062\n",
      "Epoch 75/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0330 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0428 - val_mse: 0.0062\n",
      "Epoch 76/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0389 - val_mse: 0.0059\n",
      "Epoch 77/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0382 - val_mse: 0.0060\n",
      "Epoch 78/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0327 - mse: 0.0024 - val_loss: 0.0061 - val_mae: 0.0391 - val_mse: 0.0061\n",
      "Epoch 79/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0387 - val_mse: 0.0059\n",
      "Epoch 80/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0389 - val_mse: 0.0059\n",
      "Epoch 81/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0394 - val_mse: 0.0062\n",
      "Epoch 82/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0322 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0395 - val_mse: 0.0060\n",
      "Epoch 83/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0388 - val_mse: 0.0059\n",
      "Epoch 84/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0383 - val_mse: 0.0060\n",
      "Epoch 85/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0329 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0383 - val_mse: 0.0059\n",
      "Epoch 86/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0384 - val_mse: 0.0060\n",
      "Epoch 87/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0381 - val_mse: 0.0060\n",
      "Epoch 88/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0386 - val_mse: 0.0059\n",
      "Epoch 89/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0024 - mae: 0.0332 - mse: 0.0024 - val_loss: 0.0064 - val_mae: 0.0416 - val_mse: 0.0064\n",
      "Epoch 90/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0391 - val_mse: 0.0059\n",
      "Epoch 91/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0021 - mae: 0.0317 - mse: 0.0021 - val_loss: 0.0061 - val_mae: 0.0400 - val_mse: 0.0061\n",
      "Epoch 92/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0383 - val_mse: 0.0059\n",
      "Epoch 93/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0385 - val_mse: 0.0060\n",
      "Epoch 94/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0321 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0391 - val_mse: 0.0060\n",
      "Epoch 95/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0394 - val_mse: 0.0060\n",
      "Epoch 96/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0389 - val_mse: 0.0059\n",
      "Epoch 97/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0384 - val_mse: 0.0060\n",
      "Epoch 98/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0320 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0401 - val_mse: 0.0063\n",
      "Epoch 99/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0389 - val_mse: 0.0059\n",
      "Epoch 100/100\n",
      "599/599 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0061 - val_mae: 0.0398 - val_mse: 0.0061\n",
      "899/899 [==============================] - 1s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_13120\\2027109278.py:84: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "666/666 [==============================] - 6s 5ms/step - loss: 0.0153 - mae: 0.0769 - mse: 0.0153 - val_loss: 0.0058 - val_mae: 0.0377 - val_mse: 0.0058\n",
      "Epoch 2/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0046 - mae: 0.0514 - mse: 0.0046 - val_loss: 0.0059 - val_mae: 0.0386 - val_mse: 0.0059\n",
      "Epoch 3/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0039 - mae: 0.0472 - mse: 0.0039 - val_loss: 0.0059 - val_mae: 0.0388 - val_mse: 0.0059\n",
      "Epoch 4/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0035 - mae: 0.0440 - mse: 0.0035 - val_loss: 0.0059 - val_mae: 0.0397 - val_mse: 0.0059\n",
      "Epoch 5/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0032 - mae: 0.0418 - mse: 0.0032 - val_loss: 0.0058 - val_mae: 0.0379 - val_mse: 0.0058\n",
      "Epoch 6/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0029 - mae: 0.0392 - mse: 0.0029 - val_loss: 0.0059 - val_mae: 0.0396 - val_mse: 0.0059\n",
      "Epoch 7/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0028 - mae: 0.0378 - mse: 0.0028 - val_loss: 0.0061 - val_mae: 0.0421 - val_mse: 0.0061\n",
      "Epoch 8/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0362 - mse: 0.0026 - val_loss: 0.0061 - val_mae: 0.0415 - val_mse: 0.0061\n",
      "Epoch 9/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0026 - mae: 0.0353 - mse: 0.0026 - val_loss: 0.0058 - val_mae: 0.0381 - val_mse: 0.0058\n",
      "Epoch 10/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0025 - mae: 0.0344 - mse: 0.0025 - val_loss: 0.0059 - val_mae: 0.0385 - val_mse: 0.0059\n",
      "Epoch 11/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0332 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0399 - val_mse: 0.0059\n",
      "Epoch 12/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0337 - mse: 0.0024 - val_loss: 0.0060 - val_mae: 0.0395 - val_mse: 0.0060\n",
      "Epoch 13/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0326 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0386 - val_mse: 0.0059\n",
      "Epoch 14/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0326 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0378 - val_mse: 0.0058\n",
      "Epoch 15/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0403 - val_mse: 0.0061\n",
      "Epoch 16/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0378 - val_mse: 0.0059\n",
      "Epoch 17/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0328 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0379 - val_mse: 0.0058\n",
      "Epoch 18/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0333 - mse: 0.0024 - val_loss: 0.0060 - val_mae: 0.0380 - val_mse: 0.0060\n",
      "Epoch 19/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0405 - val_mse: 0.0059\n",
      "Epoch 20/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0393 - val_mse: 0.0060\n",
      "Epoch 21/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0394 - val_mse: 0.0058\n",
      "Epoch 22/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0379 - val_mse: 0.0058\n",
      "Epoch 23/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0378 - val_mse: 0.0058\n",
      "Epoch 24/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0383 - val_mse: 0.0059\n",
      "Epoch 25/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0379 - val_mse: 0.0058\n",
      "Epoch 26/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0391 - val_mse: 0.0059\n",
      "Epoch 27/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0330 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0380 - val_mse: 0.0059\n",
      "Epoch 28/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0410 - val_mse: 0.0063\n",
      "Epoch 29/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0379 - val_mse: 0.0059\n",
      "Epoch 30/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0404 - val_mse: 0.0061\n",
      "Epoch 31/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0375 - val_mse: 0.0059\n",
      "Epoch 32/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0377 - val_mse: 0.0058\n",
      "Epoch 33/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0393 - val_mse: 0.0058\n",
      "Epoch 34/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0396 - val_mse: 0.0060\n",
      "Epoch 35/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0380 - val_mse: 0.0059\n",
      "Epoch 36/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0381 - val_mse: 0.0058\n",
      "Epoch 37/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0057 - val_mae: 0.0388 - val_mse: 0.0057\n",
      "Epoch 38/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0389 - val_mse: 0.0059\n",
      "Epoch 39/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0330 - mse: 0.0024 - val_loss: 0.0060 - val_mae: 0.0382 - val_mse: 0.0060\n",
      "Epoch 40/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0406 - val_mse: 0.0060\n",
      "Epoch 41/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0328 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0388 - val_mse: 0.0059\n",
      "Epoch 42/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0406 - val_mse: 0.0061\n",
      "Epoch 43/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0331 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0386 - val_mse: 0.0059\n",
      "Epoch 44/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 45/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0380 - val_mse: 0.0058\n",
      "Epoch 46/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0321 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0388 - val_mse: 0.0061\n",
      "Epoch 47/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0329 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0382 - val_mse: 0.0059\n",
      "Epoch 48/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0057 - val_mae: 0.0375 - val_mse: 0.0057\n",
      "Epoch 49/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0326 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0441 - val_mse: 0.0061\n",
      "Epoch 50/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0442 - val_mse: 0.0063\n",
      "Epoch 51/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0382 - val_mse: 0.0059\n",
      "Epoch 52/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0061 - val_mae: 0.0384 - val_mse: 0.0061\n",
      "Epoch 53/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0325 - mse: 0.0023 - val_loss: 0.0057 - val_mae: 0.0378 - val_mse: 0.0057\n",
      "Epoch 54/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0384 - val_mse: 0.0058\n",
      "Epoch 55/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0383 - val_mse: 0.0059\n",
      "Epoch 56/100\n",
      "666/666 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0398 - val_mse: 0.0061\n",
      "Epoch 57/100\n",
      "666/666 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0385 - val_mse: 0.0060\n",
      "Epoch 58/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0411 - val_mse: 0.0063\n",
      "Epoch 59/100\n",
      "666/666 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0326 - mse: 0.0024 - val_loss: 0.0058 - val_mae: 0.0389 - val_mse: 0.0058\n",
      "Epoch 60/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0375 - val_mse: 0.0058\n",
      "Epoch 61/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0377 - val_mse: 0.0058\n",
      "Epoch 62/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0406 - val_mse: 0.0063\n",
      "Epoch 63/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0397 - val_mse: 0.0061\n",
      "Epoch 64/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0377 - val_mse: 0.0059\n",
      "Epoch 65/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0060 - val_mae: 0.0390 - val_mse: 0.0060\n",
      "Epoch 66/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0401 - val_mse: 0.0059\n",
      "Epoch 67/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0378 - val_mse: 0.0058\n",
      "Epoch 68/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0061 - val_mae: 0.0391 - val_mse: 0.0061\n",
      "Epoch 69/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0324 - mse: 0.0024 - val_loss: 0.0062 - val_mae: 0.0429 - val_mse: 0.0062\n",
      "Epoch 70/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0379 - val_mse: 0.0058\n",
      "Epoch 71/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0315 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0382 - val_mse: 0.0058\n",
      "Epoch 72/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0385 - val_mse: 0.0059\n",
      "Epoch 73/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0389 - val_mse: 0.0060\n",
      "Epoch 74/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0321 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0381 - val_mse: 0.0058\n",
      "Epoch 75/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0322 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0391 - val_mse: 0.0059\n",
      "Epoch 76/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0324 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0379 - val_mse: 0.0059\n",
      "Epoch 77/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0378 - val_mse: 0.0058\n",
      "Epoch 78/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0317 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0391 - val_mse: 0.0058\n",
      "Epoch 79/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0024 - mae: 0.0327 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0379 - val_mse: 0.0059\n",
      "Epoch 80/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0381 - val_mse: 0.0058\n",
      "Epoch 81/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0386 - val_mse: 0.0059\n",
      "Epoch 82/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0376 - val_mse: 0.0058\n",
      "Epoch 83/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0322 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0378 - val_mse: 0.0058\n",
      "Epoch 84/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0321 - mse: 0.0022 - val_loss: 0.0057 - val_mae: 0.0377 - val_mse: 0.0057\n",
      "Epoch 85/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0322 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0390 - val_mse: 0.0059\n",
      "Epoch 86/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0377 - val_mse: 0.0058\n",
      "Epoch 87/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0321 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0377 - val_mse: 0.0060\n",
      "Epoch 88/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0321 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0377 - val_mse: 0.0059\n",
      "Epoch 89/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0057 - val_mae: 0.0376 - val_mse: 0.0057\n",
      "Epoch 90/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0320 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0389 - val_mse: 0.0058\n",
      "Epoch 91/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0320 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0405 - val_mse: 0.0060\n",
      "Epoch 92/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0318 - mse: 0.0022 - val_loss: 0.0058 - val_mae: 0.0378 - val_mse: 0.0058\n",
      "Epoch 93/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0391 - val_mse: 0.0059\n",
      "Epoch 94/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0381 - val_mse: 0.0059\n",
      "Epoch 95/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0323 - mse: 0.0023 - val_loss: 0.0059 - val_mae: 0.0409 - val_mse: 0.0059\n",
      "Epoch 96/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0321 - mse: 0.0023 - val_loss: 0.0065 - val_mae: 0.0389 - val_mse: 0.0065\n",
      "Epoch 97/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0320 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0380 - val_mse: 0.0060\n",
      "Epoch 98/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0059 - val_mae: 0.0405 - val_mse: 0.0059\n",
      "Epoch 99/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0023 - mae: 0.0322 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0407 - val_mse: 0.0060\n",
      "Epoch 100/100\n",
      "666/666 [==============================] - 3s 5ms/step - loss: 0.0022 - mae: 0.0319 - mse: 0.0022 - val_loss: 0.0061 - val_mae: 0.0390 - val_mse: 0.0061\n",
      "999/999 [==============================] - 1s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "123/123 [==============================] - 0s 1ms/step\n",
      "Results saved to models_exp/Ensemble_XGBoost_LSTM_GRU/exp_20240905_185730/exp_48_128_0.2/exp_48_128_0.2_20240905_192311.xlsx\n",
      "Results for cycle written to models_exp/Ensemble_XGBoost_LSTM_GRU/exp_20240905_185730/exp_48_128_0.2_20240905_192311_combined.xlsx\n",
      "Model eğitimi ve değerlendirmesi tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split, TimeSeriesSplit\n",
    "\n",
    "import xgboost as xgb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Batch size'leri tanımla\n",
    "batch_sizes = [48]\n",
    "unit_sizes = [128]\n",
    "dropout_sizes = [0.2]\n",
    "\n",
    "\"\"\"# Batch size'leri tanımla\n",
    "batch_sizes = [64]\n",
    "unit_sizes = [32, 64, 96, 128]\n",
    "dropout_sizes = [0.2, 0.3, 0.4, 0.5]\"\"\"\n",
    "\n",
    "\"\"\"n_estimators_list = [100, 200, 300]\n",
    "learning_rate_list = [0.01, 0.1, 0.2]\n",
    "max_depth_list = [6, 8, 10, 12]\n",
    "subsample_list = [0.7, 0.8, 0.9]\n",
    "colsample_bytree_list = [0.7, 0.8, 0.9]\"\"\"\n",
    "n_estimators = 100\n",
    "learning_rate = 0.1\n",
    "max_depth = 10\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "\n",
    "                   \n",
    "\n",
    "model_n = 'Ensemble_XGBoost_LSTM_GRU'\n",
    "# Klasör oluşturma\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "folder_main = f'models_exp/{model_n}'\n",
    "os.makedirs(folder_main, exist_ok=True)\n",
    "\n",
    "folder = f'{folder_main}/exp_{timestamp}'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for unit_size in unit_sizes:\n",
    "        for dropout_size in dropout_sizes:\n",
    "            fold_no = 1\n",
    "            all_fold_histories = []\n",
    "            params = []\n",
    "            fold_results = []\n",
    "\n",
    "            # Model parameters\n",
    "            params.append({\n",
    "                'File name': selected_file,\n",
    "                'Total Fold': 10,\n",
    "                'LSTM Units': unit_size,\n",
    "                'GRU Units': unit_size,\n",
    "                'Dropout Rate': dropout_size,\n",
    "                'Dense Units': 100,\n",
    "                'Batch Size': batch_size,\n",
    "                'Epochs': 100,\n",
    "                'LearningRate': '0.001',\n",
    "                'Normalizasyon': selected_norm,\n",
    "            })\n",
    "\n",
    "            \"\"\"kf = KFold(n_splits=params[0]['Total Fold'], shuffle=False)\n",
    "\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                # Create train/validation splits within each fold\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\"\"\"\n",
    "                \n",
    "            # KFold yerine TimeSeriesSplit kullanımı\n",
    "            tscv = TimeSeriesSplit(n_splits=params[0]['Total Fold'])\n",
    "\n",
    "            for train_index, val_index in tscv.split(X_train):\n",
    "                # Create train/validation splits within each fold\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "                \n",
    "                # Feature extraction with XGBoost\n",
    "                # XGBoost model\n",
    "                xgb_model = xgb.XGBRegressor(\n",
    "                    n_estimators=n_estimators,\n",
    "                    learning_rate=learning_rate,\n",
    "                    max_depth=max_depth,\n",
    "                    subsample=subsample,\n",
    "                    colsample_bytree=colsample_bytree\n",
    "                )\n",
    "                xgb_model.fit(X_train_fold, y_train_fold)\n",
    "                X_train_fold_xgb = xgb_model.predict(X_train_fold).reshape(-1, 1)\n",
    "                X_val_fold_xgb = xgb_model.predict(X_val_fold).reshape(-1, 1)\n",
    "                X_test_xgb = xgb_model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "                # Reshape the data\n",
    "                X_train_fold_xgb = np.array(X_train_fold_xgb).reshape((X_train_fold_xgb.shape[0], X_train_fold_xgb.shape[1], 1))\n",
    "                X_val_fold_xgb = np.array(X_val_fold_xgb).reshape((X_val_fold_xgb.shape[0], X_val_fold_xgb.shape[1], 1))\n",
    "                X_test_xgb = np.array(X_test_xgb).reshape((X_test_xgb.shape[0], X_test_xgb.shape[1], 1))\n",
    "\n",
    "                # Define the model\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(units=params[0]['LSTM Units'], activation='tanh', input_shape=(X_train_fold_xgb.shape[1], X_train_fold_xgb.shape[2]), return_sequences=True))\n",
    "                model.add(Dropout(params[0]['Dropout Rate']))\n",
    "                model.add(GRU(units=params[0]['GRU Units'], activation='tanh', return_sequences=True))\n",
    "                model.add(Dropout(params[0]['Dropout Rate']))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(params[0]['Dense Units'], activation='relu'))\n",
    "                model.add(Dropout(params[0]['Dropout Rate']))\n",
    "                model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "\n",
    "                # Train the model\n",
    "                history = model.fit(X_train_fold_xgb, y_train_fold, validation_data=(X_val_fold_xgb, y_val_fold), epochs=params[0]['Epochs'], batch_size=params[0]['Batch Size'])\n",
    "\n",
    "                # Store fold history\n",
    "                all_fold_histories.append(history.history)\n",
    "\n",
    "                # Calculate RMSE for training, validation, and test sets\n",
    "                train_rmse = np.sqrt(history.history['mse'][-1])\n",
    "                val_rmse = np.sqrt(history.history['val_mse'][-1])\n",
    "\n",
    "                test_results = model.evaluate(X_test_xgb, y_test, verbose=0)\n",
    "                test_rmse = np.sqrt(test_results[2])\n",
    "\n",
    "                # Calculate R^2 scores\n",
    "                y_pred_train = model.predict(X_train_fold_xgb).flatten()\n",
    "                y_pred_val = model.predict(X_val_fold_xgb).flatten()\n",
    "                y_pred_test = model.predict(X_test_xgb).flatten()\n",
    "\n",
    "                r2_train = r2_score(y_train_fold, y_pred_train)\n",
    "                r2_val = r2_score(y_val_fold, y_pred_val)\n",
    "                r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "                # Store fold results\n",
    "                fold_results.append({\n",
    "                    'Fold': fold_no,\n",
    "                    'Training Size': len(X_train_fold),\n",
    "                    'Validation Size': len(X_val_fold),\n",
    "                    'Test Size': len(X_test_xgb),\n",
    "                    'Training Loss': history.history['loss'][-1],\n",
    "                    'Validation Loss': history.history['val_loss'][-1],\n",
    "                    'Training MAE': history.history['mae'][-1],\n",
    "                    'Validation MAE': history.history['val_mae'][-1],\n",
    "                    'Training MSE': history.history['mse'][-1],\n",
    "                    'Validation MSE': history.history['val_mse'][-1],\n",
    "                    'Test Loss': test_results[0],\n",
    "                    'Test MAE': test_results[1],\n",
    "                    'Test MSE': test_results[2],\n",
    "                    'Training RMSE': train_rmse,\n",
    "                    'Validation RMSE': val_rmse,\n",
    "                    'Test RMSE': test_rmse,\n",
    "                    'Training R^2': r2_train,\n",
    "                    'Validation R^2': r2_val,\n",
    "                    'Test R^2': r2_test\n",
    "                })\n",
    "\n",
    "                fold_no += 1\n",
    "\n",
    "            # Tüm fold'ların sonuçlarını ortalama alma\n",
    "            average_history = {\n",
    "                'Epoch': np.arange(1, params[0]['Epochs'] + 1),\n",
    "                'Loss': np.mean(np.array([h['loss'] for h in all_fold_histories]).T, axis=1),\n",
    "                'Val_Loss': np.mean(np.array([h['val_loss'] for h in all_fold_histories]).T, axis=1),\n",
    "                'MAE': np.mean(np.array([h['mae'] for h in all_fold_histories]).T, axis=1),\n",
    "                'Val_MAE': np.mean(np.array([h['val_mae'] for h in all_fold_histories]).T, axis=1),\n",
    "                'MSE': np.mean(np.array([h['mse'] for h in all_fold_histories]).T, axis=1),\n",
    "                'Val_MSE': np.mean(np.array([h['val_mse'] for h in all_fold_histories]).T, axis=1),\n",
    "            }\n",
    "\n",
    "            # Ortalama RMSE hesaplama\n",
    "            average_rmse = {\n",
    "                'Epoch': average_history['Epoch'],\n",
    "                'Train_RMSE': np.sqrt(average_history['MSE']),\n",
    "                'Val_RMSE': np.sqrt(average_history['Val_MSE'])\n",
    "            }\n",
    "\n",
    "            # Ortalama fold sonuçlarını hesapla\n",
    "            average_fold_results = {\n",
    "                'Training Size': len(X_train_fold),\n",
    "                'Validation Size': len(X_val_fold),\n",
    "                'Test Size': len(X_test_xgb),\n",
    "                'Average Training Loss': np.mean([result['Training Loss'] for result in fold_results if not np.isnan(result['Training Loss'])]),\n",
    "                'Average Validation Loss': np.mean([result['Validation Loss'] for result in fold_results if not np.isnan(result['Validation Loss'])]),\n",
    "                'Average Test Loss': np.mean([result['Test Loss'] for result in fold_results if not np.isnan(result['Test Loss'])]),\n",
    "                'Average Training MAE': np.mean([result['Training MAE'] for result in fold_results if not np.isnan(result['Training MAE'])]),\n",
    "                'Average Validation MAE': np.mean([result['Validation MAE'] for result in fold_results if not np.isnan(result['Validation MAE'])]),\n",
    "                'Average Test MAE': np.mean([result['Test MAE'] for result in fold_results if not np.isnan(result['Test MAE'])]),\n",
    "                'Average Training MSE': np.mean([result['Training MSE'] for result in fold_results if not np.isnan(result['Training MSE'])]),\n",
    "                'Average Validation MSE': np.mean([result['Validation MSE'] for result in fold_results if not np.isnan(result['Validation MSE'])]),\n",
    "                'Average Test MSE': np.mean([result['Test MSE'] for result in fold_results if not np.isnan(result['Test MSE'])]),\n",
    "                'Average Training RMSE': np.mean([result['Training RMSE'] for result in fold_results if not np.isnan(result['Training RMSE'])]),\n",
    "                'Average Validation RMSE': np.mean([result['Validation RMSE'] for result in fold_results if not np.isnan(result['Validation RMSE'])]),\n",
    "                'Average Test RMSE': np.mean([result['Test RMSE'] for result in fold_results if not np.isnan(result['Test RMSE'])]),\n",
    "                'Average Training R^2': np.mean([result['Training R^2'] for result in fold_results if not np.isnan(result['Training R^2'])]),\n",
    "                'Average Validation R^2': np.mean([result['Validation R^2'] for result in fold_results if not np.isnan(result['Validation R^2'])]),\n",
    "                'Average Test R^2': np.mean([result['Test R^2'] for result in fold_results if not np.isnan(result['Test R^2'])]),\n",
    "            }\n",
    "\n",
    "            # Sonuçları ve model parametrelerini Excel dosyasına kaydetme\n",
    "            results_df = pd.DataFrame(average_history)\n",
    "            params_df = pd.DataFrame(params)\n",
    "            fold_results_df = pd.DataFrame(fold_results)\n",
    "            average_rmse_df = pd.DataFrame(average_rmse)\n",
    "            average_fold_results_df = pd.DataFrame([average_fold_results])\n",
    "\n",
    "            # Klasör oluşturma\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            name_detailed = f\"exp_{batch_size}_{unit_size}_{dropout_size}\"\n",
    "            folder_name = f'{folder}/{name_detailed}'\n",
    "            os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "            # Dosya adı oluşturma\n",
    "            file_name = f'{name_detailed}_{timestamp}.xlsx'  \n",
    "            file_path = os.path.join(folder_name, file_name)\n",
    "            file_path = file_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama kaybını çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_history['Epoch'], average_history['Loss'], label='Training Loss (average)')\n",
    "            plt.plot(average_history['Epoch'], average_history['Val_Loss'], label='Validation Loss (average)')\n",
    "            plt.title('Model Loss - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_loss.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama MAE'yi çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_history['Epoch'], average_history['MAE'], label='Training MAE (average)')\n",
    "            plt.plot(average_history['Epoch'], average_history['Val_MAE'], label='Validation MAE (average)')\n",
    "            plt.title('Model MAE - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_mae.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama MSE'yi çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_history['Epoch'], average_history['MSE'], label='Training MSE (average)')\n",
    "            plt.plot(average_history['Epoch'], average_history['Val_MSE'], label='Validation MSE (average)')\n",
    "            plt.title('Model MSE - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_mse.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Ortalama eğitim ve doğrulama RMSE'sini çizme\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(average_rmse['Epoch'], average_rmse['Train_RMSE'], label='Training RMSE (average)')\n",
    "            plt.plot(average_rmse['Epoch'], average_rmse['Val_RMSE'], label='Validation RMSE (average)')\n",
    "            plt.title('Model RMSE - Average across folds')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(folder_name, 'average_rmse.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Excel dosyasına veri yazma\n",
    "            with pd.ExcelWriter(file_path) as writer:\n",
    "                results_df.to_excel(writer, sheet_name='Average History', index=False)\n",
    "                params_df.to_excel(writer, sheet_name='Model Parameters', index=False)\n",
    "                fold_results_df.to_excel(writer, sheet_name='Fold Results', index=False)\n",
    "                average_rmse_df.to_excel(writer, sheet_name='Average RMSE', index=False)\n",
    "                average_fold_results_df.to_excel(writer, sheet_name='Average Fold Results', index=False)\n",
    "\n",
    "            print(f'Results saved to {file_path}')\n",
    "            \n",
    "            # İki veri çerçevesini yatay olarak birleştir (axis=1 ile)\n",
    "            combined_df = pd.concat([params_df, average_fold_results_df], axis=1)\n",
    "\n",
    "            file_name2 = f'{name_detailed}_{timestamp}_combined.xlsx'  \n",
    "            file_path2 = os.path.join(folder, file_name2)\n",
    "            file_path2 = file_path2.replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            # ExcelWriter ile dosyayı aç ve veri çerçevesini yaz\n",
    "            with pd.ExcelWriter(file_path2, engine='openpyxl') as writer:\n",
    "                combined_df.to_excel(writer, sheet_name='Cumulative Results', index=False)\n",
    "\n",
    "            print(f\"Results for cycle written to {file_path2}\")\n",
    "\n",
    "print(\"Model eğitimi ve değerlendirmesi tamamlandı.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
